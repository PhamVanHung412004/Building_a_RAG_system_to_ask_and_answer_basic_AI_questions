batch_decode ( response_tensors )
21 batch [" ref_response "] = tokenizer . batch_decode ( ref_response_tensors )
22
23 # Compute sentiment score
24 texts = [q + r for q, r in zip ( batch [" query "], batch [" response "])]
25 pipe_outputs = sentiment_pipe ( texts , ** sent_kwargs )
26 rewards = [ torch . tensor ( output [1][ " score "]) for output in pipe_outputs ]
27 ref_texts = [q + r for q, r in zip ( batch [" query "], batch [" ref_response "])]
28 ref_pipe_outputs = sentiment_pipe ( ref_texts , ** sent_kwargs )
29 ref_rewards = [ torch . tensor ( output [1][ " score "]) for output in ref_pipe_outputs ]
30 batch [" ref_rewards "] = ref_rewards
31
32 # Run PPO step
33 stats = ppo_trainer . step ( query_tensors , response_tensors , rewards )
34 ppo_trainer . log_stats ( stats , batch , rewards , columns_to_log =[" query ", " response ",
" ref_response ", " ref_rewards "])
13
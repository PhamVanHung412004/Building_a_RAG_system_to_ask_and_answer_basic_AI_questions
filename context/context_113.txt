Transformer Insight
Year 2023
Quang-Vinh Dinh
Ph.D. in Computer Science
AI VIETNAM
All-in-One Course
â¢Revisiting RNNs, MLPs, and CNNs
â¢From RNNs to Transformers
â¢Self-Attention
â¢Masked Self-Attention
â¢Cross-Attention
Outline
-
50,000 movie review for sentiment analysis
-
Consist of:
+ 25,000 movie review for training
+ 25,000 movie review for testing
-
Label: positive â€“ negative
â€œA wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-
BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire 
pieceâ€¦..â€
positive
â€œThis show was an amazing, fresh & innovative idea in the 70's when it first aired. The first 7 or 8 
years were brilliant, but things dropped off after that. By 1990, the show was not really funny anymore, 
and it's continued its decline further to the complete waste of time it is todayâ€¦.â€
negative
â€œI thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air 
conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is 
witty and the characters are likable (even the well bread suspected serial killer)â€¦.â€
positive
â€œBTW Carver gets a very annoying sidekick who makes you wanna shoot him the first three minutes 
he's on screen.â€
negative
Text Classification
AI VIETNAM
All-in-One Course
â– IMDB dataset
1
Review
â–Text classification model
AI VIETNAM
All-in-One Course
Text 
Embedding
The first von 
Trier movie i've 
ever seen â€¦
Text 
Encoding
Text 
Vectorization
Output
Data
Convert words to 
indices
Map indices to 
vectors
Understand 
context
Linear & 
Softmax
Classify
2
-
50,000 movie review for sentiment analysis
-
Consist of:
+ 25,000 movie review for training
+ 25,000 movie review for testing
-
Label: positive â€“ negative
Text 
Classification
â– IMDB dataset
Using RNN
Word-1
Word-2
Word-500
RNN Cell
RNN Cell
RNN Cell
RNN Cell
RNN Cell
RNN Cell
hidden_dim=64
dim=2
embed_dim = 128
50
55
60
65
70
75
80
85
1
2
3
4
5
6
7
8
9 10 11 12 13 14 15 16 17 18 19 20
Train Accuracy
Test Accuracy
Test accuracy: ~68%
4
Text Deep Models
â–Bidirectional RNN/LSTM
AI VIETNAM
All-in-One Course
50
60
70
80
90
100
110
1
2
3
4
5
6
7
8
9 10 11 12 13 14 15 16 17 18 19 20
Train Accuracy
Test Accuracy
(LSTM) Test accuracy: ~88%
5
Text Deep Models
â–Multilayer perceptron
Output
Text 
Sample
Preprocessing
(standardization & 
vectorization)
Preprocessing
ğ‘§1
Softmax
Fully-connected layer
Embedding
â€¦
ğ‘§2
6
Text Deep Models
â–Using Conv1D
Embedding
W
C
W
C
H=1
Global Pooling
Max pooling
AI VIETNAM
All-in-One Course
Data
ğ‘£1 
ğ‘£2 
ğ‘£3 
ğ‘£4
ğ‘£5 
ğ‘£6 
ğ‘£7 
ğ‘£8
ğ‘£9 ğ‘£10 ğ‘£11 ğ‘£12
ğ‘£13 ğ‘£14 ğ‘£15 ğ‘£16
ğ‘š1 = max ğ‘£1, ğ‘£2 , ğ‘£5 , ğ‘£6
ğ‘š2 = max ğ‘£3, ğ‘£4 , ğ‘£7 , ğ‘£8
ğ‘š3 = max ğ‘£9, ğ‘£10 , ğ‘£13 , ğ‘£14
ğ‘š4 = max ğ‘£11, ğ‘£12 , ğ‘£15 , ğ‘£16
ğ‘£1 
ğ‘£2 
ğ‘£3 
ğ‘£4
ğ‘£5 
ğ‘£6 
ğ‘£7 
ğ‘£8
ğ‘£9 ğ‘£10 ğ‘£11 ğ‘£12
ğ‘£13 ğ‘£14 ğ‘£15 ğ‘£16
ğ‘š1 ğ‘š2
ğ‘š3 ğ‘š4
(                       ) = 
2x2 max 
pooling 
max_pool1d(input_size)
Data
ğ‘£1 
ğ‘£2 
ğ‘£3 
ğ‘£4
ğ‘£5 
ğ‘£6 
ğ‘£7 
ğ‘£8
ğ‘£9 ğ‘£10 ğ‘£11 ğ‘£12
ğ‘£13 ğ‘£14 ğ‘£15 ğ‘£16
global max 
pooling 
ğ‘£1 
ğ‘£2 
ğ‘£3 
ğ‘£4
ğ‘£5 
ğ‘£6 
ğ‘£7 
ğ‘£8
ğ‘£9 ğ‘£10 ğ‘£11 ğ‘£12
ğ‘£13 ğ‘£14 ğ‘£15 ğ‘£16
(                       ) = ğ‘š
ğ‘š= max ğ‘£1, ğ‘£2, â€¦ , ğ‘£16
Global max pooling
8
Text Deep Models
â–Conv1D + GlobalMaxPooling1D 
AI VIETNAM
All-in-One Course
9
â¢Revisiting RNNs, MLPs, and CNNs
â¢From RNNs to Transformers
â¢Self-Attention
â¢Masked Self-Attention
â¢Cross-Attention
Outline
From RNNs to Transformers
AI VIETNAM
All-in-One Course
ğ·0
ğ·1
ğ·ğ‘›
â€¦
a word vector
a word vector
a word vector
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
new
representation
â– RNN/LSTM/GRU Limitations
10
From RNNs to Transformers
AI VIETNAM
All-in-One Course
â– Desire properties
ğ·0
ğ·1
ğ·ğ‘›
â€¦
a word vector
a word vector
a word vector
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
new
representation
ğ‘Œ0 = ğ›¼00ğ·0 + ğ›¼01ğ·1 + â‹¯+ ğ›¼0ğ‘›ğ·ğ‘›
ğ›¼00
ğ›¼01
ğ›¼0ğ‘›
11
ğ·0
ğ·1
ğ·ğ‘›
â€¦
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
new
representation
Desire Property
ğ›¼00
ğ›¼01
ğ›¼0ğ‘›
ğ›¼00
ğ›¼01
ğ›¼0ğ‘š
+
+
ğ‘Œ0  =
ğ›¼0ğ‘–=
âˆ™
12
ğ›¼00
ğ›¼01
ğ›¼0ğ‘›
+
+
ğ‘Œ0  =
ğ›¼00 =
âˆ™
ğ›¼01 =
âˆ™
ğ›¼0ğ‘š=
âˆ™
Desire Property
âˆ™
=
ğ›¼00 ğ›¼01 â€¦  ğ›¼0ğ‘› 
â€¦
ğ›¼00 =
âˆ™
ğ›¼01 =
âˆ™
ğ›¼0ğ‘›=
âˆ™
Context Awareness
AI VIETNAM
All-in-One Course
14
ğ›¼10 =
âˆ™
ğ›¼11 =
âˆ™
ğ›¼1ğ‘›=
âˆ™
âˆ™
=
ğ›¼10 ğ›¼11 â€¦  ğ›¼1ğ‘› 
â€¦
Context Awareness
AI VIETNAM
All-in-One Course
15
ğ›¼ğ‘›0 =
âˆ™
ğ›¼ğ‘›1 =
âˆ™
ğ›¼ğ‘›ğ‘›=
âˆ™
âˆ™
=
ğ›¼ğ‘›0 ğ›¼ğ‘›1 â€¦  ğ›¼ğ‘›ğ‘› 
â€¦
Context Awareness
AI VIETNAM
All-in-One Course
16
âˆ™
=
ğ›¼10 ğ›¼11 â€¦  ğ›¼1ğ‘› 
â€¦
âˆ™
=
ğ›¼00 ğ›¼01 â€¦  ğ›¼0ğ‘› 
â€¦
âˆ™
=
ğ›¼ğ‘›0 ğ›¼ğ‘›1 â€¦  ğ›¼ğ‘›ğ‘› 
â€¦
â€¦
â€¦
â€¦
âˆ™
=
ğ›¼00 ğ›¼01 â€¦  ğ›¼0ğ‘›
ğ›¼10 ğ›¼11 â€¦  ğ›¼1ğ‘›
â€¦ 
ğ›¼ğ‘›0 ğ›¼ğ‘›1 â€¦  ğ›¼ğ‘›ğ‘›
 
ğ›¼= ğ·ğ·ğ‘‡
=
ğ›¼0
ğ›¼1
â€¦ 
ğ›¼ğ‘›
 
17
ğ·0
ğ·1
ğ·ğ‘›
â€¦
a word vector
a word vector
a word vector
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
new
representation
ğ›¼00
ğ›¼01
ğ›¼0ğ‘›
ğ‘Œ0 = ğ›¼00ğ·0 + ğ›¼01ğ·1 + â‹¯+ ğ›¼0ğ‘›ğ·ğ‘›
weight: determine how 
much ğ‘‹0 contributes to ğ‘Œ0
(ğ›¼00, ğ›¼01 , â€¦ , ğ›¼0ğ‘›)
(ğ›¼10, ğ›¼11 , â€¦ , ğ›¼1ğ‘›)
â€¦ 
(ğ›¼ğ‘›0, ğ›¼ğ‘›1 , â€¦ , ğ›¼ğ‘›ğ‘›)
softmax(ğ›¼00, ğ›¼01 , â€¦ , ğ›¼0ğ‘›)
softmax(ğ›¼10, ğ›¼11 , â€¦ , ğ›¼1ğ‘›)
â€¦ 
softmax(ğ›¼ğ‘›0, ğ›¼ğ‘›1 , â€¦ , ğ›¼ğ‘›ğ‘›)
ğ›¼= softmax(ğ·ğ·ğ‘‡)
normalization
1
ğ·0
ğ·1
ğ·ğ‘š
â€¦
a word vector
a word vector
a word vector
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘š
â€¦
new
representation
ğ›¼00
ğ›¼01
ğ›¼0ğ‘›
ğ‘Œ0 = ğ›¼00ğ·0 + ğ›¼01ğ·1 + â‹¯+ ğ›¼0ğ‘›ğ·ğ‘›
weight: determine how 
much ğ‘‹0 contributes to ğ‘Œ0
(ğ›¼00, ğ›¼01 , â€¦ , ğ›¼0ğ‘›)
(ğ›¼10, ğ›¼11 , â€¦ , ğ›¼1ğ‘›)
â€¦ 
(ğ›¼ğ‘š0, ğ›¼ğ‘š1 , â€¦ , ğ›¼ğ‘›ğ‘›)
softmax(ğ›¼00, ğ›¼01 , â€¦ , ğ›¼0ğ‘›)
softmax(ğ›¼10, ğ›¼11 , â€¦ , ğ›¼1ğ‘›)
â€¦ 
softmax(ğ›¼ğ‘›0, ğ›¼ğ‘›1 , â€¦ , ğ›¼ğ‘›ğ‘›)
ğ›¼= softmax(ğ·ğ·ğ‘‡
ğ‘‘
)
weight vector
2
ğ‘Œ0 = ğ›¼00ğ·0 + ğ›¼01ğ·1 + â‹¯+ ğ›¼0ğ‘›ğ·ğ‘›
weight: determine how 
much ğ‘‹0 contributes to ğ‘Œ0
(ğ›¼00, ğ›¼01 , â€¦ , ğ›¼0ğ‘›)
(ğ›¼10, ğ›¼11 , â€¦ , ğ›¼1ğ‘›)
â€¦ 
(ğ›¼ğ‘›0, ğ›¼ğ‘›1 , â€¦ , ğ›¼ğ‘›ğ‘›)
softmax(ğ›¼00, ğ›¼01 , â€¦ , ğ›¼0ğ‘›)
softmax(ğ›¼10, ğ›¼11 , â€¦ , ğ›¼1ğ‘›)
â€¦ 
softmax(ğ›¼ğ‘›0, ğ›¼ğ‘›1 , â€¦ , ğ›¼ğ‘›ğ‘›)
ğ›¼= softmax(ğ·ğ·ğ‘‡
ğ‘‘
)
weight vector
ğ‘Œ= ğ›¼ğ·= softmax(ğ·ğ·ğ‘‡
ğ‘‘
)ğ·
Contextualized representation
ğ‘Œ=
ğ›¼0ğ‘– ğ›¼01 â€¦  ğ›¼0ğ‘›
ğ›¼1ğ‘– ğ›¼11 â€¦  ğ›¼1ğ‘›
â€¦ 
ğ›¼ğ‘›ğ‘– ğ›¼ğ‘›1 â€¦  ğ›¼ğ‘›ğ‘›
ğ·0
ğ·1
â€¦ 
ğ·ğ‘›
=
ğ‘Œ0
ğ‘Œ1
â€¦ 
ğ‘Œğ‘›
Context Awareness
AI VIETNAM
All-in-One Course
â– Contextualized representation
ğ‘‹=
ğ‘‹0
ğ‘‹1
. . .
ğ‘‹ğ‘›
âˆˆâ„›ğ‘›Ã—ğ‘‘
ğ‘Šğ‘„= ğœƒğ‘0 
ğœƒğ‘1 â€¦  ğœƒğ‘ğ‘šâˆˆâ„›ğ‘‘Ã—ğ‘š
ğ‘Šğ¾= ğœƒğ‘˜0 
ğœƒğ‘˜1 â€¦  ğœƒğ‘˜ğ‘šâˆˆâ„›ğ‘‘Ã—ğ‘š
ğ‘Šğ‘‰= ğœƒğ‘£0 
ğœƒğ‘£1 â€¦  ğœƒğ‘£ğ‘šâˆˆâ„›ğ‘‘Ã—ğ‘š
Query ğ‘„= ğ‘‹ğ‘Šğ‘„âˆˆâ„›ğ‘›Ã—ğ‘š
Key ğ¾= ğ‘‹ğ‘Šğ¾âˆˆâ„›ğ‘›Ã—ğ‘š
Value ğ‘‰= ğ‘‹ğ‘Šğ‘‰âˆˆâ„›ğ‘›Ã—ğ‘š
ğ‘Šğ‘‚= ğœƒ0 
ğœƒ1 â€¦  ğœƒğ‘œâˆˆâ„›ğ‘šÃ—ğ‘œ
word-0
word-1
word-n
â€¦
ğ‘‹0
ğ‘‹1
ğ‘‹ğ‘›
â€¦
ğ‘„0
ğ¾0
ğ‘‰0
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„1
ğ¾1
ğ‘‰1
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„ğ‘›
ğ¾ğ‘›
ğ‘‰ğ‘›
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
Vectorization 
& Embedding
21
ğ‘Œ= ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘ğ‘„ğ¾ğ‘‡
ğ‘‘
ğ‘‰
ğ‘Œ= ğ›¼ğ·= softmax(ğ·ğ·ğ‘‡
ğ‘‘
)ğ·
Contextualized representation
word-0
word-1
word-n
â€¦
ğ‘‹0
ğ‘‹1
ğ‘‹ğ‘›
â€¦
ğ‘„0
ğ¾0
ğ‘‰0
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„1
ğ¾1
ğ‘‰1
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„ğ‘›
ğ¾ğ‘›
ğ‘‰ğ‘›
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
22
Vectorization 
& Embedding
ğ´= ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘ğ‘„ğ¾ğ‘‡
ğ‘‘
ğ‘‰
ğ‘Œ= ğ´ğ‘Šğ‘‚
word-0
word-1
word-n
â€¦
ğ‘‹0
ğ‘‹1
ğ‘‹ğ‘›
â€¦
ğ‘„0
ğ¾0
ğ‘‰0
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„1
ğ¾1
ğ‘‰1
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„ğ‘›
ğ¾ğ‘›
ğ‘‰ğ‘›
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
Self-attention
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
Self-Attention
23
ğ‘‹= âˆ’0.1 0.1 0.3
ğ‘Šğ‘„=
âˆ’0.35 
0.51 
0.50
 0.36 âˆ’0.47 âˆ’0.29
âˆ’0.51 âˆ’0.14 âˆ’0.56
ğ‘Šğ¾=
âˆ’0.49 âˆ’0.68 0.18
âˆ’0.44 âˆ’0.46 0.18
 0.07 âˆ’0.10 0.44
ğ‘Šğ‘‰=
âˆ’0.41 
0.39 âˆ’0.65
âˆ’0.40 âˆ’0.07 âˆ’0.34
âˆ’0.55 âˆ’0.13 âˆ’0.29
ğ‘Šğ‘‚=
âˆ’0.36 âˆ’0.08 0.32
 0.27 
0.05 0.15
âˆ’0.05 âˆ’0.28 0.05
ğ‘„= ğ‘‹ğ‘Šğ‘„= âˆ’0.1 0.1 0.3
âˆ’0.35 
0.51 
0.50
 0.36 âˆ’0.47 âˆ’0.29
âˆ’0.51 âˆ’0.14 âˆ’0.56
= âˆ’0.08 âˆ’0.14 âˆ’0.24
ğ¾= ğ‘‹ğ‘Šğ¾= âˆ’0.1 0.1 0.3
âˆ’0.49 
âˆ’0.68 
0.18
âˆ’0.44 
âˆ’0.46 
0.18
 0.07 
âˆ’0.10 
0.44
= 0.02 âˆ’0.01 0.13
ğ‘‰= ğ‘‹ğ‘Šğ‘‰= âˆ’0.1 0.1 0.3
âˆ’0.41 
0.39 âˆ’0.65
âˆ’0.40 âˆ’0.07 âˆ’0.34
âˆ’0.55 âˆ’0.13 âˆ’0.29
= âˆ’0.16 âˆ’0.08 âˆ’0.05
head = 1
Self-Attention
â– Example 1
24
ğ‘Œ= ğ´ğ‘Šğ‘‚= âˆ’0.16 âˆ’0.08 âˆ’0.05
âˆ’0.36 âˆ’0.08 0.32
 0.27 
0.05 0.15
âˆ’0.05 âˆ’0.28 0.05
= âˆ’0.16 âˆ’0.08 âˆ’0.05
ğ´= softmax ğ‘„ğ¾ğ‘‡
ğ‘‘
ğ‘‰
= softmax âˆ’0.08 âˆ’0.14 âˆ’0.24
0.02
âˆ’0.01
0.13
1
ğ‘‘
) âˆ’0.16 âˆ’0.08 âˆ’0.05
= âˆ’0.16 âˆ’0.08 âˆ’0.05
approximately
Self-Attention
AI VIETNAM
All-in-One Course
â– Example 1
= softmax âˆ’0.0198
âˆ’0.16 âˆ’0.08 âˆ’0.05
25
head = 1
Self-Attention
â– Example 2
ğ‘‹= âˆ’0.1 
0.1 
0.3
 0.4 âˆ’1.1 âˆ’0.3
ğ‘Šğ‘„=
âˆ’0.35 
0.51 
0.50
 0.36 âˆ’0.47 âˆ’0.29
âˆ’0.51 âˆ’0.14 âˆ’0.56
ğ‘Šğ¾=
âˆ’0.49 
âˆ’0.68 0.18
âˆ’0.44 
âˆ’0.46 0.18
 0.07 
âˆ’0.10 0.44
ğ‘Šğ‘‰=
âˆ’0.41 
0.39 âˆ’0.65
âˆ’0.40 âˆ’0.07 âˆ’0.34
âˆ’0.55 âˆ’0.13 âˆ’0.29
ğ‘Šğ‘‚=
âˆ’0.36 âˆ’0.08 0.32
 0.27 
0.05 0.15
âˆ’0.05 âˆ’0.28 0.05
ğ‘„= ğ‘‹ğ‘Šğ‘„= âˆ’0.1 
0.1 
0.3
 0.4 âˆ’1.1 âˆ’0.3
âˆ’0.35 
0.51 
0.50
 0.36 âˆ’0.47 âˆ’0.29
âˆ’0.51 âˆ’0.14 âˆ’0.56
ğ¾= ğ‘‹ğ‘Šğ¾= âˆ’0.1 
0.1 
0.3
 0.4 âˆ’1.1 âˆ’0.3
âˆ’0.49 
âˆ’0.68 
0.18
âˆ’0.44 
âˆ’0.46 
0.18
 0.07 
âˆ’0.10 
0.44
ğ‘‰= ğ‘‹ğ‘Šğ‘‰= âˆ’0.1 
0.1 
0.3
 0.4 âˆ’1.1 âˆ’0.3
âˆ’0.41 
0.39 âˆ’0.65
âˆ’0.40 âˆ’0.07 âˆ’0.34
âˆ’0.55 âˆ’0.13 âˆ’0.29
= âˆ’0.08 âˆ’0.14 âˆ’0.24
âˆ’0.39 0.77 0.69
= 0.02 âˆ’0.01 0.13
0.27 0.27 âˆ’0.26
= âˆ’0.16 âˆ’0.08 âˆ’0.05
âˆ’0.02 âˆ’0.02 0.05
ğ´= ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘ğ‘„ğ¾ğ‘‡
ğ‘‘
ğ‘‰
26
approximately
Self-Attention
AI VIETNAM
All-in-One Course
â– Example 2
ğ‘Œ= ğ´ğ‘Šğ‘‚= 0.14 0.09 0.07
0.12 0.08 0.06
âˆ’0.36 âˆ’0.08 0.32
 0.27 
0.05 0.15
âˆ’0.05 âˆ’0.28 0.05
= âˆ’0.029 âˆ’0.028 0.065
âˆ’0.025 âˆ’0.025 0.058
ğ´= softmax ğ‘„ğ¾ğ‘‡
ğ‘‘
ğ‘‰
= softmax
âˆ’0.08 âˆ’0.14 âˆ’0.24
âˆ’0.39 
0.77 
0.69
 0.02 
0.27
âˆ’0.01 
0.27
 0.13 âˆ’0.26
1
ğ‘‘
âˆ’0.16 âˆ’0.08 âˆ’0.05
âˆ’0.02 âˆ’0.02 
0.05
= 0.49 0.51
0.52 0.48
âˆ’0.16 âˆ’0.08 âˆ’0.05
âˆ’0.02 âˆ’0.02 
0.05 = 0.14 0.09 0.07
0.12 0.08 0.06
= softmax
âˆ’0.019 
0.002
 0.043 
âˆ’0.046
âˆ’0.16 âˆ’0.08 âˆ’0.05
âˆ’0.02 âˆ’0.02 
0.05
27
Softmax
n
d
n
d
d
d
n
n
n
n
n
ğ‘‘ğ‘
ğ‘‘ğ‘˜
ğ‘‘ğ‘£
ğ‘‘ğ‘
ğ‘‘ğ‘˜
ğ‘‘ğ‘£
ğ‘Šğ‘
ğ‘Šğ‘˜
ğ‘Šğ‘£
Q
K
V
ğ‘„ğ¾ğ‘‡
Y
A
n
n
ğ‘‘ğ‘= ğ‘‘ğ‘˜= ğ‘‘ğ‘£
Embedding size
Sequence length
Input
ğ‘‘ğ‘£
Self-Attention
28
word-0
word-1
word-n
â€¦
ğ‘‹0
ğ‘‹1
ğ‘‹ğ‘›
â€¦
ğ‘„0
ğ¾0
ğ‘‰0
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„1
ğ¾1
ğ‘‰1
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„ğ‘›
ğ¾ğ‘›
ğ‘‰ğ‘›
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
Self-attention
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
word-0
word-1
word-n
â€¦
ğ‘‹0
ğ‘‹1
ğ‘‹ğ‘›
â€¦
ğ‘„0
ğ¾0
ğ‘‰0
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„1
ğ¾1
ğ‘‰1
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„ğ‘›
ğ¾ğ‘›
ğ‘‰ğ‘›
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
Self-attention
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
word-0
word-1
word-n
â€¦
ğ‘‹0
ğ‘‹1
ğ‘‹ğ‘›
â€¦
ğ‘„0
ğ¾0
ğ‘‰0
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„1
ğ¾1
ğ‘‰1
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„ğ‘›
ğ¾ğ‘›
ğ‘‰ğ‘›
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
Self-attention
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
ğ‘Œğ‘–= ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘ğ‘„ğ‘–ğ¾ğ‘–
ğ‘‡
ğ‘‘
ğ‘‰ğ‘–
ğ‘‚= concat(â€¦ ğ‘Œğ‘–â€¦ )ğ‘Šğ‘‚
ğ‘Šğ‘‚= ğœƒ0 
ğœƒ1 â€¦  ğœƒğ‘œâˆˆâ„›â„âˆ—ğ‘šÃ—ğ‘œ
29
â¢Revisiting RNNs, MLPs, and CNNs
â¢From RNNs to Transformers
â¢Self-Attention
â¢Masked Self-Attention
â¢Cross-Attention
Outline
word-0
word-1
word-n
â€¦
ğ‘‹0
ğ‘‹1
ğ‘‹ğ‘›
â€¦
ğ‘„0
ğ¾0
ğ‘‰0
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„1
ğ¾1
ğ‘‰1
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„ğ‘›
ğ¾ğ‘›
ğ‘‰ğ‘›
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
Transformer
AI VIETNAM
All-in-One Course
â– Masked self-attention
30
ğ·0
ğ·1
ğ·ğ‘›
â€¦
a word vector
a word vector
a word vector
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
ğ›¼00
ğ›¼01
ğ›¼0ğ‘›
ğ‘Œ0 = ğ›¼00ğ·0 + ğ›¼01ğ·1 + â‹¯+ ğ›¼0ğ‘›ğ·ğ‘›
ğ‘Œ0 = ğ›¼00ğ·0 + 0 Ã— ğ·1 + â‹¯+ 0 Ã— ğ·ğ‘›
ğ›¼0 = softmax(ğ·0ğ·ğ‘‡
ğ‘‘
) =
ğ›¼00
ğ›¼01
â€¦
ğ›¼0ğ‘›
ğ›¼00
0
â€¦
0
How to obtain 
kind of â†’
ğ›¼0 = softmax ğ·0ğ·ğ‘‡
ğ‘‘
âˆ—
1
0
â€¦
0
=
ğ›¼00
0
â€¦
0
?
Masked 
self-attention
ğ·0
ğ·1
ğ·ğ‘›
â€¦
a word vector
a word vector
a word vector
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
ğ›¼00
ğ›¼01
ğ›¼0ğ‘›
ğ‘Œ0 = ğ›¼00ğ·0 + ğ›¼01ğ·1 + â‹¯+ ğ›¼0ğ‘›ğ·ğ‘›
ğ‘Œ0 = ğ›¼00ğ·0 + 0 Ã— ğ·1 + â‹¯+ 0 Ã— ğ·ğ‘›
ğ›¼0 = softmax(ğ·0ğ·ğ‘‡
ğ‘‘
) =
ğ›¼00
ğ›¼01
â€¦
ğ›¼0ğ‘›
ğ›¼00
0
â€¦
0
How to obtain 
kind of â†’
ğ›¼0 = softmax
ğ·0ğ·ğ‘‡
ğ‘‘
âˆ—
1
0
â€¦
0
=
ğ›¼00
0
â€¦
0
?
Mask 
self-attention
ğ·0
ğ·1
ğ·ğ‘›
â€¦
a word vector
a word vector
a word vector
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
ğ›¼00
ğ›¼01
ğ›¼0ğ‘›
ğ‘Œ0 = ğ›¼00ğ·0 + ğ›¼01ğ·1 + â‹¯+ ğ›¼0ğ‘›ğ·ğ‘›
ğ‘Œ0 = ğ›¼00ğ·0 + 0 Ã— ğ·1 + â‹¯+ 0 Ã— ğ·ğ‘›
ğ›¼0 = softmax(ğ·0ğ·ğ‘‡
ğ‘š) =
ğ›¼00
ğ›¼01
â€¦
ğ›¼0ğ‘›
ğ›¼00
0
â€¦
0
How to obtain 
kind of â†’
ğ›¼0 = softmax
ğ·0ğ·ğ‘‡
ğ‘‘
+
0
âˆ’âˆ
â€¦
âˆ’âˆ
=
ğ›¼00
0
â€¦
0
?
Mask 
self-attention
ğ·0
ğ·1
ğ·ğ‘›
â€¦
a word vector
a word vector
a word vector
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
ğ›¼10
ğ›¼11
ğ›¼1ğ‘›
ğ‘Œ1 = ğ›¼10ğ·0 + ğ›¼11ğ·1 + â‹¯+ ğ›¼1ğ‘›ğ·ğ‘›
ğ‘Œ1 = ğ›¼10ğ·0 + ğ›¼11ğ·1 + â‹¯+ 0 Ã— ğ·ğ‘›
ğ›¼1 = softmax
ğ·1ğ·ğ‘‡
ğ‘‘
+
0
0
âˆ’âˆ
â€¦
âˆ’âˆ
=
ğ›¼10
ğ›¼11
0
â€¦
0
Mask 
self-attention
34
ğ·0
ğ·1
ğ·ğ‘›
â€¦
a word vector
a word vector
a word vector
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
ğ›¼ğ‘›0
ğ›¼ğ‘›1
ğ›¼ğ‘›ğ‘›
ğ‘Œğ‘›= ğ›¼ğ‘›0ğ·0 + ğ›¼ğ‘›1ğ·1 + â‹¯+ ğ›¼ğ‘›ğ‘›ğ·ğ‘›
?
ğ›¼ğ‘›= softmax
ğ·ğ‘›ğ·ğ‘‡
ğ‘‘
+
0
0
0
â€¦
0
=
ğ›¼ğ‘›0
ğ›¼ğ‘›1
ğ›¼ğ‘›2
â€¦
ğ›¼ğ‘›ğ‘›
Mask 
self-attention
35
ğ·0
ğ·1
ğ·ğ‘›
â€¦
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
ğ·0
ğ·1
ğ·ğ‘›
â€¦
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
ğ›¼= ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘ğ·ğ·ğ‘‡
ğ‘‘
ğ›¼= ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘ğ·ğ·ğ‘‡
ğ‘‘
+ ğ‘€
ğ‘€=
0 
âˆ’âˆ 
âˆ’âˆâ€¦ âˆ’âˆ
0 
0 
âˆ’âˆâ€¦ âˆ’âˆ
â€¦
0 
0 
0 
â€¦  
0
ğ‘Œ= ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘ğ‘„ğ¾ğ‘‡
ğ‘‘
+ ğ‘€ğ‘‰
ğ‘€=
0 
âˆ’âˆ 
âˆ’âˆâ€¦ âˆ’âˆ
0 
0 
âˆ’âˆâ€¦ âˆ’âˆ
â€¦
0 
0 
0 
â€¦  
0
Mask self-attention
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
word-0
word-1
word-n
â€¦
ğ‘‹0
ğ‘‹1
ğ‘‹ğ‘›
â€¦
ğ‘„0
ğ¾0
ğ‘‰0
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„1
ğ¾1
ğ‘‰1
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„ğ‘›
ğ¾ğ‘›
ğ‘‰ğ‘›
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
37
ğ´= ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘ğ‘„ğ¾ğ‘‡
ğ‘‘
+ ğ‘€ğ‘‰
ğ‘Œ= ğ´ğ‘Šğ‘‚
Mask self-attention
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
word-0
word-1
word-n
â€¦
ğ‘‹0
ğ‘‹1
ğ‘‹ğ‘›
â€¦
ğ‘„0
ğ¾0
ğ‘‰0
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„1
ğ¾1
ğ‘‰1
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„ğ‘›
ğ¾ğ‘›
ğ‘‰ğ‘›
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
Masked 
Self-Attention
38
ğ‘‹= âˆ’0.1 
0.1 
0.3
 0.4 âˆ’1.1 âˆ’0.3
ğ‘Šğ‘„=
âˆ’0.35 
0.51 
0.50
 0.36 âˆ’0.47 âˆ’0.29
âˆ’0.51 âˆ’0.14 âˆ’0.56
ğ‘Šğ¾=
âˆ’0.49 
âˆ’0.68 0.18
âˆ’0.44 
âˆ’0.46 0.18
 0.07 
âˆ’0.10 0.44
ğ‘Šğ‘‰=
âˆ’0.41 
0.39 âˆ’0.65
âˆ’0.40 âˆ’0.07 âˆ’0.34
âˆ’0.55 âˆ’0.13 âˆ’0.29
ğ‘Šğ‘‚=
âˆ’0.36 âˆ’0.08 0.32
 0.27 
0.05 0.15
âˆ’0.05 âˆ’0.28 0.05
ğ‘„= ğ‘‹ğ‘Šğ‘„= âˆ’0.1 
0.1 
0.3
 0.4 âˆ’1.1 âˆ’0.3
âˆ’0.35 
0.51 
0.50
 0.36 âˆ’0.47 âˆ’0.29
âˆ’0.51 âˆ’0.14 âˆ’0.56
ğ¾= ğ‘‹ğ‘Šğ¾= âˆ’0.1 
0.1 
0.3
 0.4 âˆ’1.1 âˆ’0.3
âˆ’0.49 
âˆ’0.68 
0.18
âˆ’0.44 
âˆ’0.46 
0.18
 0.07 
âˆ’0.10 
0.44
ğ‘‰= ğ‘‹ğ‘Šğ‘‰= âˆ’0.1 
0.1 
0.3
 0.4 âˆ’1.1 âˆ’0.3
âˆ’0.41 
0.39 âˆ’0.65
âˆ’0.40 âˆ’0.07 âˆ’0.34
âˆ’0.55 âˆ’0.13 âˆ’0.29
head = 1
Masked Multi-
head Attention
ğ‘€= 0 
âˆ’âˆ
0 
0
= âˆ’0.08 âˆ’0.14 âˆ’0.24
âˆ’0.39 0.77 0.69
= 0.02 âˆ’0.01 0.13
0.27 0.27 âˆ’0.26
= âˆ’0.16 âˆ’0.08 âˆ’0.05
âˆ’0.02 âˆ’0.02 0.05
39
approximately
Masked Multi-head Attention
AI VIETNAM
All-in-One Course
â– Example 
ğ‘Œ= ğ´ğ‘Šğ‘‚= âˆ’0.16 âˆ’0.08 âˆ’0.05
 0.12 
0.08 
0.06
âˆ’0.36 âˆ’0.08 0.32
 0.27 
0.05 0.15
âˆ’0.05 âˆ’0.28 0.05
=
0.03 0.02 âˆ’0.06
âˆ’0.02 âˆ’0.02 0.05
ğ´= ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘ğ‘„ğ¾ğ‘‡
ğ‘‘
+ ğ‘€ğ‘‰
= ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘
âˆ’0.08 âˆ’0.14 âˆ’0.24
âˆ’0.39 
0.77 
0.69
 0.02 
0.27
âˆ’0.01 
0.27
 0.13 âˆ’0.26
1
ğ‘‘
+ 0 
âˆ’âˆ
0 
0
âˆ’0.16 âˆ’0.08 âˆ’0.05
âˆ’0.02 âˆ’0.02 
0.05
=
1.0 
0.0
0.52 0.48
âˆ’0.16 âˆ’0.08 âˆ’0.05
âˆ’0.02 âˆ’0.02 
0.05 = âˆ’0.16 âˆ’0.08 âˆ’0.05
 0.12 
0.08 0.06
= ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘
âˆ’0.019 
0.002
 0.043 
âˆ’0.046 + 0 
âˆ’âˆ
0 
0
âˆ’0.16 âˆ’0.08 âˆ’0.05
âˆ’0.02 âˆ’0.02 
0.05
40
Softmax
n
d
n
d
d
d
n
n
n
n
n
ğ‘‘ğ‘
ğ‘‘ğ‘˜
ğ‘‘ğ‘£
ğ‘‘ğ‘
ğ‘‘ğ‘˜
ğ‘‘ğ‘£
ğ‘Šğ‘
ğ‘Šğ‘˜
ğ‘Šğ‘£
Q
K
V
ğ‘„ğ¾ğ‘‡
Y
A
n
n
ğ‘‘ğ‘= ğ‘‘ğ‘˜= ğ‘‘ğ‘£
Embedding size
Sequence length
Input
ğ‘‘ğ‘£
Masked Self-Attention
âˆ’âˆ
0
41
ğ´= ğ‘ ğ‘–ğ‘”ğ‘šğ‘œğ‘–ğ‘‘ğ‘„ğ¾ğ‘‡
ğ‘‘
ğ‘‰
ğ‘Œ= ğ´ğ‘Šğ‘‚
ğ¸0
ğ¸1
ğ¸ğ‘›
â€¦
ğ‘„0
ğ¾0
ğ‘‰0
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„1
ğ¾1
ğ‘‰1
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
ğ‘„ğ‘›
ğ¾ğ‘›
ğ‘‰ğ‘›
ğ‘Šğ‘„
ğ‘Šğ¾
ğ‘Šğ‘‰
One head cross-attention
ğ‘Œ0
ğ‘Œ1
ğ‘Œğ‘›
â€¦
ğ·0
ğ·1
ğ·ğ‘›
Cross-Attention
â– Example
42
head = 1
Cross-Attention
â– Example
ğ‘‹= âˆ’0.1 
0.1 
0.3
 0.4 âˆ’1.1 âˆ’0.3
ğ‘Šğ‘„=
âˆ’0.35 
0.51 
0.50
 0.36 âˆ’0.47 âˆ’0.29
âˆ’0.51 âˆ’0.14 âˆ’0.56
ğ‘Šğ¾=
âˆ’0.49 
âˆ’0.68 0.18
âˆ’0.44 
âˆ’0.46 0.18
 0.07 
âˆ’0.10 0.44
ğ‘Šğ‘‰=
âˆ’0.41 
0.39 âˆ’0.65
âˆ’0.40 âˆ’0.07 âˆ’0.34
âˆ’0.55 âˆ’0.13 âˆ’0.29
ğ‘Šğ‘‚=
âˆ’0.36 âˆ’0.08 0.32
 0.27 
0.05 0.15
âˆ’0.05 âˆ’0.28 0.05
ğ‘„= ğ¶ğ‘Šğ‘„= âˆ’0.6 
0.3 âˆ’0.4
 0.5 
0.9 âˆ’0.5
âˆ’0.35 
0.51 
0.50
 0.36 âˆ’0.47 âˆ’0.29
âˆ’0.51 âˆ’0.14 âˆ’0.56
ğ¾= ğ‘‹ğ‘Šğ¾= âˆ’0.1 
0.1 
0.3
 0.4 âˆ’1.1 âˆ’0.3
âˆ’0.49 
âˆ’0.68 
0.18
âˆ’0.44 
âˆ’0.46 
0.18
 0.07 
âˆ’0.10 
0.44
ğ‘‰= ğ‘‹ğ‘Šğ‘‰= âˆ’0.1 
0.1 
0.3
 0.4 âˆ’1.1 âˆ’0.3
âˆ’0.41 
0.39 âˆ’0.65
âˆ’0.40 âˆ’0.07 âˆ’0.34
âˆ’0.55 âˆ’0.13 âˆ’0.29
= 0.52 âˆ’0.39 âˆ’0.16
0.40 âˆ’0.09 
0.27
= 0.02 âˆ’0.01 0.13
0.27 0.27 âˆ’0.26
= âˆ’0.16 âˆ’0.08 âˆ’0.05
âˆ’0.02 âˆ’0.02 0.05
ğ¶= âˆ’0.6 
0.3 âˆ’0.4
 0.5 
0.9 âˆ’0.5
43
approximately
Cross-Attention
AI VIETNAM
All-in-One Course
â– Example
ğ‘Œ= ğ´ğ‘Šğ‘‚= 0.15 0.10 0.07
0.13 0.09 0.07
âˆ’0.36 âˆ’0.08 0.32
 0.27 
0.05 0.15
âˆ’0.05 âˆ’0.28 0.05
= âˆ’0.0305 âˆ’0.0296 0.0677
âˆ’0.0281 âˆ’0.0277 0.0630
ğ´= softmax ğ‘„ğ¾ğ‘‡
ğ‘‘
ğ‘‰
= softmax
0.52 âˆ’0.39 âˆ’0.16
0.40 âˆ’0.09 
0.27
 0.02 
0.27
âˆ’0.01 
0.27
 0.13 âˆ’0.26
1
ğ‘‘
âˆ’0.16 âˆ’0.08 âˆ’0.05
âˆ’0.02 âˆ’0.02 
0.05
= 0.49 0.51
0.51 0.49
âˆ’0.16 âˆ’0.08 âˆ’0.05
âˆ’0.02 âˆ’0.02 
0.05 = 0.15 0.10 0.07
0.13 0.09 0.07
= softmax
âˆ’0.0028 0.0470
 0.0278 0.0075
âˆ’0.16 âˆ’0.08 âˆ’0.05
âˆ’0.02 âˆ’0.02 
0.05
44
Softmax
n
d
n
d
d
d
n
m
m
n
m
ğ‘‘ğ‘
ğ‘‘ğ‘˜
ğ‘‘ğ‘£
ğ‘‘ğ‘
ğ‘‘ğ‘˜
ğ‘‘ğ‘£
ğ‘Šğ‘
ğ‘Šğ‘˜
ğ‘Šğ‘£
Q
K
V
ğ‘„ğ¾ğ‘‡
Z
A
n
m
ğ‘‘ğ‘= ğ‘‘ğ‘˜
Embedding size
Sequence length
Input 1
(Decoder hidden state)
m
d
Sequence length
Input 2
(Encoder output)
ğ‘‘ğ‘£
Cross-Attention
45

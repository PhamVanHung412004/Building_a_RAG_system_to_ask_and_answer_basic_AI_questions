Sau đó, việc so sánh các hình ảnh không
được thực hiện trực tiếp trên ảnh gốc mà là thông qua việc tính sự tương đồng giữa các vector này.
Đoạn code bên đưới khởi tạo một hàm để trích xuất vector đặc trưng từ một hình sử dụng mô hình CLIP.
Tiếp theo, hàm get_single_image_embedding nhận một hình ảnh làm đầu vào và sử dụng phương thức
_encode_image của OpenCLIPEmbeddingFunction để trích xuất ảnh thành một vector đặc trưng.
1 embedding_function = OpenCLIPEmbeddingFunction()
2
3 def get_single_image_embedding(image):
4 embedding = embedding_function._encode_image(image=image)
5 return np.array(embedding)
Truy vấn embedding vector với độ đo L1hàm get_l1_score được nâng cấp lên bằng cách sử dụng
CLIP model để trích xuất vector đặc trưng.
1 def get_l1_score(root_img_path, query_path, size):
2 query = read_image_from_path(query_path, size)
3 query_embedding = get_single_image_embedding(query)
4 ls_path_score = []
5 for folder in os.listdir(root_img_path):
6 if folder in CLASS_NAME:
7 path = root_img_path + folder
8 images_np, images_path = folder_to_images(path, size) # mang numpy nhieu anh,
paths
9 embedding_list = []
10 for idx_img in range(images_np.shape[0]):
11 embedding = get_single_image_embedding(images_np[idx_img].astype(np.uint8))
12 embedding_list.append(embedding)
13 rates = absolute_difference(query_embedding, np.stack(embedding_list))
14 ls_path_score.extend(list(zip(images_path, rates)))
15 return query, ls_path_score
Hình 12: Image retrieval ảnh đơn giản với model CLIP và L1
11
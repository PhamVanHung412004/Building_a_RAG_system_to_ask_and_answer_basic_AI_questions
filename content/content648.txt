<<<<<<< HEAD
Node ID: 95ca3bf4-ff03-4375-beb9-181bf941c6f4
Text: Điều này gây ra khó khăn khi áp dụng các model từ NLP (ví dụ
Mamba, Transformer) sang CV. Hình 1: Pixel-level và Patch-level khi sử
dụng mô hình Transformer cho data dạng ảnh. Hình 1 mô tả 2 cách chuyển
đổi từ data 2D sang data 1D. Nếu ta chia ảnh đầu vào theo pixel-level
thì với ví dụ như hình (ảnh224x224) ta sẽ có hơn50k token, nếu ánh xạ
tươn...
=======
Điều này gây ra khó khăn khi áp dụng các model từ NLP (ví dụ Mamba, Transformer) sang CV.
Hình 1: Pixel-level và Patch-level khi sử dụng mô hình Transformer cho data dạng ảnh.
Hình 1 mô tả 2 cách chuyển đổi từ data 2D sang data 1D. Nếu ta chia ảnh đầu vào theo pixel-level
thì với ví dụ như hình (ảnh224x224) ta sẽ có hơn50k token, nếu ánh xạ tương ứng sang text là 1 câu
có 50k từ. Điều này cực kì khó khăn đối với các GPU để tính toán. Cách phổ biến được sử dụng đối
với Transformer chính là chia ảnh đầu vào thành các patch nhỏ (ví dụ16x16 pixel), ảnh có kích thước
224x224 sau khi chia sẽ có tổng cộng14*14=196 patch (hoặc token).196 token là hoàn toàn hợp lý so với
50k và các GPU vẫn có thể hoạt động bình thường.
2
>>>>>>> HEAD@{1}

Multi-layer Perception
Activation and Initialization
Year 2023
Quang-Vinh Dinh
Ph.D. in Computer Science
AI VIETNAM
All-in-One Course
â¢Pipeline Recommendation
â¢Data Normalization
â¢Activation Functions
â¢MLP Examples
â¢Initialization Methods
Outline
To-do List for Training
Training
Data
Testing
Data
Model
â‰ 
Used to train model
(Teach the model 
by examples)
Used to validate model
(Check how good the model is)
Data Preparation
Data 
Normalization
Model (Network) 
Construction
Parameter 
Initialization
Optimizer 
Selection
Loss function Selection
Metric 
Selection
Data Preparation
1
Image = Image
255
Convert to the range [0,1]
Image = Image
127.5 âˆ’1
Convert to the range [-1,1]
Image = Image âˆ’Î¼
Ïƒ
Z-score normalization
Image = Image âˆ’ğ‘šğ‘’ğ‘ğ‘›
std
In Pytorch
Normalize(ğ‘šğ‘’ğ‘ğ‘›, std)
[0,1]
mean = 0 ; std = 1
[-1,1]
mean = 0.5; std = 0.5
Compute mean and std 
from data
In Theory
ğ‘‹âˆˆ0, 255
ğ‘‹âˆˆ0, 1
Data Preparation
Data 
Normalization
Model (Network) 
Construction
Parameter 
Initialization
Optimizer 
Selection
Loss function Selection
Metric 
Selection
Data Normalization
(a) [0, 1] Normalization
(b) [-1, 1] Normalization
(c) z-score Normalization
1
2
3
[0, 1] Normalization
[-1, 1] Normalization
z-score Normalization
Data Normalization
Training Pipeline
AI VIETNAM
All-in-One Course
Data Preparation
Data 
Normalization
Model (Network) 
Construction
Parameter 
Initialization
Optimizer 
Selection
Loss function 
Selection
Metric Selection
Multi-layer Perceptron
1) #Hidden Layers?
2) #Nodes in a Hidden Layers?
3) Which activation functions?
4) Which Initializers?
5
Training Pipeline
AI VIETNAM
All-in-One Course
Model (Network) Construction
Input layer
Ouptut layer
Output
1
ğ‘§1
ğ‘§2
ğ‘§3
activation
Input
1
. . .
. . .
Fully connect
activation
Hidden Layers
How many hidden layers?
How many nodes in a hidden layer?
Which activation function?
Which network components?
6
How many nodes?
AI VIETNAM
All-in-One Course
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
1
Sigmoid 
activation
How many nodes?
Fully 
connect
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
Model (Network) Construction
7
How many nodes?
AI VIETNAM
All-in-One Course
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
1
Sigmoid 
activation
Grid Search
Fully 
connect
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
ğ‘1 ğ‘2 â€¦ ğ‘ğ‘˜
Model (Network) Construction
8
256 nodes
[-1, 1] Normalization
64 nodes
1024 nodes
Cross-entropy Loss
SGD with lr=0.01
How many nodes?
Train-Acc: 90%
Test-Acc: 87%
Train-Acc: 89%
Test-Acc: 86%
Train-Acc: 90%
Test-Acc: 87%
9
2 Hidden Layers
3 Hidden Layers
4 Hidden Layers
Train-Acc: 92%
Test-Acc: 88%
Train-Acc: 91%
Test-Acc: 88%
Train-Acc: 92%
Test-Acc: 88%
1 Hidden Layer
Train-Acc: 90%
Test-Acc: 87%
Activation Functions
AI VIETNAM
All-in-One Course
Model (Network) Construction
Which activation function?
tanh ğ‘¥=
2
1 + ğ‘’âˆ’2ğ‘¥âˆ’1
sigmoid ğ‘¥=
1
1 + ğ‘’âˆ’ğ‘¥
PReLU ğ‘¥= á‰Šğ›¼ğ‘¥ if ğ‘¥< 0
ğ‘¥ 
if ğ‘¥â‰¥0
ELU ğ‘¥= á‰Šğ›¼ğ‘’ğ‘¥âˆ’1  if ğ‘¥< 0
ğ‘¥ 
if ğ‘¥â‰¥0
softplus ğ‘¥= log 1 + ğ‘’ğ‘¥
ReLU ğ‘¥= á‰Š0 
if ğ‘¥< 0
ğ‘¥ 
if ğ‘¥â‰¥0
2001
2015
2010
ğ‘†ğ¸ğ¿ğ‘ˆğ‘¥= á‰Šğœ†ğ‘¥ 
if ğ‘¥â‰¥0
ğœ†Î± ğ‘’ğ‘¥âˆ’1  if ğ‘¥< 0
2017
2015
ğ‘ ğ‘¤ğ‘–ğ‘ â„ğ‘¥= ğ‘¥âˆ—
1
1 + ğ‘’âˆ’ğ‘¥
2017
ğœ†â‰ˆ1.0507
Î± â‰ˆ1.6733
11
Activation Functions
â– Step function
AI VIETNAM
All-in-One Course
ğ‘“ğ‘¥= á‰Š0 ğ‘–ğ‘“ ğ‘¥< 0
1 ğ‘–ğ‘“ ğ‘¥â‰¥0
Binary Step Function
Input layer
1
1
. . .
Step
Function
ğ‘§1
ğ‘§10
Softmax 
activation
Fully 
connect
10 Nodes
Output layer
. . .
https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/
12
Activation Functions
â– Sigmoid function
AI VIETNAM
All-in-One Course
sigmoid ğ‘¥=
1
1 + ğ‘’âˆ’ğ‘¥
sigmoidâ€² ğ‘¥= sigmoid ğ‘¥
1 âˆ’sigmoid ğ‘¥
13
Activation Functions
AI VIETNAM
All-in-One Course
sigmoid ğ‘¥=
1
1 + ğ‘’âˆ’ğ‘¥
= sigmoid ğ‘¥
1 âˆ’sigmoid ğ‘¥
sigmoidâ€²(ğ‘¥) =
1
1 + ğ‘’âˆ’ğ‘¥
â€²
=
âˆ’1
1 + ğ‘’âˆ’ğ‘¥2 âˆ’ğ‘’âˆ’ğ‘¥
=
ğ‘’âˆ’ğ‘¥
1 + ğ‘’âˆ’ğ‘¥2 = ğ‘’âˆ’ğ‘¥+ 1 âˆ’1
1 + ğ‘’âˆ’ğ‘¥2
=
1
1 + ğ‘’âˆ’ğ‘¥âˆ’
1
1 + ğ‘’âˆ’ğ‘¥2
=
1
1 + ğ‘’âˆ’ğ‘¥
1 âˆ’
1
1 + ğ‘’âˆ’ğ‘¥
14
Activation Functions
â– Tanh function
AI VIETNAM
All-in-One Course
ğ‘¡ğ‘ğ‘›â„â€² ğ‘¥= 1 âˆ’ğ‘¡ğ‘ğ‘›â„2(ğ‘¥)
tanh ğ‘¥= ğ‘’ğ‘¥âˆ’ğ‘’âˆ’ğ‘¥
ğ‘’ğ‘¥+ ğ‘’âˆ’ğ‘¥
=
2
1 + ğ‘’âˆ’2ğ‘¥âˆ’1
= 1 âˆ’
2
ğ‘’2ğ‘¥+ 1
15
Activation Functions
AI VIETNAM
All-in-One Course
tanh ğ‘¥= ğ‘’ğ‘¥âˆ’ğ‘’âˆ’ğ‘¥
ğ‘’ğ‘¥+ ğ‘’âˆ’ğ‘¥= 1 âˆ’
2
ğ‘’2ğ‘¥+ 1 =
2
ğ‘’âˆ’2ğ‘¥+ 1 âˆ’1
tanhâ€²(ğ‘¥) =
ğ‘’ğ‘¥âˆ’ğ‘’âˆ’ğ‘¥
ğ‘’ğ‘¥+ ğ‘’âˆ’ğ‘¥
â€²
= ğ‘’ğ‘¥+ ğ‘’âˆ’ğ‘¥
ğ‘’ğ‘¥+ ğ‘’âˆ’ğ‘¥âˆ’ğ‘’ğ‘¥âˆ’ğ‘’âˆ’ğ‘¥
ğ‘’ğ‘¥âˆ’ğ‘’âˆ’ğ‘¥
ğ‘’ğ‘¥+ ğ‘’âˆ’ğ‘¥2
= ğ‘’ğ‘¥+ ğ‘’âˆ’ğ‘¥2 âˆ’ğ‘’ğ‘¥âˆ’ğ‘’âˆ’ğ‘¥2
ğ‘’ğ‘¥+ ğ‘’âˆ’ğ‘¥2
= 1 âˆ’
ğ‘’ğ‘¥âˆ’ğ‘’âˆ’ğ‘¥
ğ‘’ğ‘¥+ ğ‘’âˆ’ğ‘¥
2
= 1 âˆ’ğ‘¡ğ‘ğ‘›â„2(ğ‘¥)
16
Activation Functions
AI VIETNAM
All-in-One Course
tanh ğ‘¥= ğ‘’ğ‘¥âˆ’ğ‘’âˆ’ğ‘¥
ğ‘’ğ‘¥+ ğ‘’âˆ’ğ‘¥= 1 âˆ’
2
ğ‘’2ğ‘¥+ 1 =
2
ğ‘’âˆ’2ğ‘¥+ 1 âˆ’1
ğ‘¡ğ‘ğ‘›â„â€²(ğ‘¥) =
2
ğ‘’âˆ’2ğ‘¥+ 1 âˆ’1 
â€²
=
4ğ‘’âˆ’2ğ‘¥
ğ‘’âˆ’2ğ‘¥+ 1 2 = 4 ğ‘’âˆ’2ğ‘¥+ 1 âˆ’1
ğ‘’âˆ’2ğ‘¥+ 1 2  
= 4
1
ğ‘’âˆ’2ğ‘¥+ 1 âˆ’
1
ğ‘’âˆ’2ğ‘¥+ 1 2
= âˆ’
4
ğ‘’âˆ’2ğ‘¥+ 1 2 âˆ’
4
ğ‘’âˆ’2ğ‘¥+ 1
= âˆ’
4
ğ‘’âˆ’2ğ‘¥+ 1 2 âˆ’
4
ğ‘’âˆ’2ğ‘¥+ 1 + 1 âˆ’1
= 1 âˆ’
2
ğ‘’âˆ’2ğ‘¥+ 1 âˆ’1
2
= 1 âˆ’ğ‘¡ğ‘ğ‘›â„2(ğ‘¥)
17
Activation Functions
â– Softplus function
AI VIETNAM
All-in-One Course
softplus ğ‘¥= log 1 + ğ‘’ğ‘¥
softplusâ€² ğ‘¥=
1
1 + ğ‘’âˆ’ğ‘¥
18
Activation Functions
â– ReLU function
AI VIETNAM
All-in-One Course
ReLU ğ‘¥= á‰Š0 
if ğ‘¥â‰¤0
ğ‘¥ 
if ğ‘¥> 0
ReLU â€² ğ‘¥= á‰Š0 
if ğ‘¥â‰¤0
1 
if ğ‘¥> 0
19
Activation Functions
â– LeakyReLU  function
AI VIETNAM
All-in-One Course
LeakyReLU ğ‘¥= á‰Š0.01ğ‘¥ if ğ‘¥â‰¤0
ğ‘¥ 
if ğ‘¥> 0
LeakyReLUâ€² ğ‘¥= á‰Š0.01 if ğ‘¥â‰¤0
1 
if ğ‘¥> 0
20
Activation Functions
â– ELU function
AI VIETNAM
All-in-One Course
ELU ğ‘¥= á‰Šğ›¼ğ‘’ğ‘¥âˆ’1  if ğ‘¥â‰¤0
ğ‘¥ 
if ğ‘¥> 0
ELU â€² ğ‘¥= á‰Šğ›¼ğ‘’ğ‘¥ 
if ğ‘¥â‰¤0
1 
if ğ‘¥> 0
ğ›¼= 0.1
21
Activation Functions
â– PReLU function
AI VIETNAM
All-in-One Course
PReLU ğ‘¥= á‰Šğ›¼ğ‘¥ if ğ‘¥< 0
ğ‘¥ 
if ğ‘¥â‰¥0
PReLUâ€² ğ‘¥= á‰Šğ›¼ 
if ğ‘¥â‰¤0
1 
if ğ‘¥> 0
ğ›¼= 0.1
22
Activation Functions
â– Swish function
AI VIETNAM
All-in-One Course
ğ‘ ğ‘¤ğ‘–ğ‘ â„â€² ğ‘¥= ğ‘ ğ‘¤ğ‘–ğ‘ â„ğ‘¥+ Ïƒ ğ‘¥(1 âˆ’ğ‘ ğ‘¤ğ‘–ğ‘ â„ğ‘¥)
ğ‘ ğ‘¤ğ‘–ğ‘ â„ğ‘¥=
ğ‘¥
1 + ğ‘’âˆ’ğ‘¥= ğ‘¥Ïƒ ğ‘¥
Ïƒ ğ‘¥=
1
1 + ğ‘’âˆ’ğ‘¥
23
Activation Functions
AI VIETNAM
All-in-One Course
ğ‘ ğ‘¤ğ‘–ğ‘ â„ğ‘¥=
ğ‘¥
1 + ğ‘’âˆ’ğ‘¥= ğ‘¥Ïƒ ğ‘¥
Ïƒ ğ‘¥=
1
1 + ğ‘’âˆ’ğ‘¥
ğ‘ ğ‘¤ğ‘–ğ‘ hâ€² ğ‘¥
= ğ‘¥Ïƒ ğ‘¥
â€² = ğ‘¥â€² Ïƒ ğ‘¥+ ğ‘¥Ïƒ ğ‘¥
â€²
= Ïƒ ğ‘¥+ ğ‘¥Ïƒ ğ‘¥
1 âˆ’Ïƒ ğ‘¥
= Ïƒ ğ‘¥+ ğ‘¥Ïƒ ğ‘¥âˆ’ğ‘¥Ïƒ ğ‘¥2
= ğ‘¥Ïƒ ğ‘¥+ Ïƒ ğ‘¥
1 âˆ’ğ‘¥Ïƒ ğ‘¥
= ğ‘ ğ‘¤ğ‘–ğ‘ â„ğ‘¥+ Ïƒ ğ‘¥(1 âˆ’ğ‘ ğ‘¤ğ‘–ğ‘ â„ğ‘¥)
24
â¢Pipeline Recommendation
â¢Data Normalization
â¢Activation Functions
â¢MLP Examples
â¢Initialization Methods
Outline
To-do List for Training
Train a model
AI VIETNAM
All-in-One Course
Data Preparation
Data 
Normalization
Model (Network) 
Construction
Parameter 
Initialization
Optimizer 
Selection
Loss function 
Selection
Metric Selection
25
MLP Example 1
AI VIETNAM
All-in-One Course
Feature
Label
ğ’™=
ğ’™(1)
ğ’™(2)
ğ’™(3)
=
1.5 0.2
4.7 1.6
5.6 2.2
ğ’š=
0
1
2
=
0.0 
0.0
0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ‘¾â„= ğ‘¾ğ’‰1 ğ‘¾â„2
=
0.0 
0.0 
0.0
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ‘¾ğ‘§= ğ‘¾ğ’›1 ğ‘¾ğ‘§2 ğ‘¾ğ‘§3
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
Input layer
Hidden layer
Output layer
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
26
ğ’‰= ğ’™ğ‘¾â„=
1 1.5 0.2
1 4.7 1.6
1 5.6 2.2
0.0 
0.0
0.86 
âˆ’1.04
0.41 âˆ’0.65
=
1.373 
âˆ’1.696
4.708 
âˆ’5.951
5.731 
âˆ’7.281
ReLU(ğ’‰) =
1.373 
0
4.708 
0
5.731 
0
Feature
Label
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
Input layer
Hidden layer
Output layer
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
=
0.0 
0.0
0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ‘¾â„= ğ‘¾ğ’‰1 ğ‘¾â„2
=
0.0 
0.0 
0.0
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ‘¾ğ‘§= ğ‘¾ğ’›1 ğ‘¾ğ‘§2 ğ‘¾ğ‘§3
ğ’™=
ğ’™(1)
ğ’™(2)
ğ’™(3)
=
1 1.5 0.2
1 4.7 1.6
1 5.6 2.2
ğ’š=
0
1
2
27
ReLU(ğ’‰) =
1.373 
0
4.708 
0
5.731 
0
ğŸ ReLU(ğ’‰) =
1 1.373 
0
1 4.708 
0
1 5.731 
0
ğ’›= ğŸ ReLU(ğ’‰) ğ‘¾ğ‘§=
1 1.373 
0
1 4.708 
0
1 5.731 
0
0.0 
0.0 
0.0
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
=
0.439 0.356 0.195
1.507 1.220 0.670
1.835 1.485 0.816
Feature
Label
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
Input layer
Hidden layer
Output layer
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
=
0.0 
0.0
0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ‘¾â„= ğ‘¾ğ’‰1 ğ‘¾â„2
=
0.0 
0.0 
0.0
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ‘¾ğ‘§= ğ‘¾ğ’›1 ğ‘¾ğ‘§2 ğ‘¾ğ‘§3
ğ’™=
ğ’™(1)
ğ’™(2)
ğ’™(3)
=
1 1.5 0.2
1 4.7 1.6
1 5.6 2.2
ğ’š=
0
1
2
28
loss = 1.269
Feature
Label
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
Input layer
Hidden layer
Output layer
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
=
0.0 
0.0
0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ‘¾â„= ğ‘¾ğ’‰1 ğ‘¾â„2
=
0.0 
0.0 
0.0
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ‘¾ğ‘§= ğ‘¾ğ’›1 ğ‘¾ğ‘§2 ğ‘¾ğ‘§3
ğ’›=
0.439 0.356 0.195
1.507 1.220 0.670
1.835 1.485 0.816
à·ğ’š= softmax(ğ’›) =
à·ğ’š(1)
à·ğ’š(2)
à·ğ’š(3)
=
0.369 0.340 0.289
0.458 0.343 0.198
0.484 0.341 0.174
ğ’™=
ğ’™(1)
ğ’™(2)
ğ’™(3)
=
1 1.5 0.2
1 4.7 1.6
1 5.6 2.2
ğ’š=
0
1
2
29
Example 2 - Dying ReLU
Feature
Label
ğ’™= 1.5
0.2
ğ‘¦= 0
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
Input layer
Hidden layer
Output layer
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
= 0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ’= ğ’ğŸ ğ’2
=
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ’˜= ğ’˜1 ğ’˜2 ğ’˜3
ğ’ƒğ’= 0.0
0.0
ğ’ƒğ’˜=
0.0
0.0
0.0
AI VIETNAM
All-in-One Course
30
= 0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ’= ğ’ğŸ 
ğ’2
=
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ’˜= ğ’˜1 
ğ’˜2 
ğ’˜3
ğ’ƒğ’= 0.0
0.0
ğ’ƒğ’˜=
0.0
0.0
0.0
ğ’™= 1.5
0.2
ğ‘¦= 0
â†’ğ’š=
1
0
0
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
Input layer
Hidden layer
Output layer
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
Loss 
Function
âˆ’à·
ğ‘–
ğ‘¦ğ‘–ğ‘™ğ‘œğ‘”à·œğ‘¦
ğ‘š11
ğ‘š21
ğ‘¤12
ğ‘¤21
ğ‘¤31
ğ‘š12
ğ‘ğ‘š1
ğ‘š22
ğ‘ğ‘š2
ğ‘¤11
ğ‘ğ‘¤1
ğ‘¤22
ğ‘ğ‘¤2
ğ‘¤32
ğ‘ğ‘¤3
31
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
Loss 
Function
âˆ’à·
ğ‘–
ğ‘¦ğ‘–ğ‘™ğ‘œğ‘”à·œğ‘¦
ğ‘š11
ğ‘š21
ğ‘¤12
ğ‘¤21
ğ‘¤31
ğ‘š12
ğ‘ğ‘š1
ğ‘š22
ğ‘ğ‘š2
ğ‘¤11
ğ‘ğ‘¤1
ğ‘¤22
ğ‘ğ‘¤2
ğ‘¤32
ğ‘ğ‘¤3
= 0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ’= ğ’ğŸ 
ğ’2
=
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ’˜= ğ’˜1 
ğ’˜2 
ğ’˜3
ğ’ƒğ’= 0.0
0.0
ğ’ƒğ’˜=
0.0
0.0
0.0
ğ’š=
1
0
0
ğ’™= 1.5
0.2
ğ’‰= 1.372
âˆ’1.68
ğ‘ğğ‹ğ”= 1.372
0.0
ğ’›=
0.439
0.343
0.192
à·ğ’š=
0.372
0.338
0.290
loss = âˆ’logà·œy1 = 0.989
Forward pass
zero value
32
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
Loss 
Function
âˆ’à·
ğ‘–
ğ‘¦ğ‘–ğ‘™ğ‘œğ‘”à·œğ‘¦ğ‘–
ğ‘š11
ğ‘š21
ğ‘¤12
ğ‘¤21
ğ‘¤31
ğ‘š12
ğ‘ğ‘š1
ğ‘š22
ğ‘ğ‘š2
ğ‘¤11
ğ‘ğ‘¤1
ğ‘¤22
ğ‘ğ‘¤2
ğ‘¤32
ğ‘ğ‘¤3
ğœ•ğ¿
ğœ•ğ‘§ğ‘–
= à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
ğœ•ğ¿
ğœ•ğ‘¤ğ‘–ğ‘—
= ğ‘¥ğ‘—
ğœ•ğ¿
ğœ•ğ‘§ğ‘–
ğœ•ğ¿
ğœ•ğ‘ğ‘¤ğ‘–
= ğœ•ğ¿
ğœ•ğ‘§ğ‘–
ReLU â€² â„ğ‘—= àµ0 
if â„ğ‘—â‰¤0
1 
if â„ğ‘—> 0
ğœ•ğ¿
ğœ•â„ğ‘—
= àµ
 0 
if â„ğ‘—â‰¤0
ğœ•ğ¿
ğœ•ğ‘Ÿğ‘’ğ‘™ğ‘¢ğ‘—
 
if â„ğ‘—> 0
ğœ•ğ¿
ğœ•ğ‘Ÿğ‘’ğ‘™ğ‘¢ğ‘—
= à·
ğ‘–
ğ‘¤ğ‘–ğ‘—
ğœ•ğ¿
ğœ•ğ‘§ğ‘–
ğœ•ğ¿
ğœ•ğ‘šğ‘—ğ‘˜
= ğ‘¥ğ‘˜
ğœ•ğ¿
ğœ•â„ğ‘—
ğœ•ğ¿
ğœ•ğ‘ğ‘šğ‘—
= ğœ•ğ¿
ğœ•â„ğ‘—
Backward 
pass
33
ğ’= 0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ’˜=
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ’ƒğ’= 0.0
0.0
ğ’ƒğ’˜=
0.0
0.0
0.0
ğ’™= 1.5
0.2
ğ’‰= 1.372
âˆ’1.68
ğ‘ğğ‹ğ”= 1.372
0.0
ğ’›=
0.439
0.343
0.192
à·ğ’š=
0.372
0.338
0.290
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
Loss 
Function
âˆ’à·
ğ‘–
ğ‘¦ğ‘–ğ‘™ğ‘œğ‘”à·œğ‘¦
ğ‘š11
ğ‘š21
ğ‘¤12
ğ‘¤21
ğ‘¤31
ğ‘š12
ğ‘ğ‘š1
ğ‘š22
ğ‘ğ‘š2
ğ‘¤11
ğ‘ğ‘¤1
ğ‘¤22
ğ‘ğ‘¤2
ğ‘¤32
ğ‘ğ‘¤3
loss = 0.989
ğœ•ğ¿
ğœ•ğ‘¤ğ‘–ğ‘—
= ğ‘¥ğ‘—
ğœ•ğ¿
ğœ•ğ‘§ğ‘–
ğœ•ğ¿
ğœ•ğ‘§ğ‘–
= à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
ğ›ğ’›ğ¿=
âˆ’0.628
0.338
0.290
ğ›ğ’˜ğ¿= âˆ’0.628 
0.338 
0.29
0.0 
0.0 
0.0
ğœ•ğ¿
ğœ•ğ‘ğ‘¤ğ‘–
= ğœ•ğ¿
ğœ•ğ‘§ğ‘–
ğ›ğ’ƒğ’˜ğ¿=
âˆ’0.628
0.338
0.290
ğœ•ğ¿
ğœ•ğ‘Ÿğ‘’ğ‘™ğ‘¢ğ‘—
= à·
ğ‘–
ğ‘¤ğ‘–ğ‘—
ğœ•ğ¿
ğœ•ğ‘§ğ‘–
ğ›ğ‘ğğ‹ğ”ğ¿=
âˆ’0.0759
. âˆ’0.0445
Backward 
pass
ğ’= 0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ’˜=
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ’ƒğ’= 0.0
0.0
ğ’ƒğ’˜=
0.0
0.0
0.0
ğ’™= 1.5
0.2
ğ’‰= 1.372
âˆ’1.68
ğ‘ğğ‹ğ”= 1.372
0.0
ğ’›=
0.439
0.343
0.192
à·ğ’š=
0.372
0.338
0.290
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
Loss 
Function
âˆ’à·
ğ‘–
ğ‘¦ğ‘–ğ‘™ğ‘œğ‘”à·œğ‘¦
ğ‘š11
ğ‘š21
ğ‘¤12
ğ‘¤21
ğ‘¤31
ğ‘š12
ğ‘ğ‘š1
ğ‘š22
ğ‘ğ‘š2
ğ‘¤11
ğ‘ğ‘¤1
ğ‘¤22
ğ‘ğ‘¤2
ğ‘¤32
ğ‘ğ‘¤3
loss = 0.989
ğœ•ğ¿
ğœ•ğ‘šğ‘—ğ‘˜
= ğ‘¥ğ‘˜
ğœ•ğ¿
ğœ•â„ğ‘—
ğ›ğ’ğ¿= âˆ’0.114 
0.0
âˆ’0.015 0.0
ğœ•ğ¿
ğœ•ğ‘ğ‘šğ‘—
= ğœ•ğ¿
ğœ•â„ğ‘—
ğ›ğ’ƒğ’ğ¿= âˆ’0.0759
0.0
ğœ•ğ¿
ğœ•â„ğ‘—
= àµ
 0 
if â„ğ‘—â‰¤0
ğœ•ğ¿
ğœ•ğ‘Ÿğ‘’ğ‘™ğ‘¢ğ‘—
 
if â„ğ‘—> 0
ğ›ğ¡ğ¿= âˆ’0.0759
0.0
ğœ•ğ¿
ğœ•ğ‘Ÿğ‘’ğ‘™ğ‘¢ğ‘—
= à·
ğ‘–
ğ‘¤ğ‘–ğ‘—
ğœ•ğ¿
ğœ•ğ‘§ğ‘–
ğ›ğ‘ğğ‹ğ”ğ¿= âˆ’0.0759
âˆ’0.0445
Backward 
pass
ğ’= 0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ’˜=
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ’ƒğ’= 0.0
0.0
ğ’ƒğ’˜=
0.0
0.0
0.0
ğ›ğ’ƒğ’ğ¿= âˆ’0.0759
0.0
ğ›ğ’ğ¿= âˆ’0.114 
0.0
âˆ’0.015 0.0
ğ›ğ’˜ğ¿= âˆ’0.628 
0.338 0.29
0.0 
0.0 
0.0
ğ›ğ’ƒğ’˜ğ¿=
âˆ’0.628
0.338
0.290
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
Loss 
Function
âˆ’à·
ğ‘–
ğ‘¦ğ‘–ğ‘™ğ‘œğ‘”à·œğ‘¦
ğ‘š11
ğ‘š21
ğ‘¤12
ğ‘¤21
ğ‘¤31
ğ‘š12
ğ‘ğ‘š1
ğ‘š22
ğ‘ğ‘š2
ğ‘¤11
ğ‘ğ‘¤1
ğ‘¤22
ğ‘ğ‘¤2
ğ‘¤32
ğ‘ğ‘¤3
loss = 0.989
Update the parameters with ğœ‚= 0.01
ğ’= 0.861 
âˆ’1.04
0.4105 âˆ’0.65
ğ’˜= 0.328 
0.245 
0.136
âˆ’0.47 âˆ’1.06 0.063
ğ’ƒğ’= 0.000759
0.0
ğ’ƒğ’˜=
 0.0062
âˆ’0.0033
âˆ’0.0029
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
Loss 
Function
âˆ’à·
ğ‘–
ğ‘¦ğ‘–ğ‘™ğ‘œğ‘”à·œğ‘¦
ğ‘š11
ğ‘š21
ğ‘¤12
ğ‘¤21
ğ‘¤31
ğ‘š12
ğ‘ğ‘š1
ğ‘š22
ğ‘ğ‘š2
ğ‘¤11
ğ‘ğ‘¤1
ğ‘¤22
ğ‘ğ‘¤2
ğ‘¤32
ğ‘ğ‘¤3
ğ’š=
1
0
0
= 0.861 
âˆ’1.04
0.4105 âˆ’0.65
ğ’= ğ’ğŸ 
ğ’2
= 0.328 
0.245 
0.136
âˆ’0.47 âˆ’1.06 0.063
ğ’˜= ğ’˜1 
ğ’˜2 
ğ’˜3
ğ’ƒğ’= 0.000759
0.0
ğ’ƒğ’˜=
 0.0062
âˆ’0.0033
âˆ’0.0029
ğ’™= 1.5
0.2
ğ’‰= 1.374
âˆ’1.68
ğ‘ğğ‹ğ”= 1.374
0.0
ğ’›=
0.458
0.334
0.184
à·ğ’š=
0.378
0.334
0.287
loss = âˆ’logà·œy1 = 0.972
Forward pass again
still zero value
37
Example 3 - Zero Initialization
Diagram
Model
Input
Label
Loss
Parameters
ğ‘¥
ğ‘¤
ğ‘
à·œğ‘¦= ğ‘¤ğ‘¥+ ğ‘
(à·œğ‘¦âˆ’ğ‘¦)2
ğ‘¦
Cheat sheet
Compute the output à·œğ‘¦
Compute the loss
Compute derivative
Update parameters
à·œğ‘¦= ğ‘¤ğ‘¥+ ğ‘
ğ¿= (à·œğ‘¦âˆ’ğ‘¦)2
ğ¿ğ‘¤
â€² = 2ğ‘¥(à·œğ‘¦âˆ’ğ‘¦)
ğ¿ğ‘
â€² = 2(à·œğ‘¦âˆ’ğ‘¦)
ğ‘¤= ğ‘¤âˆ’ğœ‚ğ¿ğ‘¤
â€²
ğ‘= ğ‘âˆ’ğœ‚ğ¿ğ‘
â€²
â– Linear regression
AI VIETNAM
All-in-One Course
38
Example 3 - Zero Initialization
AI VIETNAM
All-in-One Course
Given
sample
data
Model
ğ‘¥ = 6.7
ğ‘= 0.0
w = 0.0
ğ‘¦ = 9.1
à·œğ‘¦= ğ‘¥ğ‘¤+ ğ‘ = 0.0 
Input
Label
Loss
à·œğ‘¦âˆ’ğ‘¦2 = 82.81
Parameters
Forward 
propagation
House price prediction
Initialize 
b=0.0 and 
w=0.0
Feature
Label
1
39
Forward 
propagation
New w and b help 
the loss reduce
Model
ğ‘¥ = 0.67
ğ‘¦ = 9.1
à·œğ‘¦= ğ‘¥ğ‘¤+ ğ‘ = 8.351 
Input
Label
Loss
Parameters
ğ‘= ğ‘âˆ’ğœ‚ğ¿â€²b
à·œğ‘¦âˆ’ğ‘¦2 = 0.559
ğ‘= 0.182
ğ‘¤ = 1.2194
w = w âˆ’ğœ‚ğ¿â€²w
3
Model
ğ‘¥ = 0.67
ğ‘= 0.0
ğ‘¤ = 0.0
ğ‘¦ = 9.1
à·œğ‘¦= ğ‘¥ğ‘¤+ ğ‘ = 0.0 
Input
Label
Loss
Parameters
Backpropagation
ğ‘= ğ‘âˆ’ğœ‚ğ¿â€²b
w = w âˆ’ğœ‚ğ¿â€²w
à·œğ‘¦âˆ’ğ‘¦2 = 82.81
ğ¿ğ‘¤
â€² = 2ğ‘¥à·œğ‘¦âˆ’ğ‘¦
 = âˆ’121.94
ğ¿ğ‘
â€² = 2 à·œğ‘¦âˆ’ğ‘¦
 = âˆ’18.2
ğœ‚= 0.01
2
ğ‘= ğ‘âˆ’ğœ‚ğ¿â€²b = 0.182
w = w âˆ’ğœ‚ğ¿â€²w = 1.2194
40
Example 4 - Zero Initialization
4) Compute derivative
5) Update parameters
1) Pick a sample (ğ‘¥, ğ‘¦) from training data   
2) Compute output à·œğ‘¦
3) Compute loss
à·œğ‘¦= ğœ(ğ‘§) =
1
1 + ğ‘’âˆ’ğ‘§
ğ¿(ğœ½) = âˆ’ylogà·œyâˆ’(1âˆ’y)log(1âˆ’à·œy )
âˆ‡ğœ½ğ¿= ğ±(à·œy âˆ’ğ‘¦)
ğœ½= ğœ½âˆ’ğœ‚ğ¿ğœ½
â€²
ğœ‚is learning rate
ğ‘§= ğœ½ğ‘‡ğ’™
ğœ½ğ‘‡ = [ğ‘ ğ‘¤1 ğ‘¤2]
ğ’™ğ‘‡ = [1 ğ‘¥1 ğ‘¥2]
Model
Label
Loss
ğ‘¥1
âˆ’ylogà·œyâˆ’(1âˆ’y)log(1âˆ’à·œy )
ğ‘¦
ğ‘¥2
à·œğ‘¦= ğœ(ğ‘§) =
1
1 + ğ‘’âˆ’ğ‘§
ğ‘§= ğ‘¤1ğ‘¥1 + ğ‘¤2ğ‘¥2 + ğ‘
ğ‘¤1
ğ‘
ğ‘¤2
AI VIETNAM
All-in-One Course
â– Logistic regression
41
Example 4 - Zero Initialization
Model
Label
Loss
ğ‘¥1
0.0
0.0
ğ‘¦
ğ‘¥2
0.0
ğ‘¥1 = 1.4
ğ‘¥2 = 0.2
ğ‘§= 0.0
à·œğ‘¦= 0.5
ğ‘¦= 0
ğ¿= 0.693
ğ‘¤1
ğ‘
ğ‘¤2
à·œğ‘¦= ğœ(ğ‘§) =
1
1 + ğ‘’âˆ’ğ‘§
ğ‘§= ğ‘¤1ğ‘¥1 + ğ‘¤2ğ‘¥2 + ğ‘
âˆ’ylogà·œyâˆ’(1âˆ’y)log(1âˆ’à·œy )
AI VIETNAM
All-in-One Course
ğ’™ =
1
1.4
0.2
ğ’š= 0
Dataset
42
Example 4 - Zero Initialization
Model
Loss
ğ‘¥1
0.0
0.0
ğ‘§= ğ‘¤1ğ‘¥1 + ğ‘¤2ğ‘¥2 + ğ‘
ğ‘¦
à·œğ‘¦= ğœ(ğ‘§) =
1
1 + ğ‘’âˆ’ğ‘§
ğ‘¥2
0.0
ğœ‚= 0.01
ğ‘¤1
ğ‘
ğ‘¤2
ğ¿ğœ½
â€² = ğ±(à·œy âˆ’ğ‘¦)
=
1
1.4
0.2
0.5
=
0.5
0.7
0.1
=
ğ¿ğ‘
â€²
ğ¿ğ‘¤1
â€²
ğ¿ğ‘¤2
â€²
ğ‘= 0.005
ğ‘¤1= 0.007
ğ‘¤2= 0.001
ğ¿ğ‘
â€²
ğ¿ğ‘¤1
â€²
ğ¿ğ‘¤2
â€²
ğ‘§= 0.0
à·œğ‘¦= 0.5
ğ‘¦= 0
ğ¿= 0.693
âˆ’ylogà·œyâˆ’(1âˆ’y)log(1âˆ’à·œy )
ğ‘¥1 = 1.4
ğ‘¥2 = 0.2
AI VIETNAM
All-in-One Course
ğ’™ =
1
1.4
0.2
ğ’š= 0
Dataset
43
Example 4 - Zero Initialization
Model
Loss
ğ‘¥1
0.0
0.0
ğ‘§= ğ‘¤1ğ‘¥1 + ğ‘¤2ğ‘¥2 + ğ‘
ğ‘¦
à·œğ‘¦= ğœ(ğ‘§) =
1
1 + ğ‘’âˆ’ğ‘§
ğ‘¥2
0.0
ğœ‚= 0.01
ğ‘¤1
ğ‘
ğ‘¤2
ğ¿ğ‘
â€²
ğ¿ğ‘¤1
â€²
ğ¿ğ‘¤2
â€²
à·œğ‘¦= 0.6856
ğ¿= 1.1573
âˆ’ylogà·œyâˆ’(1âˆ’y)log(1âˆ’à·œy )
ğ‘§= 0.78
ğ‘¥1 = 1.4
ğ‘¥2 = 0.2
ğ‘¦= 0
AI VIETNAM
All-in-One Course
ğ’™ =
1
1.4
0.2
ğ’š= 0
Dataset
ğ¿ğœ½
â€² = ğ±(à·œy âˆ’ğ‘¦)
=
1
1.4
0.2
0.5
=
0.5
0.7
0.1
=
ğ¿ğ‘
â€²
ğ¿ğ‘¤1
â€²
ğ¿ğ‘¤2
â€²
ğ‘= âˆ’0.005
ğ‘¤1= âˆ’0.007
ğ‘¤2= âˆ’0.001
44
Example 4 - Zero Initialization
ğ’™ =
1
1.4
0.2
ğ’š= 0
Dataset
AI VIETNAM
All-in-One Course
Model
Loss
ğ‘¥1
ğ‘§= ğ‘¤1ğ‘¥1 + ğ‘¤2ğ‘¥2 + ğ‘
ğ‘¦
à·œğ‘¦= ğœ(ğ‘§) =
1
1 + ğ‘’âˆ’ğ‘§
ğ‘¥2
ğ‘¤1
ğ‘
ğ‘¤2
à·œğ‘¦= 0.49
ğ¿= 0.68
âˆ’ylogà·œyâˆ’(1âˆ’y)log(1âˆ’à·œy )
ğ‘§= âˆ’0.016
previous ğ‘³= 1.1573
ğ‘¥1 = 1.4
ğ‘¥2 = 0.2
ğ‘¦= 0
âˆ’0.007
âˆ’0.005
âˆ’0.001
45
Example 5 - Zero Initialization
Model
Label
ğ‘¥
L = âˆ’ğ‘¦0logà·œğ‘¦0 âˆ’ğ‘¦1logà·œğ‘¦1
ğ‘§0 = ğ‘¤0ğ‘¥+ ğ‘0
ğ‘¤0
ğ‘0
ğ‘¦
ğ‘§1 = ğ‘¤1ğ‘¥+ ğ‘1
ğ‘¤1
ğ‘1
à·œğ‘¦0 =
ğ‘’ğ‘§0
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
à·œğ‘¦1 =
ğ‘’ğ‘§1
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
1
ğ‘¥
ğ‘§0
ğ‘§1
Softmax
à·œy0 = ğ‘ƒğ‘™ğ‘ğ‘ğ‘’ğ‘™= 0|ğ‘¥
à·œy1 = ğ‘ƒğ‘™ğ‘ğ‘ğ‘’ğ‘™= 1|ğ‘¥
Model
Feature
Label
Category A
Category B
Training 
data
One-hot 
encoding 
for labels
ğ‘¦= 0 â†’ğ’šğ‘‡= [1, 0]
ğ‘¦= 1 â†’ğ’šğ‘‡= [0, 1]
0 1
index
AI VIETNAM
All-in-One Course
â– Softmax regression
46
Example 5 - Zero Initialization
AI VIETNAM
All-in-One Course
Model
Label
ğ‘¥
L = âˆ’ğ‘¦0logà·œğ‘¦0 âˆ’ğ‘¦1logà·œğ‘¦1
ğ‘§0 = ğ‘¤0ğ‘¥+ ğ‘0
ğ‘¤0
ğ‘0
ğ‘¦
ğ‘§1 = ğ‘¤1ğ‘¥+ ğ‘1
ğ‘¤1
ğ‘1
à·œğ‘¦0 =
ğ‘’ğ‘§0
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
à·œğ‘¦1 =
ğ‘’ğ‘§1
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
ğ‘¥= 1.4
ğ’š= 1
0
Feature
Label
Training data
One-hot encoding for label
ğ‘¦= 0 â†’ğ’šğ‘‡= [1 0]
ğ‘¦= 1 â†’ğ’šğ‘‡= [0 1]
ğ‘¦0 ğ‘¦1
#class=2
#feature=1
ğ‘¥, ğ‘¦= 1.4, 0
Training example
47
Example 5 - Zero Initialization
Feature
Label
Training data
#class=2
#feature=1
One-hot encoding for label
ğ‘¦= 0 â†’ğ’šğ‘‡= [1 0]
ğ‘¦= 1 â†’ğ’šğ‘‡= [0 1]
ğ‘¦0 ğ‘¦1
ğ‘¥, ğ‘¦= 1.4, 0
Training example
ğ‘¥
L = âˆ’ğ‘¦0logà·œğ‘¦0 âˆ’ğ‘¦1logà·œğ‘¦1
ğ‘§0 = ğ‘¤0ğ‘¥+ ğ‘0
0.0
0.0
ğ‘¦
ğ‘§1 = ğ‘¤1ğ‘¥+ ğ‘1
0.0
0.0
à·œğ‘¦0 =
ğ‘’ğ‘§0
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
à·œğ‘¦1 =
ğ‘’ğ‘§1
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
ğ’™= 1.4
ğ‘¤0
ğ‘0
ğ‘¤1
ğ‘1
ğ’›0 = 0.0
ğ’›1 = 0.0
à·ğ’š0 = 0.5
à·ğ’š1 = 0.5
ğ¿= âˆ’log0.5 = 0.693
ğ’š= 1
0
AI VIETNAM
All-in-One Course
48
Example 5 - Zero Initialization
AI VIETNAM
All-in-One Course
ğ‘¦= 0 â†’ğ’šğ‘‡= [1 0]
ğ‘¦= 1 â†’ğ’šğ‘‡= [0 1]
ğ‘¦0 ğ‘¦1
ğœ•ğ¿
ğœ•ğ’›0
= à·œğ‘¦0 âˆ’1
= 0.5 âˆ’1 = âˆ’0.5
ğœ•ğ¿
ğœ•ğ‘§ğ‘–
= à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
ğœ•ğ¿
ğœ•ğ‘¤ğ‘–
= ğ‘¥à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
ğœ•ğ¿
ğœ•ğ‘ğ‘–
= à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
Derivative
ğœ•ğ¿
ğœ•ğ’›1
= à·œğ‘¦1 âˆ’0 = 0.5
ğ‘¥
L = âˆ’ğ‘¦0logà·œğ‘¦0 âˆ’ğ‘¦1logà·œğ‘¦1
ğ‘§0 = ğ‘¤0ğ‘¥+ ğ‘0
0.0
0.0
ğ‘¦
ğ‘§1 = ğ‘¤1ğ‘¥+ ğ‘1
0.0
0.0
à·œğ‘¦0 =
ğ‘’ğ‘§0
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
à·œğ‘¦1 =
ğ‘’ğ‘§1
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
ğ‘¤0
ğ‘0
ğ‘¤1
ğ‘1
ğœ•ğ‘³
ğœ•ğ’›0
= âˆ’0.5
ğœ•ğ‘³
ğœ•ğ’›1
= 0.5
ğ’™= 1.4
à·ğ’š0 = 0.5
à·ğ’š1 = 0.5
ğ¿= âˆ’log0.5 = 0.693
ğ’š= 1
0
49
Example 5 - Zero Initialization
AI VIETNAM
All-in-One Course
ğœ•ğ‘³
ğœ•ğ‘0
=
à·œğ‘¦0 âˆ’1 = âˆ’0.5
ğœ•ğ¿
ğœ•ğ‘§ğ‘–
= à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
ğœ•ğ¿
ğœ•ğ‘¤ğ‘–
= ğ‘¥à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
ğœ•ğ¿
ğœ•ğ‘ğ‘–
= à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
Derivative
ğœ•ğ‘³
ğœ•ğ‘1
=
à·œğ‘¦1 âˆ’0 = 0.5
ğ‘¦= 0 â†’ğ’šğ‘‡= [1 0]
ğ‘¦= 1 â†’ğ’šğ‘‡= [0 1]
ğ‘¦0 ğ‘¦1
ğ‘¥
L = âˆ’ğ‘¦0logà·œğ‘¦0 âˆ’ğ‘¦1logà·œğ‘¦1
ğ‘§0 = ğ‘¤0ğ‘¥+ ğ‘0
0.0
0.0
ğ‘¦
ğ‘§1 = ğ‘¤1ğ‘¥+ ğ‘1
0.0
0.0
à·œğ‘¦0 =
ğ‘’ğ‘§0
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
à·œğ‘¦1 =
ğ‘’ğ‘§1
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
ğ‘¤0
ğ‘0
ğ‘¤1
ğ‘1
ğœ•ğ‘³
ğœ•ğ‘0
= âˆ’0.5
ğœ•ğ‘³
ğœ•ğ‘1
= 0.5
ğ’™= 1.4
à·ğ’š0 = 0.5
à·ğ’š1 = 0.5
ğ¿= âˆ’log0.5 = 0.693
ğ’š= 1
0
50
Example 5 - Zero Initialization
AI VIETNAM
All-in-One Course
ğœ•ğ¿
ğœ•ğ‘§ğ‘–
= à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
ğœ•ğ¿
ğœ•ğ‘¤ğ‘–
= ğ‘¥à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
ğœ•ğ¿
ğœ•ğ‘ğ‘–
= à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
Derivative
ğ‘¦= 0 â†’ğ’šğ‘‡= [1 0]
ğ‘¦= 1 â†’ğ’šğ‘‡= [0 1]
ğ‘¦0 ğ‘¦1
ğœ•ğ‘³
ğœ•ğ‘¤0
= ğ‘¥(à·œğ‘¦0 âˆ’1 )
= âˆ’0.5âˆ—1.4=âˆ’0.7
ğœ•ğ‘³
ğœ•ğ‘¤1
= ğ‘¥(à·œğ‘¦1 âˆ’0 )
= 0.5âˆ—1.4=0.7
ğ‘¥
L = âˆ’ğ‘¦0logà·œğ‘¦0 âˆ’ğ‘¦1logà·œğ‘¦1
ğ‘§0 = ğ‘¤0ğ‘¥+ ğ‘0
0.0
0.0
ğ‘¦
ğ‘§1 = ğ‘¤1ğ‘¥+ ğ‘1
0.0
0.0
à·œğ‘¦0 =
ğ‘’ğ‘§0
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
à·œğ‘¦1 =
ğ‘’ğ‘§1
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
ğ‘¤0
ğ‘0
ğ‘¤1
ğ‘1
ğœ•ğ‘³
ğœ•ğ‘¤0
= âˆ’0.7
ğœ•ğ‘³
ğœ•ğ‘¤0
= 0.7
ğœ•ğ‘³
ğœ•ğ‘0
= âˆ’0.5
ğœ•ğ‘³
ğœ•ğ‘1
= 0.5
ğ’™= 1.4
à·ğ’š0 = 0.5
à·ğ’š1 = 0.5
ğ¿= âˆ’log0.5 = 0.693
ğ’š= 1
0
51
Example 5 - Zero Initialization
AI VIETNAM
All-in-One Course
Update parameters
ğœ½= ğœ½âˆ’ğœ‚ğ¿ğœ½
â€²
ğœ‚ is learning rate
ğœ½= ğ‘0 ğ‘1
ğ‘¤0 ğ‘¤1
ğœ‚= 0.1
ğ¿ğœ½
â€² =
ğœ•ğ¿
ğœ•ğ‘0
 ğœ•ğ¿
ğœ•ğ‘1
ğœ•ğ¿
ğœ•ğ‘¤0
 
ğœ•ğ¿
ğœ•ğ‘¤1
ğœ½= 0.0 
0.0
0.0 
0.0 âˆ’0.01 âˆ’0.5 0.5
âˆ’0.7 0.7
= âˆ’0.005 0.005
âˆ’0.007 0.007
ğ‘¥
L = âˆ’ğ‘¦0logà·œğ‘¦0 âˆ’ğ‘¦1logà·œğ‘¦1
ğ‘§0 = ğ‘¤0ğ‘¥+ ğ‘0
âˆ’0.007
âˆ’0.005
ğ‘¦
ğ‘§1 = ğ‘¤1ğ‘¥+ ğ‘1
0.007
0.005
à·œğ‘¦0 =
ğ‘’ğ‘§0
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
à·œğ‘¦1 =
ğ‘’ğ‘§1
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
ğ‘¤0
ğ‘0
ğ‘¤1
ğ‘1
ğœ•ğ‘³
ğœ•ğ‘¤0
= âˆ’0.7
ğœ•ğ‘³
ğœ•ğ‘¤0
= 0.7
ğœ•ğ‘³
ğœ•ğ‘0
= âˆ’0.5
ğœ•ğ‘³
ğœ•ğ‘1
= 0.5
ğ’™= 1.4
à·ğ’š0 = 0.5
à·ğ’š1 = 0.5
ğ¿= âˆ’log0.5 = 0.693
ğ’š= 1
0
52
Example 5 - Zero Initialization
AI VIETNAM
All-in-One Course
Feature
Label
Training data
One-hot encoding for label
ğ‘¦= 0 â†’ğ’šğ‘‡= [1 0]
ğ‘¦= 1 â†’ğ’šğ‘‡= [0 1]
ğ‘¦0 ğ‘¦1
ğ‘¥, ğ‘¦= 1.4, 0
Training example
ğ‘¥
L = âˆ’ğ‘¦0logà·œğ‘¦0 âˆ’ğ‘¦1logà·œğ‘¦1
ğ‘§0 = ğ‘¤0ğ‘¥+ ğ‘0
ğ‘¦
ğ‘§1 = ğ‘¤1ğ‘¥+ ğ‘1
à·œğ‘¦0 =
ğ‘’ğ‘§0
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
à·œğ‘¦1 =
ğ‘’ğ‘§1
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
ğ‘¤0
ğ‘0
ğ‘¤1
ğ‘1
ğ’™= 1.4
à·ğ’š0 = 0.51
à·ğ’š1 = 0.49
ğ¿= âˆ’log0.51 = 0.678
ğ’›0 = 0.015
ğ’›1 = âˆ’0.015
ğ’š= 1
0
ğ’›0 = 0.0
ğ’›1 = 0.0
à·ğ’š0 = 0.5
à·ğ’š1 = 0.5
ğ¿= âˆ’log0.5 = 0.693
losses reduce!!!
âˆ’0.007
âˆ’0.005
0.007
0.005
53
Example 6 - Zero Initialization
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
Input layer
Hidden layer
Output layer
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
= 0.0 0.0
0.0 0.0
ğ’‰= ğ’‰ğŸ ğ’‰2
= 0.0 
0.0 
0.0
0.0 
0.0 
0.0
ğ’˜= ğ’˜1 ğ’˜2 ğ’˜3
ğ’ƒğ’‰= 0.0
0.0
ğ’ƒğ’˜=
0.0
0.0
0.0
Feature
Label
ğ’™=
ğ’™(1)
ğ’™(2)
ğ’™(3)
=
1.5 0.2
4.7 1.6
5.6 2.2
ğ’š=
0
1
2
AI VIETNAM
All-in-One Course
54
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
Loss 
Function
âˆ’à·
ğ‘–
ğ‘¦ğ‘–ğ‘™ğ‘œğ‘”à·œğ‘¦
ğ‘š11
ğ‘š21
ğ‘¤12
ğ‘¤21
ğ‘¤31
ğ‘š12
ğ‘ğ‘š1
ğ‘š22
ğ‘ğ‘š2
ğ‘¤11
ğ‘ğ‘¤1
ğ‘¤22
ğ‘ğ‘¤2
ğ‘¤32
ğ‘ğ‘¤3
= 0.0 
0.0
0.0 
0.0
ğ’= ğ’ğŸ 
ğ’2
= 0.0 
0.0 
0.0
0.0 
0.0 
0.0
ğ’˜= ğ’˜1 
ğ’˜2 
ğ’˜3
ğ’ƒğ’= 0.0
0.0
ğ’ƒğ’˜=
0.0
0.0
0.0
ğ’š=
1 0 0
0 1 0
0 0 1
ğ’™=
1.5 0.2
4.7 1.6
5.6 2.2
ğ’‰=
0.0 
0.0
0.0 
0.0
0.0 
0.0
ğ‘ğğ‹ğ”=
0.0 
0.0
0.0 
0.0
0.0 
0.0
ğ’›=
0.0 
0.0 
0.0
0.0 
0.0 
0.0
0.0 
0.0 
0.0
à·ğ’š=
0.333 0.333 0.333
0.333 0.333 0.333
0.333 0.333 0.333
loss =
âˆ’log0.333
âˆ’log0.333
âˆ’log0.333
55
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
Loss 
Function
âˆ’à·
ğ‘–
ğ‘¦ğ‘–ğ‘™ğ‘œğ‘”à·œğ‘¦
ğ‘š11
ğ‘š21
ğ‘¤12
ğ‘¤21
ğ‘¤31
ğ‘š12
ğ‘ğ‘š1
ğ‘š22
ğ‘ğ‘š2
ğ‘¤11
ğ‘ğ‘¤1
ğ‘¤22
ğ‘ğ‘¤2
ğ‘¤32
ğ‘ğ‘¤3
= 0.0 
0.0
0.0 
0.0
ğ’= ğ’ğŸ 
ğ’2
= 0.0 
0.0 
0.0
0.0 
0.0 
0.0
ğ’˜= ğ’˜1 
ğ’˜2 
ğ’˜3
ğ’ƒğ’= 0.0
0.0
ğ’ƒğ’˜=
ğ‘£
ğ‘£
ğ‘£
ğ’™=
1.5 0.2
4.7 1.6
5.6 2.2
ğ’‰=
0.0 
0.0
0.0 
0.0
0.0 
0.0
ğ‘ğğ‹ğ”=
0.0 
0.0
0.0 
0.0
0.0 
0.0
ğ’›=
0.0 
0.0 
0.0
0.0 
0.0 
0.0
0.0 
0.0 
0.0
à·ğ’š=
0.333 0.333 0.333
0.333 0.333 0.333
0.333 0.333 0.333
ğ’š=
1 0 0
0 1 0
0 0 1
loss =
âˆ’log0.333
âˆ’log0.333
âˆ’log0.333
56
Optimizers
AI VIETNAM
All-in-One Course
Optimizer Selection
https://www.kdnuggets.com/2019/06/gradient-
descent-algorithms-cheat-sheet.html
Define a way to update parameters
Data Preparation
Data 
Normalization
Model (Network) 
Construction
Parameter 
Initialization
Optimizer 
Selection
Loss function 
Selection
Metric Selection
57
Summary
Recommendation
AI VIETNAM
All-in-One Course
Data Preparation
Data 
Normalization
Model (Network) 
Construction
Parameter 
Initialization
Optimizer 
Selection
Loss function 
Selection
Metric Selection
[-1, 1]
ReLU Activation
Batch norm
He normal
Adam
58
Discussion
â– Sigmoid and SGD
â– W/o using normalization
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
1
Sigmoid 
activation
128 Nodes
Hidden layer
Fully 
connect
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
â€¦
â€¦
AI VIETNAM
All-in-One Course
59
Discussion
â– Sigmoid and SGD
â– W/o using normalization
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
7 hidden layers
Fully 
connect
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
â€¦
â€¦
AI VIETNAM
All-in-One Course
â€¦
60
Discussion
AI VIETNAM
All-in-One Course
2 hidden layers
5 hidden layers (!)
7 hidden layers
Discussion
AI VIETNAM
All-in-One Course
Tensorflow
62
Further Reading
AI VIETNAM
All-in-One Course
https://www.deeplearning.ai/ai-notes/initialization/index.html
https://towardsdatascience.com/the-dying-relu-problem-clearly-explained-42d0c54e0d24
Dying ReLU
Initialization
63

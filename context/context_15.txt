Multi-layer Perception
Quang-Vinh Dinh
Ph.D. in Computer Science
AI VIETNAM
All-in-One Course
â¢Image Data Loading Using Numpy&PyTorch
â¢Softmax+Normalization for Fashion-MNIST
â¢MLP and Examples
â¢Step-by-Step Implementation
â¢Training Strategy (optional)
Outline
Image Classification: Image Data
â– Grayscale images
AI VIETNAM
All-in-One Course
(Height, Width)
Pixel p = scalar
0 â‰¤p â‰¤255
Resolution: #pixels
Resolution = HeightxWidth
1
Image Classification: Image Data
â– Color images
AI VIETNAM
All-in-One Course
(Height, Width, channel)
Pixel p=
ğ‘Ÿ
ğ‘”
ğ‘
0 â‰¤r,g,b â‰¤255
RGB color image
Resolution: #pixels
Resolution = HeightxWidth
2
Important Packages
â– Some functions
import urllib.request as req
req.urlretrieve(url, name)
To download a file
from PIL import Image
img = Image.open(name)
To open an image
import matplotlib.pyplot as plt
plt.imshow(img)
To show an image
3
MNIST dataset
Image Data
Grayscale images
Resolution=28x28
Training set: 60000 samples
Testing set: 10000 samples
4
MNIST dataset
Image Data
Grayscale images
Resolution=28x28
Training set: 60000 samples
Testing set: 10000 samples
http://yann.lecun.com/exdb/mnist/
5
T-shirt
Trouser
Pullover
Dress
Coat
Sandal
Shirt
Sneaker
Bag
Ankle
Boot
Image Data
Fashion-MNIST dataset
Grayscale images
Resolution=28x28
Training set: 60000 samples
Testing set: 10000 samples
Image Classification
AI VIETNAM
All-in-One Course
Download data
Fashion-MNIST dataset
Grayscale images
Resolution=28x28
Training set: 60000 samples
Testing set: 10000 samples
28
28
784
7
Image Data
Fashion-MNIST data
AI VIETNAM
All-in-One Course
Download data
28
28
784
Demo
8
Image Data
â– Using Pytorch
AI VIETNAM
All-in-One Course
data 
(ndarray, tensor)
data 
(ndarray, tensor)
Size
Mode
â€¦
â€¦
9
Fashion MNIST
â– Using Pytorch
â€¦
â€¦
â€¦
â€¦
60000 samples
Each sample is a tuple (PIL image, label)
AI VIETNAM
All-in-One Course
10
Fashion MNIST
â– Using Pytorch
â€¦
â€¦
â€¦
â€¦
60000 samples
Each sample is a tuple (image tensor, label)
AI VIETNAM
All-in-One Course
11
Fashion MNIST
â– Using Pytorch
approximately
â€¦
â€¦
â€¦
â€¦
1024 samples
Each sample is a tuple (image tensor, label)
â€¦
â€¦
â€¦
â€¦
1024 samples
â€¦
â€¦
â€¦
Batch index 0
Batch index n
AI VIETNAM
All-in-One Course
Fashion MNIST
â– Using Pytorch
â€¦
â€¦
â€¦
â€¦
1024 samples
Each sample is a tuple 
(image tensor, label)
â€¦
â€¦
â€¦
â€¦
1024 samples
â€¦
â€¦
â€¦
Batch index 0
Batch index n
AI VIETNAM
All-in-One Course
â¢Image Data Loading Using Numpy&PyTorch
â¢Softmax+Normalization for Fashion-MNIST
â¢MLP and Examples
â¢Step-by-Step Implementation
â¢Training Strategy (optional)
Outline
Softmax Regression
ğ‘§0 = ğ‘¥ğ‘¤0 + ğ‘0
ğ‘§1 = ğ‘¥ğ‘¤1 + ğ‘1
à·œy0 =
ğ‘’ğ‘§0
Ïƒğ‘—=0
1
ğ‘’ğ‘§ğ‘—
à·œy1 =
ğ‘’ğ‘§1
Ïƒğ‘—=0
1
ğ‘’ğ‘§ğ‘—
ğ’›= ğ‘§0
ğ‘§1 = ğ‘0 ğ‘¤0
ğ‘1 ğ‘¤1
1
ğ‘¥= ğœ½0
ğ‘‡
ğœ½1
ğ‘‡
1
ğ‘¥= ğœ½ğ‘‡ğ’™
à·œğ²= à·œy0
à·œy1 =
1
Ïƒğ‘—=0
1
ğ‘’ğ‘§ğ‘—
ğ‘’ğ‘§0
ğ‘’ğ‘§1 =
ğ‘’ğ’›
Ïƒğ‘—=0
1
ğ‘’ğ‘§ğ‘—
ğ¿ğœ½= âˆ’à·
ğ‘–=0
1
ğ‘¦ğ‘–logà·œğ‘¦ğ‘–= âˆ’ğ’šğ‘‡ğ‘™ğ‘œğ‘”à·ğ’š
1
ğ‘¤1
à·œy0
ğ‘¥
Softmax
function
ğ‘¤0
ğ‘0
ğ‘¤1
ğ‘1
à·œy1
Model
ğ‘§0
ğ‘§1
Derivative
ğœ•ğ¿
ğœ•ğ‘§ğ‘–
= à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
ğœ•ğ¿
ğœ•ğ‘¤ğ‘–
= ğ‘¥à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
ğœ•ğ¿
ğœ•ğ‘ğ‘–
= à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
ğœ•à·œğ‘¦ğ‘–
ğœ•ğ‘§ğ‘—
= àµà·œğ‘¦ğ‘–1 âˆ’à·œğ‘¦ğ‘– ğ‘–ğ‘“ ğ‘–= ğ‘—
âˆ’à·œğ‘¦ğ‘–à·œğ‘¦ğ‘— 
ğ‘–ğ‘“ ğ‘–â‰ ğ‘— 
ğœ•ğ¿
ğœ•à·œğ‘¦ğ‘–
= âˆ’ğ‘¦ğ‘–
à·œğ‘¦ğ‘–
One-hot encoding for label
ğ‘¦= 0 â†’ğ’šğ‘‡= [1 0]
ğ‘¦= 1 â†’ğ’šğ‘‡= [0 1]
ğ‘¦0 ğ‘¦1
vector
scalar
ğ’™= 1
ğ‘¥
ğœ½=
ğ‘0 ğ‘1
ğ‘¤0 ğ‘¤1
Where to 
put Flatten
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
Normalization
Fully 
connect
256 Nodes
Hidden layer
1
. . .
15
Where to put Flatten
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
Normalization
Fully 
connect
256 Nodes
Hidden layer
1
. . .
16
784 Nodes
Flatten
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
Fully 
connect
10 Nodes
Output layer
28
28
. . .
. . .
Normalization
Fully 
connect
256 Nodes
Hidden layer
1
. . .
28x28
Input Layer
Where to 
put Flatten
17
Softmax 
Regression
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
Data Sets
without 
normalization
learning rate = 0.01
Case 1
18
Softmax 
Regression
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
Data Sets
without 
normalization
learning rate = 0.00001
Case 2
20
Softmax Regression 
+ Normalization
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
Normalization-1
Image = Image
255
Case 3
22
Softmax Regression 
+ Normalization
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
Normalization-1
Image = Image
127.5 âˆ’1
Case 4
24
Softmax Regression 
+ Normalization
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
Normalization-2
Image = Image âˆ’Î¼
Ïƒ
Case 5
26
â¢Image Data Loading Using Numpy&PyTorch
â¢Softmax+Normalization for Fashion-MNIST
â¢MLP and Examples
â¢Step-by-Step Implementation
â¢Training Strategy (optional)
Outline
MLP - Motivation
â– More parameters â†’ better capacity (~stronger model)
AI VIETNAM
All-in-One Course
â–John Von Neumann's quote â€œwith four parameters I can fit an elephant, with five 
I can make him wiggle his trunkâ€
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
Normalization
28
Multi-layer Perceptron
â– An idea: More parameters â†’ better capacity (~stronger model)
â– Adding more layers
AI VIETNAM
All-in-One Course
Input layer
Output layer
Output
1
ğ‘§1
ğ‘§2
ğ‘§3
activation
Input
1
. . .
. . .
Fully connect
activation
called Hidden Layers
#hidden layers is arbitrary
#nodes in a hidden layer is arbitrary
28
Multi-layer Perceptron
â– ReLU function
AI VIETNAM
All-in-One Course
ReLU ğ‘¥= á‰Š0 
if ğ‘¥< 0
ğ‘¥ 
if ğ‘¥â‰¥0
ğ‘¥
ğ‘…ğ‘’ğ¿ğ‘ˆ(ğ‘¥)
30
Multi-layer Perceptron
An instance
AI VIETNAM
All-in-One Course
Input layer
Output
1
ğ‘§1
ğ‘§2
ğ‘§3
Softmax 
activation
Input
1
ReLU 
activation
Hidden layer
Fully 
connect
Fully 
connect
Ouptut layer
Multi-layer Perceptron
AI VIETNAM
All-in-One Course
Input layer
Output
1
ğ‘§1
ğ‘§2
ğ‘§3
Softmax 
activation
Input
1
ReLU 
activation
Hidden layer 1
Fully 
connect
Fully 
connect
1
ReLU 
activation
Hidden layer 2
Fully 
connect
Ouptut layer
32
Back to 
Fashion-MNIST
Image = Image
255.0
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
Normalization
Fully 
connect
256 Nodes
Hidden layer
1
. . .
33
MLP Example
AI VIETNAM
All-in-One Course
Feature
Label
ğ’™=
ğ’™(1)
ğ’™(2)
ğ’™(3)
=
1.5 0.2
4.7 1.6
5.6 2.2
ğ’š=
0
1
2
=
0.0 
0.0
0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ‘¾â„= ğ‘¾ğ’‰1 ğ‘¾â„2
=
0.0 
0.0 
0.0
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ‘¾ğ‘§= ğ‘¾ğ’›1 ğ‘¾ğ‘§2 ğ‘¾ğ‘§3
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
Input layer
Hidden layer
Ouptut layer
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
34
ğ’‰= ğ’™ğ‘¾â„=
1 1.5 0.2
1 4.7 1.6
1 5.6 2.2
0.0 
0.0
0.86 
âˆ’1.04
0.41 âˆ’0.65
=
1.373 
âˆ’1.696
4.708 
âˆ’5.951
5.731 
âˆ’7.281
ReLU(ğ’‰) =
1.373 
0
4.708 
0
5.731 
0
Feature
Label
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
Input layer
Hidden layer
Ouptut layer
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
=
0.0 
0.0
0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ‘¾â„= ğ‘¾ğ’‰1 ğ‘¾â„2
=
0.0 
0.0 
0.0
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ‘¾ğ‘§= ğ‘¾ğ’›1 ğ‘¾ğ‘§2 ğ‘¾ğ‘§3
ğ’™=
ğ’™(1)
ğ’™(2)
ğ’™(3)
=
1 1.5 0.2
1 4.7 1.6
1 5.6 2.2
ğ’š=
0
1
2
35
ReLU(ğ’‰) =
1.373 
0
4.708 
0
5.731 
0
ğŸ ReLU(ğ’‰) =
1 1.373 
0
1 4.708 
0
1 5.731 
0
ğ’›= ğŸ ReLU(ğ’‰) ğ‘¾ğ‘§=
1 1.373 
0
1 4.708 
0
1 5.731 
0
0.0 
0.0 
0.0
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
=
0.439 0.356 0.195
1.507 1.220 0.670
1.835 1.485 0.816
Feature
Label
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
Input layer
Hidden layer
Ouptut layer
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
=
0.0 
0.0
0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ‘¾â„= ğ‘¾ğ’‰1 ğ‘¾â„2
=
0.0 
0.0 
0.0
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ‘¾ğ‘§= ğ‘¾ğ’›1 ğ‘¾ğ‘§2 ğ‘¾ğ‘§3
ğ’™=
ğ’™(1)
ğ’™(2)
ğ’™(3)
=
1 1.5 0.2
1 4.7 1.6
1 5.6 2.2
ğ’š=
0
1
2
36
loss = 1.269
Feature
Label
1
Softmax
ğ‘¥1
ğ‘¥2
1
ReLU
ReLU
Input layer
Hidden layer
Ouptut layer
à·œy1
à·œy2
à·œy3
ğ‘§1
ğ‘§2
ğ‘§3
â„1
â„2
=
0.0 
0.0
0.86 
âˆ’1.04
0.41 âˆ’0.65
ğ‘¾â„= ğ‘¾ğ’‰1 ğ‘¾â„2
=
0.0 
0.0 
0.0
0.32 
0.25 
0.14
âˆ’0.47 âˆ’1.06 0.063
ğ‘¾ğ‘§= ğ‘¾ğ’›1 ğ‘¾ğ‘§2 ğ‘¾ğ‘§3
ğ’›=
0.439 0.356 0.195
1.507 1.220 0.670
1.835 1.485 0.816
à·ğ’š= softmax(ğ’›) =
à·ğ’š(1)
à·ğ’š(2)
à·ğ’š(3)
=
0.369 0.340 0.289
0.458 0.343 0.198
0.484 0.341 0.174
ğ’™=
ğ’™(1)
ğ’™(2)
ğ’™(3)
=
1 1.5 0.2
1 4.7 1.6
1 5.6 2.2
ğ’š=
0
1
2
37
Softmax and MLP
AI VIETNAM
All-in-One Course
Training Accuracy: ~86%
Training Accuracy: ~90%
â¢Image Data Loading Using Numpy&PyTorch
â¢Softmax+Normalization for Fashion-MNIST
â¢MLP and Examples
â¢Step-by-Step Implementation
â¢Training Strategy (optional)
Outline
Step-by-Step Implementation
AI VIETNAM
All-in-One Course
â– 1. Data Preparation
â€¦
â€¦
â€¦
â€¦
1024 samples
Each sample is a tuple (image tensor, label)
â€¦
â€¦
â€¦
â€¦
1024 samples
â€¦
â€¦
â€¦
Batch index 0
Batch index n
39
Step-by-Step Implementation
â– 2. Model, loss and optimizer
784 Nodes
Flatten
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
Fully 
connect
10 Nodes
Output layer
28
28
. . .
. . .
Normalization
Fully 
connect
256 Nodes
Hidden layer
1
. . .
28x28
Input Layer
40
Step-by-Step 
Implementation
â– 3. Training
Training 
Dataset
Model
Model
GPU
Step-by-Step Implementation
AI VIETNAM
All-in-One Course
â– 4. Inference
Test 
Dataset
Model
Model
GPU
42
Step-by-Step 
Implementation
â– Addition 1: Compute
    Training Loss and Accuracy
Step-by-Step Implementation
â– Addition 2: Compute  Test Loss and Accuracy
Step-by-Step 
Implementation
â– Addition 2: Compute
    Test Loss and Accuracy
â¢Image Data Loading Using Numpy&PyTorch
â¢Softmax+Normalization for Fashion-MNIST
â¢MLP and Examples
â¢Step-by-Step Implementation
â¢Training Strategy (optional)
Outline
To-do List for Training
AI VIETNAM
All-in-One Course
Data Preparation
Data 
Normalization
Model (Network) 
Construction
Parameter 
Initialization
Optimizer 
Selection
Loss function 
Selection
Metric Selection
46
To-do List for Training
AI VIETNAM
All-in-One Course
Data Preparation
Training
Data
Testing
Data
Model
â‰ 
Used to train model
(Teach the model by examples)
Used to validate model
(Check how good the model is)
47
To-do List for Training
AI VIETNAM
All-in-One Course
Data Preparation
Data 
Normalization
Model (Network) 
Construction
Parameter 
Initialization
Optimizer 
Selection
Loss function 
Selection
Metric Selection
48
To-do List for Training
AI VIETNAM
All-in-One Course
Data Normalization
28
28
Image = Image
255
Convert to the range [0,1]
Image = Image
127.5 âˆ’1
Convert to the range [-1,1]
Image = Image âˆ’Î¼
Ïƒ
Z-score normalization
Î¼ is the mean of 
 the image or training data
Ïƒ is thestandard deviation
 of the image or training data
49
Implmentation
Image = Image
255
Convert to the range [0,1]
Image = Image
127.5 âˆ’1
Convert to the range [-1,1]
Image = Image âˆ’Î¼
Ïƒ
Z-score normalization
Image = Image âˆ’ğ‘šğ‘’ğ‘ğ‘›
std
In Pytorch
Normalize(ğ‘šğ‘’ğ‘ğ‘›, std)
[0,1]
mean = 0 ; std = 1
[-1,1]
mean = 0.5; std = 0.5
Compute mean and std 
from data
In Theory
ğ‘‹âˆˆ0, 255
ğ‘‹âˆˆ0, 1
50
To-do List for Training
AI VIETNAM
All-in-One Course
Data Preparation
Data 
Normalization
Model (Network) 
Construction
Parameter 
Initialization
Optimizer 
Selection
Loss function 
Selection
Metric Selection
51
To-do List for Training
AI VIETNAM
All-in-One Course
Model (Network) Construction
Input layer
Ouptut layer
Output
1
ğ‘§1
ğ‘§2
ğ‘§3
activation
Input
1
. . .
. . .
Fully connect
activation
Hidden Layers
How many hidden layers?
How many nodes in a hidden layer?
Which activation function?
Which network components?
52
How many nodes?
AI VIETNAM
All-in-One Course
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
1
Sigmoid 
activation
How many nodes?
Fully 
connect
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
53
How many nodes?
AI VIETNAM
All-in-One Course
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
1
Sigmoid 
activation
Grid Search
Fully 
connect
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
ğ‘1 ğ‘2 â€¦ ğ‘ğ‘˜
54
airplane
automobile
bird
cat
deer
dog
frog
horse
ship
truck
Image Classification
Cifar-10 dataset
Color images
Resolution=32x32
Training set: 50000 samples
Testing set: 10000 samples

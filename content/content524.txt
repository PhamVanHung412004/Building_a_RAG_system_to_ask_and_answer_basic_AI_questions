AI VIETNAM aivietnam.edu.vn
12 )
13
14 def get_hf_llm ( model_name : str = " mistralai / Mistral -7B- Instruct -v0 .2",
15 max_new_token = 1024 ,
16 ** kwargs ):
17
18 model = AutoModelForCausalLM . from_pretrained (
19 model_name ,
20 quantization_config = nf4_config ,
21 low_cpu_mem_usage = True
22 )
23 tokenizer = AutoTokenizer . from_pretrained ( model_name )
24
25 model_pipeline = pipeline (
26 "text - generation ",
27 model = model ,
28 tokenizer = tokenizer ,
29 max_new_tokens = max_new_token ,
30 pad_token_id = tokenizer . eos_token_id ,
31 device_map =" auto "
32 )
33
34 llm = HuggingFacePipeline (
35 pipeline = model_pipeline ,
36 model_kwargs = kwargs
37 )
38
39 return llm
Trong project này, mô hình LLM mà chúng ta sử dụng là mô hình Mistral 7B được huấn luyện
trên dữ liệu instruction. Các bạn có thể thay thế bằng mô hình khác có cấu hình tương tự.

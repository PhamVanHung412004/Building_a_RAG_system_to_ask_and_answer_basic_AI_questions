Chá»§ Ä‘á»:
Máº¡ng nÆ¡-ron (neural network) 
Má»¥c Ä‘Ã­ch buá»•i há»c
â—
LÃ½ thuyáº¿t xÃ¢y dá»±ng máº¡ng NÆ¡ ron nhÃ¢n táº¡o
â—
Thuáº­t toÃ¡n há»c cho máº¡ng NÆ¡ron nhÃ¢n táº¡o: Gradient 
Descend
Lá»‹ch sá»­
â—1958: NhÃ  tÃ¢m lÃ½ há»c Frank Rosenblatt táº¡o ra máº¡ng nÆ¡ron (neural) 
nhÃ¢n táº¡o
â—‹
Äáº·t tÃªn lÃ  Perceptron
â—‹
Má»¥c Ä‘Ã­ch mÃ´ hÃ¬nh hoÃ¡ quÃ¡ trÃ¬nh nháº­n thá»©c cá»§a con ngÆ°á»i
â—‹
Trong má»™t thá»i gian dÃ i, Neural Nets chá»‰ lÃ  má»™t khÃ¡i niá»‡m hÆ¡n 
lÃ  má»™t cÃ´ng cá»¥ thá»±c táº¿.
â—1986: BÃ i bÃ¡o vá» thuáº­t toÃ¡n backpropagation bá»Ÿi Rumelhar et al.
â—‹
CÃ¡ch huáº¥n luyá»‡n máº¡ng nÆ¡ron
â—‹
Neural network Ä‘Ã£ táº¡o Ä‘Æ°á»£c nhá»¯ng bÆ°á»›c tiáº¿n nhá» nhÆ°ng 
cháº¯c cháº¯n nhá» sá»± há»— trá»£ cá»§a sá»©c máº¡nh tÃ­nh toÃ¡n
â—2012: máº¡ng nÆ¡ ron tÃ­ch cháº­p (CNN) AlexNet Ä‘Ã£ chiáº¿n tháº¯ng trong 
ImageNet 2012
â—‹
Deeplearning trá»Ÿ thÃ nh tÃ¢m Ä‘iá»ƒm chÃº Ã½ Ä‘áº¿n ngÃ y nay
4
Lá»‹ch sá»­
Sá»± phÃ¡t triá»ƒn neural net nhá» sá»± phÃ¡t triá»ƒn cá»§a sá»©c máº¡nh tÃ­nh toÃ¡n
5
Máº¡ng neural trong nÃ£o ngÆ°á»i
â—
Neural: thÃ nh pháº§n chÃ­nh cá»§a mÃ´ tháº§n kinh á»Ÿ háº§u háº¿t cÃ¡c loÃ i 
Ä‘á»™ng váº­t
â—‹
Máº¡ng neural trong nÃ£o ngÆ°á»i
â—‹
Tiáº¿p nháº­n tÃ­n hiá»‡u Ä‘áº§u vÃ o (input) qua cÃ¡c dendrites
â—‹
CÃ¡c tÃ­n hiá»‡u sáº½ Ä‘Æ°á»£c neural quyáº¿t Ä‘á»‹nh xem cÃ³ Ä‘Æ°á»£c Ä‘i qua 
khÃ´ng táº¡i nucleus
â– 
Náº¿u Ä‘Æ°á»£c qua: cÃ¡c tÃ­n hiá»‡u nÃ y sáº½ Ä‘áº¿n axon vÃ  truyá»n 
qua cÃ¡c dendrites cá»§a cÃ¡c neural khÃ¡c
â—‹
Má»™t axon xuáº¥t cÃ¡c tÃ­n hiá»‡u Ä‘áº§u ra (output)
6
Máº¡ng nÆ¡-ron nhÃ¢n táº¡o: Giá»›i thiá»‡u
â– Máº¡ng nÆ¡-ron nhÃ¢n táº¡o (Artificial neural network â€“ ANN)
â‘MÃ´ phá»ng cÃ¡c há»‡ thá»‘ng nÆ¡-ron sinh há»c (cÃ¡c bá»™ nÃ£o con ngÆ°á»i)
â‘ANN lÃ  má»™t cáº¥u trÃºc (structure/network) Ä‘Æ°á»£c táº¡o nÃªn bá»Ÿi má»™t 
sá»‘ lÆ°á»£ng cÃ¡c nÆ¡-ron (artificial neurons) liÃªn káº¿t  vá»›i nhau
â– Má»—i nÆ¡-ron
â‘CÃ³ má»™t Ä‘áº·c tÃ­nh vÃ o/ra
â‘Thá»±c hiá»‡n má»™t tÃ­nh toÃ¡n cá»¥c bá»™ (má»™t hÃ m cá»¥c bá»™)
â– GiÃ¡ trá»‹ Ä‘áº§u ra cá»§a má»™t nÆ¡-ron Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh bá»Ÿi
â‘Äáº·c tÃ­nh vÃ o/ra cá»§a nÃ³
â‘CÃ¡c liÃªn káº¿t cá»§a nÃ³ vá»›i cÃ¡c nÆ¡-ron khÃ¡c
â‘(CÃ³ thá»ƒ) cÃ¡c Ä‘áº§u vÃ o bá»• sung
7
Máº¡ng nÆ¡-ron nhÃ¢n táº¡o: Giá»›i thiá»‡u
8
â– ANN cÃ³ thá»ƒ Ä‘Æ°á»£c xem nhÆ° má»™t cáº¥u trÃºc xá»­ lÃ½ thÃ´ng tin má»™t
cÃ¡ch phÃ¢n tÃ¡n vÃ  song song á»Ÿ má»©c cao
â– ANN cÃ³ kháº£ nÄƒng há»c (learn), nhá»› láº¡i (recall), vÃ  khÃ¡i quÃ¡t hÃ³a
(generalize) tá»« cÃ¡c dá»¯ liá»‡u há»c
â– Kháº£ nÄƒng cá»§a má»™t ANN phá»¥ thuá»™c vÃ o
â‘Kiáº¿n trÃºc (topology) cá»§a máº¡ng nÆ¡-ron
â‘Äáº·c tÃ­nh Ä‘áº§u vÃ o/ra cá»§a má»—i nÆ¡-ron
â‘Thuáº­t toÃ¡n há»c (huáº¥n luyá»‡n)
â‘Dá»¯ liá»‡u há»c
â—
CÃ¡c tÃ­n hiá»‡u Ä‘áº§u vÃ o (input 
signals) cá»§a nÆ¡-ron (xi, i=1..m)
â—
Trá»ng sá»‘ Ä‘iá»u chá»‰nh (bias) w0 
(vá»›i x0 = 1)
â—
Äáº§u vÃ o tá»•ng thá»ƒ (Net input) lÃ  
má»™t hÃ m tÃ­ch há»£p cá»§a cÃ¡c tÃ­n 
hiá»‡u Ä‘áº§u vÃ o â€“ 
â—
HÃ m tÃ¡c Ä‘á»™ng/truyá»n 
(Activation/transfer function) 
tÃ­nh giÃ¡ trá»‹ Ä‘áº§u ra cá»§a nÆ¡-ron â€“ 
â—
GiÃ¡ trá»‹ Ä‘áº§u ra (Output) cá»§a nÆ¡- 
ron:
Cáº¥u trÃºc vÃ  hoáº¡t Ä‘á»™ng cá»§a má»™t nÆ¡-ron
9
Äáº§u vÃ o nÆ¡-ron
10
â—
ThÃ´ng tin Ä‘áº§u vÃ o Ä‘Æ°á»£c tá»•ng 
há»£p láº¡i vÃ  Ä‘Æ°a vÃ o Ä‘áº§u vÃ o 
tá»•ng thá»ƒ
â—
Má»—i nÃºt bá»• sung thÃªm thÃ´ng tin 
vÃ  Ä‘Ã³ng gÃ³p thÃªm má»™t pháº§n 
vÃ o output cá»§a nÆ¡-ron
â—
CÃ ng cÃ³ nhiá»u nÃºt (thÃ´ng tin), 
chÃºng ta cÃ ng cÃ³ thá»ƒ náº¯m báº¯t 
Ä‘Æ°á»£c nhiá»u tÃ¡c Ä‘á»™ng hÆ¡n
â—
Má»—i nÃºt Ä‘i kÃ¨m má»™t trá»ng sá»‘ 
Ä‘iá»u chá»‰nh wi thá»ƒ hiá»‡n Ä‘á»™ quan 
trá»ng cá»§a thÃ´ng tin Ä‘áº§u vÃ o Ä‘Ã³ 
Ä‘á»‘i vá»›i thÃ´ng tin Ä‘áº§u ra
â—
Äáº§u vÃ o tá»•ng thá»ƒ (net input) thÆ°á»ng Ä‘Æ°á»£c tÃ­nh toÃ¡n bá»Ÿi má»™t hÃ m 
tuyáº¿n tÃ­nh 
Äáº§u vÃ o tá»•ng thá»ƒ
11
â—
Ã nghÄ©a cá»§a trá»ng sá»‘ Ä‘iá»u chá»‰nh (bias) w0
â†’ Há» cÃ¡c hÃ m Net=w1x1 khÃ´ng thá»ƒ phÃ¢n tÃ¡ch Ä‘Æ°á»£c cÃ¡c vÃ­ dá»¥ thÃ nh 2
lá»›p (two classes)
â†’ NhÆ°ng: há» cÃ¡c hÃ m Net=w1x1+w0 cÃ³ thá»ƒ!
HÃ m tÃ¡c Ä‘á»™ng trong nÆ¡-ron
â—
HÃ m tÃ¡c Ä‘á»™ng mÃ´ phá»ng tá»· lá»‡ truyá»n xung qua axon cá»§a má»™t neuron 
tháº§n kinh. Trong má»™t máº¡ng nÆ¡-ron nhÃ¢n táº¡o, hÃ m kÃ­ch hoáº¡t Ä‘Ã³ng vai 
trÃ² lÃ  thÃ nh pháº§n phi tuyáº¿n táº¡i output cá»§a cÃ¡c nÆ¡-ron.
Táº¡i sao láº¡i cáº§n cÃ¡c hÃ m kÃ­ch hoáº¡t phi tuyáº¿n?
â—
CÃ¢u tráº£ lá»i lÃ  náº¿u khÃ´ng cÃ³ cÃ¡c hÃ m kÃ­ch hoáº¡t phi tuyáº¿n, thÃ¬ máº¡ng 
nÆ¡-ron cá»§a chÃºng ta dÃ¹ cÃ³ nhiá»u lá»›p váº«n sáº½ cÃ³ hiá»‡u quáº£ nhÆ° má»™t lá»›p 
tuyáº¿n tÃ­nh mÃ  thÃ´i.
12
HÃ m tÃ¡c Ä‘á»™ng: Giá»›i háº¡n cá»©ng
Out
Î¸
Binary
hard-limiter
1
0
Net
Net
Out
1
-1
0
Bipolar
hard-limiter
13
Î¸
â€¢ CÃ²n Ä‘Æ°á»£c gá»i lÃ  hÃ m ngÆ°á»¡ng 
(threshold function)
â€¢ GiÃ¡ trá»‹ Ä‘áº§u ra láº¥y má»™t trong 2 giÃ¡ trá»‹ 
â€¢ Î¸ lÃ  giÃ¡ trá»‹ ngÆ°á»¡ng
â€¢ NhÆ°á»£c Ä‘iá»ƒm: khÃ´ng liÃªn tá»¥c, khÃ´ng cÃ³ 
Ä‘áº¡o hÃ m
HÃ m tÃ¡c Ä‘á»™ng: Logic ngÆ°á»¡ng
Out
1
0
1/Î±
Net
-Î¸
(1/Î±)-Î¸
14
(Î± >0)
â€¢ CÃ²n Ä‘Æ°á»£c gá»i lÃ  hÃ m tuyáº¿n tÃ­nh bÃ£o
hÃ²a (saturating linear function)
â€¢ Káº¿t há»£p cá»§a 2 hÃ m tÃ¡c Ä‘á»™ng: tuyáº¿n  
tÃ­nh vÃ  giá»›i háº¡n cháº·t
â€¢ Î± xÃ¡c Ä‘á»‹nh Ä‘á»™ dá»‘c cá»§a khoáº£ng tuyáº¿n
tÃ­nh
â€¢ NhÆ°á»£c Ä‘iá»ƒm: LiÃªn tá»¥c, nhÆ°ng khÃ´ng  
cÃ³ Ä‘áº¡o hÃ m
HÃ m tÃ¡c Ä‘á»™ng: Sigmoid
-Î¸
0
Net
1
 
0.5
Out
15
â€¢ÄÆ°á»£c dÃ¹ng phá»• biáº¿n
â€¢Tham sá»‘ Î± xÃ¡c Ä‘á»‹nh Ä‘á»™ dá»‘c
â€¢GiÃ¡ trá»‹ Ä‘áº§u ra trong khoáº£ng (0,1)
â€¢Æ¯u Ä‘iá»ƒm
â€¢ LiÃªn tá»¥c, vÃ  Ä‘áº¡o hÃ m liÃªn tá»¥c
â€¢ Äáº¡o hÃ m cá»§a má»™t hÃ m sigmoid
Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng má»™t hÃ m 
cá»§a chÃ­nh nÃ³
HÃ m tÃ¡c Ä‘á»™ng: Hyperbolic tangent
-Î¸
0
Net
1
 
-1
Out
Out(Net) = tanh( Net,Î±,Î¸ ) = 
16
â– CÅ©ng hay Ä‘Æ°á»£c sá»­ dá»¥ng
â– Tham sá»‘ Î± xÃ¡c Ä‘á»‹nh Ä‘á»™ dá»‘c
â– GiÃ¡ trá»‹ Ä‘áº§u ra trong khoáº£ng (-1,1)
â– Æ¯u Ä‘iá»ƒm
â‘LiÃªn tá»¥c, vÃ  Ä‘áº¡o hÃ m liÃªn tá»¥c
â‘Äáº¡o hÃ m cá»§a má»™t hÃ m tanh cÃ³ 
thá»ƒ  Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng má»™t 
hÃ m cá»§a  chÃ­nh nÃ³
â– ÄÆ°á»£c sá»­ dá»¥ng nhiá»u nháº¥t hiá»‡n nay
â– GiÃ¡ trá»‹ Ä‘áº§u ra luÃ´n khÃ´ng Ã¢m
â– Æ¯u Ä‘iá»ƒm
â‘LiÃªn tá»¥c
â‘KhÃ´ng cÃ³ Ä‘áº¡o hÃ m táº¡i Ä‘iá»ƒm 0 duy  
nháº¥t.
â‘Dá»… tÃ­nh toÃ¡n
HÃ m tÃ¡c Ä‘á»™ng: rectified linear unit  (ReLU)
17
ğ‘‚ğ‘¢ğ‘¡  ğ‘›ğ‘’ğ‘¡
= max(0, ğ‘›ğ‘’ğ‘¡)
ANN: Kiáº¿n trÃºc máº¡ng (1)
input
18
hidden
layer
output  
layer
output
bias
â– Kiáº¿n trÃºc cá»§a má»™t ANN Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh bá»Ÿi:
â‘Sá»‘ lÆ°á»£ng cÃ¡c tÃ­n hiá»‡u Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra
â‘Sá»‘ lÆ°á»£ng cÃ¡c táº§ng
â‘Sá»‘ lÆ°á»£ng cÃ¡c nÆ¡-ron trong má»—i táº§ng
â‘Sá»‘ lÆ°á»£ng cÃ¡c liÃªn káº¿t Ä‘á»‘i vá»›i má»—i nÆ¡-ron
â‘CÃ¡ch thá»©c cÃ¡c nÆ¡-ron (trong má»™t táº§ng,  
hoáº·c giá»¯a cÃ¡c táº§ng) liÃªn káº¿t vá»›i nhau
â– Má»™t ANN pháº£i cÃ³
â‘Má»™t táº§ng Ä‘áº§u vÃ o (input layer)
â‘Má»™t táº§ng Ä‘áº§u ra (output layer)
â‘KhÃ´ng, má»™t, hoáº·c nhiá»u táº§ng áº©n (hidden  
layer(s))
VÃ­ dá»¥: Má»™t ANN vá»›i má»™t táº§ng áº©n
â€¢ Äáº§u vÃ o: 3 tÃ­n hiá»‡u
â€¢ Äáº§u ra: 2 giÃ¡ trá»‹
â€¢ Tá»•ng cá»™ng, cÃ³ 6 neurons
- 4 á»Ÿ táº§ng áº©n
- 2 á»Ÿ táº§ng Ä‘áº§u ra
ANN: Kiáº¿n trÃºc máº¡ng (2)
â– Má»™t táº§ng (layer) chá»©a má»™t nhÃ³m cÃ¡c nÆ¡-ron
â– Táº§ng áº©n (hidden layer) lÃ  má»™t táº§ng náº±m á»Ÿ giá»¯a táº§ng Ä‘áº§u  vÃ o (input 
layer) vÃ  táº§ng Ä‘áº§u ra (output layer)
â– CÃ¡c nÃºt á»Ÿ táº§ng áº©n (hidden nodes) khÃ´ng tÆ°Æ¡ng tÃ¡c trá»±c  tiáº¿p vá»›i 
mÃ´i trÆ°á»ng bÃªn ngoÃ i (cá»§a máº¡ng nÆ¡-ron)
â– Má»™t ANN Ä‘Æ°á»£c gá»i lÃ  liÃªn káº¿t Ä‘áº§y Ä‘á»§ (fully connected)  náº¿u má»i 
Ä‘áº§u ra tá»« má»™t táº§ng liÃªn káº¿t vá»›i má»i nÆ¡-ron cá»§a táº§ng káº¿ tiáº¿p
19
ANN: Kiáº¿n trÃºc máº¡ng (3)
20
â– Má»™t ANN Ä‘Æ°á»£c gá»i lÃ  máº¡ng lan truyá»n tiáº¿n (feed- forward 
network) náº¿u khÃ´ng cÃ³ báº¥t ká»³ Ä‘áº§u ra cá»§a má»™t nÃºt lÃ  Ä‘áº§u vÃ o cá»§a 
má»™t nÃºt khÃ¡c thuá»™c cÃ¹ng táº§ng (hoáº·c thuá»™c má»™t táº§ng phÃ­a trÆ°á»›c)
â– Khi cÃ¡c Ä‘áº§u ra cá»§a má»™t nÃºt liÃªn káº¿t ngÆ°á»£c láº¡i lÃ m cÃ¡c Ä‘áº§u vÃ o cá»§a 
má»™t nÃºt thuá»™c cÃ¹ng táº§ng (hoáº·c thuá»™c má»™t táº§ng phÃ­a trÆ°á»›c), thÃ¬ Ä‘Ã³ lÃ  
má»™t máº¡ng pháº£n há»“i (feedback  network)
â‘Náº¿u pháº£n há»“i lÃ  liÃªn káº¿t Ä‘áº§u vÃ o Ä‘á»‘i vá»›i cÃ¡c nÃºt thuá»™c cÃ¹ng táº§ng,  
thÃ¬ Ä‘Ã³ lÃ  pháº£n há»“i bÃªn (lateral feedback)
â– CÃ¡c máº¡ng pháº£n há»“i cÃ³ cÃ¡c vÃ²ng láº·p kÃ­n (closed loops)
Ä‘Æ°á»£c gá»i lÃ  cÃ¡c máº¡ng há»“i quy (recurrent networks)
ANN: Kiáº¿n trÃºc máº¡ng (4)
Máº¡ng lan  
truyá»n tiáº¿n  
má»™t táº§ng
21
Máº¡ng lan  
truyá»n tiáº¿n  
nhiá»u táº§ng
Má»™t nÆ¡-ron vá»›i  
pháº£n há»“i Ä‘áº¿n  
chÃ­nh nÃ³
Máº¡ng há»“i  
quy má»™t  
táº§ng
Máº¡ng há»“i  
quy nhiá»u  
táº§ng
ANN: CÃ¡ch huáº¥n luyá»‡n
â€¢ 2 kiá»ƒu há»c trong cÃ¡c máº¡ng nÆ¡-ron nhÃ¢n táº¡o
â€¢ Há»c tham sá»‘ (Parameter learning)
â†’ Má»¥c tiÃªu lÃ  thay Ä‘á»•i thÃ­ch nghi cÃ¡c trá»ng sá»‘ (weights) cá»§a 
cÃ¡c liÃªn káº¿t trong máº¡ng nÆ¡-ron
â€¢ Há»c cáº¥u trÃºc (Structure learning)
â†’ Má»¥c tiÃªu lÃ  thay Ä‘á»•i thÃ­ch nghi cáº¥u trÃºc máº¡ng, bao gá»“m sá»‘ 
lÆ°á»£ng cÃ¡c nÆ¡-ron vÃ  cÃ¡c kiá»ƒu liÃªn káº¿t giá»¯a chÃºng
Or
â€¢ 2 kiá»ƒu há»c nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n Ä‘á»“ng thá»i hoáº·c 
riÃªng ráº½
â€¢ Trong bÃ i há»c nÃ y, chÃºng ta sáº½ chá»‰ xÃ©t viá»‡c há»c tham sá»‘
22
ANN: Ã½ tÆ°á»Ÿng
â– Huáº¥n luyá»‡n má»™t máº¡ng nÆ¡ron (khi cá»‘ Ä‘á»‹nh kiáº¿n trÃºc) chÃ­nh lÃ 
viá»‡c há»c cÃ¡c trá»ng sá»‘ w cá»§a máº¡ng tá»« táº­p há»c D.
â– ÄÆ°a viá»‡c há»c vá» bÃ i toÃ¡n cá»±c tiá»ƒu hoÃ¡ má»™t hÃ m lá»—i thá»±c  
nghiá»‡m:
â‘Trong Ä‘Ã³ out(x) lÃ  Ä‘áº§u ra cá»§a máº¡ng, vá»›i Ä‘áº§u vÃ o x cÃ³ nhÃ£n tÆ°Æ¡ng 
á»©ng lÃ   dx; loss lÃ  má»™t hÃ m Ä‘o lá»—i phÃ¡n Ä‘oÃ¡n.
â– Nhiá»u phÆ°Æ¡ng phÃ¡p láº·p dá»±a trÃªn Gradient:
â‘Backpropagation
â‘SGD
â‘Adam
â‘AdaGrad
Î£
x2
xm
x0  
x1
w0
w1
w2
wm
â€¦
Out
23
â—
Má»™t perceptron lÃ  má»™t kiá»ƒu  
Ä‘Æ¡n giáº£n nháº¥t cá»§a ANNs (chá»‰  
gá»“m duy nháº¥t má»™t nÆ¡-ron)
â—
Sá»­ dá»¥ng hÃ m tÃ¡c Ä‘á»™ng giá»›i  
háº¡n cháº·t
Perceptron
Î£
xm
0
x =1
w0
w1
w2
wm
x1
x2
â€¦
Out
24
â—
Äá»‘i vá»›i má»™t vÃ­ dá»¥ x, giÃ¡ trá»‹
Ä‘áº§u ra cá»§a perceptron lÃ 
â—‹
1, náº¿u Net(w,x) > 0
â—‹
-1, náº¿u ngÆ°á»£c láº¡i
Perceptron: Minh há»a
Máº·t pháº³ng phÃ¢n tÃ¡ch  
w0+w1x1+w2x2=0
Äáº§u ra = 1
x1
25
Äáº§u ra = -1
x2
Perceptron: Giáº£i thuáº­t há»c
26
â– Vá»›i má»™t táº­p cÃ¡c vÃ­ dá»¥ há»c D= {(x,d)}
â‘x lÃ  vectÆ¡ Ä‘áº§u vÃ o
â‘d lÃ  giÃ¡ trá»‹ Ä‘áº§u ra mong muá»‘n (-1 hoáº·c 1)
â– QuÃ¡ trÃ¬nh há»c cá»§a perceptron nháº±m xÃ¡c Ä‘á»‹nh má»™t vectÆ¡ trá»ng  sá»‘ 
cho phÃ©p perceptron sinh ra giÃ¡ trá»‹ Ä‘áº§u ra chÃ­nh xÃ¡c (-1  hoáº·c 1) 
cho má»—i vÃ­ dá»¥ há»c
â– Vá»›i má»™t vÃ­ dá»¥ há»c x Ä‘Æ°á»£c perceptron phÃ¢n lá»›p chÃ­nh xÃ¡c, thÃ¬
vectÆ¡ trá»ng sá»‘ w khÃ´ng thay Ä‘á»•i
â– Náº¿u d=1 nhÆ°ng perceptron láº¡i sinh ra -1 (Out=-1), thÃ¬ w cáº§n  
Ä‘Æ°á»£c thay Ä‘á»•i sao cho giÃ¡ trá»‹ Net(w,x) tÄƒng lÃªn
â– Náº¿u d=-1 nhÆ°ng perceptron láº¡i sinh ra 1 (Out=1), thÃ¬ w cáº§n
Ä‘Æ°á»£c thay Ä‘á»•i sao cho giÃ¡ trá»‹ Net(w,x) giáº£m Ä‘i
2323
Perceptron: Giáº£i thuáº­t há»c
Khá»Ÿi táº¡o tham sá»‘ w (wi â† giÃ¡ trá»‹ ngáº«u nhiÃªn nhá»)
báº¯t Ä‘áº§u
âˆ†w â† 0
vá»›i má»—i quan sÃ¡t (x,d) âˆˆ D  
Dá»± Ä‘oÃ¡n giÃ¡ trá»‹ Ä‘áº§u ra tÆ°Æ¡ng á»©ng vá»›i dá»¯ liá»‡u x 
Náº¿u (Outâ‰ d)
âˆ†w â† âˆ†w + Î·(d - Out) x
káº¿t thÃºc vÃ²ng láº·p
w â† w + âˆ†w
Tá»›i khi toÃ n bá»™ dá»¯ liá»‡u trong D Ä‘Æ°á»£c phÃ¢n loáº¡i Ä‘Ãºng tráº£ vá» w
Perceptron: Giá»›i háº¡n
â€¢ Giáº£i thuáº­t há»c cho perceptron Ä‘Æ°á»£c chá»©ng
minh lÃ  há»™i tá»¥ (converge) náº¿u:
28
â€¢ CÃ¡c vÃ­ dá»¥ há»c lÃ  cÃ³ thá»ƒ phÃ¢n tÃ¡ch 
tuyáº¿n tÃ­nh  (linearly separable)
â€¢ Sá»­ dá»¥ng má»™t tá»‘c Ä‘á»™ há»c Î· Ä‘á»§ nhá»
â€¢ Giáº£i thuáº­t há»c perceptron cÃ³ thá»ƒ khÃ´ng 
há»™i tá»¥ náº¿u nhÆ° cÃ¡c vÃ­ dá»¥ há»c khÃ´ng thá»ƒ 
phÃ¢n tÃ¡ch tuyáº¿n tÃ­nh (not linearly 
separable)
Má»™t perceptron khÃ´ng  
thá»ƒ phÃ¢n lá»›p chÃ­nh xÃ¡c  
Ä‘á»‘i vá»›i táº­p há»c nÃ y!
HÃ m Ä‘Ã¡nh giÃ¡ lá»—i (Loss function)
â– Lá»—i há»c gÃ¢y ra bá»Ÿi vectÆ¡ trá»ng sá»‘ (hiá»‡n táº¡i) w Ä‘á»‘i vá»›i
toÃ n bá»™ táº­p há»c D:
29
â– XÃ©t má»™t ANN cÃ³ n nÆ¡-ron Ä‘áº§u ra
â– Äá»‘i vá»›i má»™t vÃ­ dá»¥ há»c (x,d), giÃ¡ trá»‹ lá»—i há»c (training error)
gÃ¢y ra bá»Ÿi vectÆ¡ trá»ng sá»‘ (hiá»‡n táº¡i) w:
â– Gradient cá»§a E (kÃ½ hiá»‡u lÃ  âˆ‡E) lÃ  má»™t vectÆ¡
â‘trong Ä‘Ã³ N lÃ  tá»•ng sá»‘ cÃ¡c trá»ng sá»‘ (cÃ¡c liÃªn káº¿t) trong máº¡ng
â– Gradient âˆ‡E xÃ¡c Ä‘á»‹nh hÆ°á»›ng gÃ¢y ra viá»‡c tÄƒng nhanh nháº¥t (steepest  
increase) Ä‘á»‘i vá»›i giÃ¡ trá»‹ lá»—i E
â– VÃ¬ váº­y, hÆ°á»›ng gÃ¢y ra viá»‡c giáº£m nhanh nháº¥t (steepest decrease) lÃ 
hÆ°á»›ng ngÆ°á»£c vá»›i gradient cá»§a E
â– YÃªu cáº§u: CÃ¡c hÃ m tÃ¡c Ä‘á»™ng Ä‘Æ°á»£c sá»­ dá»¥ng trong máº¡ng pháº£i cÃ³ Ä‘áº¡o
hÃ m liÃªn tá»¥c
Tá»‘i thiá»ƒu hoÃ¡ lá»—i vá»›i Gradient
30
Gradient descent: Minh há»a
KhÃ´ng gian má»™t chiá»u
E(w)
KhÃ´ng gian 2 chiá»u
E(w1,w2)
31
28
Gradient descent
Khá»Ÿi táº¡o tham sá»‘ w (wi â† giÃ¡ trá»‹ ngáº«u nhiÃªn nhá»)
báº¯t Ä‘áº§u
Vá»›i má»—i quan sÃ¡t (x,d)âˆˆD
TÃ­nh toÃ¡n giÃ¡ trá»‹ dá»± Ä‘oÃ¡n cá»§a 
máº¡ng wi
Káº¿t thÃºc vÃ²ng láº·p
Láº·p láº¡i tá»›i khi (thoáº£ mÃ£n Ä‘iá»u kiá»‡n dá»«ng láº¡i)
Tráº£ vá» giÃ¡ trá»‹ tham sá»‘ w
Äiá»u kiá»‡n dá»«ng láº¡i: Sá»‘ chu ká»³ há»c (epochs), NgÆ°á»¡ng lá»—i, ...
28
Náº¿u ta láº¥y tá»«ng táº­p nhá» 
má»™t cÃ¡ch ngáº«u nhiÃªn tá»« 
D, ta cÃ³ â€œmini-batch 
training"
Gradient descent incremental
ANN nhiá»u táº§ng vÃ  giáº£i thuáº­t lan truyá»n ngÆ°á»£c
33
â– Má»™t perceptron chá»‰ cÃ³ thá»ƒ biá»ƒu diá»…n má»™t hÃ m phÃ¢n tÃ¡ch tuyáº¿n tÃ­nh
(linear separation function)
â– Má»™t máº¡ng nÆ¡-ron nhiá»u táº§ng (multi-layer NN) Ä‘Æ°á»£c há»c bá»Ÿi giáº£i thuáº­t  
lan truyá»n ngÆ°á»£c (Back Propagation - BP) cÃ³ thá»ƒ biá»ƒu diá»…n má»™t hÃ m  
phÃ¢n tÃ¡ch phi tuyáº¿n phá»©c táº¡p (highly non-linear separation function)
â– Giáº£i thuáº­t há»c BP Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ há»c cÃ¡c trá»ng sá»‘ cá»§a má»™t 
máº¡ng  nÆ¡-ron nhiá»u táº§ng
â‘Cáº¥u trÃºc máº¡ng cá»‘ Ä‘á»‹nh (cÃ¡c nÆ¡-ron vÃ  cÃ¡c liÃªn káº¿t giá»¯a chÃºng lÃ  cá»‘ Ä‘á»‹nh)
â‘Äá»‘i vá»›i má»—i nÆ¡-ron, hÃ m tÃ¡c Ä‘á»™ng pháº£i cÃ³ Ä‘áº¡o hÃ m liÃªn tá»¥c
â– Giáº£i thuáº­t BP Ã¡p dá»¥ng chiáº¿n lÆ°á»£c gradient descent trong quy táº¯c cáº­p  
nháº­t cÃ¡c trá»ng sá»‘
â‘Äá»ƒ cá»±c tiá»ƒu hÃ³a lá»—i (khÃ¡c biá»‡t) giá»¯a cÃ¡c giÃ¡ trá»‹ Ä‘áº§u ra thá»±c táº¿ vÃ  cÃ¡c giÃ¡ trá»‹ 
Ä‘áº§u ra mong muá»‘n, Ä‘á»‘i vá»›i cÃ¡c vÃ­ dá»¥ há»c
34
Giáº£i thuáº­t há»c lan truyá»n ngÆ°á»£c (1)
â– Giáº£i thuáº­t há»c lan truyá»n ngÆ°á»£c tÃ¬m kiáº¿m má»™t vectÆ¡ cÃ¡c trá»ng  sá»‘ 
(weights vector) giÃºp cá»±c tiá»ƒu hÃ³a lá»—i tá»•ng thá»ƒ cá»§a há»‡ thá»‘ng Ä‘á»‘i 
vá»›i táº­p há»c
â– Giáº£i thuáº­t BP bao gá»“m 2 giai Ä‘oáº¡n (bÆ°á»›c)
â‘Giai Ä‘oáº¡n lan truyá»n tiáº¿n tÃ­n hiá»‡u (Signal forward). CÃ¡c tÃ­n hiá»‡u  
Ä‘áº§u vÃ o (vectÆ¡ cÃ¡c giÃ¡ trá»‹ Ä‘áº§u vÃ o) Ä‘Æ°á»£c lan truyá»n tiáº¿n tá»« táº§ng  Ä‘áº§u 
vÃ o Ä‘áº¿n táº§ng Ä‘áº§u ra (Ä‘i qua cÃ¡c táº§ng áº©n)
â‘Giai Ä‘oáº¡n lan truyá»n ngÆ°á»£c lá»—i (Error backward)
â– CÄƒn cá»© vÃ o giÃ¡ trá»‹ Ä‘áº§u ra mong muá»‘n cá»§a vectÆ¡ Ä‘áº§u vÃ o, há»‡ thá»‘ng tÃ­nh 
toÃ¡n giÃ¡ trá»‹ lá»—i
â– Báº¯t Ä‘áº§u tá»« táº§ng Ä‘áº§u ra, giÃ¡ trá»‹ lá»—i Ä‘Æ°á»£c lan truyá»n ngÆ°á»£c qua máº¡ng, tá»« 
táº§ng nÃ y qua táº§ng khÃ¡c (phÃ­a trÆ°á»›c), cho Ä‘áº¿n táº§ng Ä‘áº§u vÃ o
â– Viá»‡c lan truyá»n ngÆ°á»£c lá»—i (error back-propagation) Ä‘Æ°á»£c thá»±c hiá»‡n 
thÃ´ng qua viá»‡c tÃ­nh toÃ¡n (má»™t cÃ¡ch truy há»“i) giÃ¡ trá»‹ gradient cá»¥c bá»™ cá»§a  
má»—i nÆ¡-ron
Giáº£i thuáº­t há»c lan truyá»n ngÆ°á»£c (2)
Giai Ä‘oáº¡n lan truyá»n tiáº¿n  
tÃ­n hiá»‡u:
â€¢KÃ­ch hoáº¡t (truyá»n tÃ­n hiá»‡u
qua) máº¡ng
Giai Ä‘oáº¡n lan truyá»n
ngÆ°á»£c lá»—i:
â€¢TÃ­nh toÃ¡n lá»—i á»Ÿ Ä‘áº§u ra
â€¢Lan truyá»n (ngÆ°á»£c) lá»—i
35
Giáº£i thuáº­t BP: Cáº¥u trÃºc máº¡ng
Hidden  
neuron zq  
(q=1..l)
w
qj
Outq
w
iq
Outi
...
...
...
...
x1
xj
xm
...
...
Input xj
(j=1..m)
36
Output  
neuron yi  
(i=1..n)
â€¢ XÃ©t máº¡ng nÆ¡-ron 3 táº§ng (trong
hÃ¬nh váº½) Ä‘á»ƒ minh há»a giáº£i thuáº­t 
há»c BP
â€¢ m tÃ­n hiá»‡u Ä‘áº§u vÃ o xj (j=1..m)
â€¢ l nÆ¡-ron táº§ng áº©n zq (q=1..l)
â€¢ n nÆ¡-ron Ä‘áº§u ra yi (i=1..n)
â€¢ w lÃ  trá»ng sá»‘ cá»§a liÃªn káº¿t tá»« tÃ­n
qj
hiá»‡u Ä‘áº§u vÃ o xj tá»›i nÆ¡-ron táº§ng áº©n
zq
â€¢ wiq lÃ  trá»ng sá»‘ cá»§a liÃªn káº¿t tá»« nÆ¡-  
ron táº§ng áº©n zq tá»›i nÆ¡-ron Ä‘áº§u ra yi
â€¢ Outq lÃ  giÃ¡ trá»‹ Ä‘áº§u ra (cá»¥c bá»™) cá»§a  
nÆ¡-ron táº§ng áº©n zq
â€¢ Outi lÃ  giÃ¡ trá»‹ Ä‘áº§u ra cá»§a máº¡ng
tÆ°Æ¡ng á»©ng vá»›i nÆ¡-ron Ä‘áº§u ra yi
â– Äá»‘i vá»›i má»—i vÃ­ dá»¥ há»c x
â‘VectÆ¡ Ä‘áº§u vÃ o x Ä‘Æ°á»£c lan truyá»n tá»« táº§ng Ä‘áº§u vÃ o Ä‘áº¿n táº§ng Ä‘áº§u ra
â‘Máº¡ng sáº½ sinh ra má»™t giÃ¡ trá»‹ Ä‘áº§u ra dá»± Ä‘oÃ¡n (predicted output) 
Out (lÃ  má»™t vectÆ¡ cá»§a cÃ¡c giÃ¡ trá»‹ Outi, i=1..n)
â– Äá»‘i vá»›i má»™t vectÆ¡ Ä‘áº§u vÃ o x, má»™t nÆ¡-ron zq á»Ÿ táº§ng áº©n sáº½ nháº­n 
Ä‘Æ°á»£c giÃ¡ trá»‹ Ä‘áº§u vÃ o tá»•ng thá»ƒ (net input) báº±ng:
trong Ä‘Ã³ f () lÃ  hÃ m tÃ¡c Ä‘á»™ng (activation function) cá»§a nÆ¡-ron zq
37
Giáº£i thuáº­t BP: Lan truyá»n tiáº¿n (1)
â€¦vÃ  sinh ra má»™t giÃ¡ trá»‹ Ä‘áº§u ra (cá»¥c bá»™) báº±ng:
â– GiÃ¡ trá»‹ Ä‘áº§u vÃ o tá»•ng thá»ƒ (net input) cá»§a nÆ¡-ron yi á»Ÿ táº§ng
Ä‘áº§u ra
38
â– NÆ¡-ron yi  sinh ra giÃ¡ trá»‹ Ä‘áº§u ra (lÃ  má»™t giÃ¡ trá»‹ Ä‘áº§u ra cá»§a máº¡ng)
â– VectÆ¡ cÃ¡c giÃ¡ trá»‹ Ä‘áº§u ra Outi (i=1..n) chÃ­nh lÃ  giÃ¡ trá»‹ Ä‘áº§u ra
thá»±c táº¿ cá»§a máº¡ng, Ä‘á»‘i vá»›i vectÆ¡ Ä‘áº§u vÃ o x
Giáº£i thuáº­t BP: Lan truyá»n tiáº¿n (2)
Giáº£i thuáº­t BP: Lan truyá»n ngÆ°á»£c (1)
39
â– Äá»‘i vá»›i má»—i vÃ­ dá»¥ há»c x
â‘CÃ¡c tÃ­n hiá»‡u lá»—i (error signals) do sá»± khÃ¡c biáº¿t giá»¯a giÃ¡ trá»‹ Ä‘áº§u ra  
mong muá»‘n d vÃ  giÃ¡ trá»‹ Ä‘áº§u ra thá»±c táº¿ Out Ä‘Æ°á»£c tÃ­nh toÃ¡n
â‘CÃ¡c tÃ­n hiá»‡u lá»—i nÃ y Ä‘Æ°á»£c lan truyá»n ngÆ°á»£c (back-propagated) tá»«  
táº§ng Ä‘áº§u ra tá»›i cÃ¡c táº§ng phÃ­a trÆ°á»›c, Ä‘á»ƒ cáº­p nháº­t cÃ¡c trá»ng sá»‘  
(weights)
â– Äá»ƒ xÃ©t cÃ¡c tÃ­n hiá»‡u lá»—i vÃ  viá»‡c lan truyá»n ngÆ°á»£c cá»§a  chÃºng, 
cáº§n Ä‘á»‹nh nghÄ©a má»™t hÃ m lá»—i
Giáº£i thuáº­t BP: Äáº¡o hÃ m chuá»—i
40
Vá»›i quy táº¯c Ä‘áº¡o hÃ m chuá»—i ta biáº¿t Ä‘Æ°á»£c ráº±ng
Trá»±c quan hoÃ¡ bÆ°á»›c lan truyá»n ngÆ°á»£c:
Giáº£i thuáº­t BP: Lan truyá»n ngÆ°á»£c (2)
41
â– Theo phÆ°Æ¡ng phÃ¡p gradient-descent, cÃ¡c trá»ng sá»‘ cá»§a cÃ¡c liÃªn
káº¿t tá»« táº§ng áº©n tá»›i táº§ng Ä‘áº§u ra Ä‘Æ°á»£c cáº­p nháº­t bá»Ÿi
â– Sá»­ dá»¥ng quy táº¯c chuá»—i Ä‘áº¡o hÃ m Ä‘á»‘i vá»›i âˆ‚E/âˆ‚wiq, ta cÃ³
(LÆ°u Ã½: dáº¥u â€œâ€“â€ Ä‘Ã£ Ä‘Æ°á»£c káº¿t há»£p vá»›i giÃ¡ trá»‹ âˆ‚E/âˆ‚Outi)
â—¼ i lÃ  tÃ­n hiá»‡u lá»—i (error signal) cá»§a nÆ¡-ron yi á»Ÿ táº§ng Ä‘áº§u ra
trong Ä‘Ã³ Neti lÃ  Ä‘áº§u vÃ o tá»•ng thá»ƒ (net input) cá»§a nÆ¡-ron yi á»Ÿ táº§ng
Ä‘áº§u ra, vÃ  f'(Neti)=f(Neti)/Neti
Giáº£i thuáº­t BP: Lan truyá»n ngÆ°á»£c (4)
42
â– Ãp dá»¥ng quy táº¯c chuá»—i Ä‘áº¡o hÃ m, ta cÃ³
â– Î´q lÃ  tÃ­n hiá»‡u lá»—i (error signal) cá»§a nÆ¡-ron zq á»Ÿ táº§ng áº©n
trong Ä‘Ã³ Netq lÃ  Ä‘áº§u vÃ o tá»•ng thá»ƒ (net input) cá»§a nÆ¡-ron zq á»Ÿ táº§ng 
áº©n, vÃ  f'(Netq)=âˆ‚f(Netq)/âˆ‚Netq
Giáº£i thuáº­t BP: Lan truyá»n ngÆ°á»£c (5)
43
â– Theo cÃ¡c cÃ´ng thá»©c tÃ­nh cÃ¡c tÃ­n hiá»‡u lá»—i Î´i vÃ  Î´q Ä‘Ã£ nÃªu, thÃ¬ tÃ­n  hiá»‡u 
lá»—i cá»§a má»™t nÆ¡-ron á»Ÿ táº§ng áº©n khÃ¡c vá»›i tÃ­n hiá»‡u lá»—i cá»§a má»™t nÆ¡-ron á»Ÿ 
táº§ng Ä‘áº§u ra
â– Do sá»± khÃ¡c biá»‡t nÃ y, thá»§ tá»¥c cáº­p nháº­t trá»ng sá»‘ trong giáº£i thuáº­t
BP cÃ²n Ä‘Æ°á»£c gá»i lÃ  quy táº¯c há»c delta tá»•ng quÃ¡t
â– TÃ­n hiá»‡u lá»—i Î´q cá»§a nÆ¡-ron zq á»Ÿ táº§ng áº©n Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh bá»Ÿi
â‘CÃ¡c tÃ­n hiá»‡u lá»—i Î´i cá»§a cÃ¡c nÆ¡-ron yi á»Ÿ táº§ng Ä‘áº§u ra (mÃ  nÆ¡-ron zq
liÃªn káº¿t tá»›i)
â‘CÃ¡c há»‡ sá»‘ chÃ­nh lÃ  cÃ¡c trá»ng sá»‘ wiq
Giáº£i thuáº­t BP: Lan truyá»n ngÆ°á»£c (6)
44
â– QuÃ¡ trÃ¬nh tÃ­nh toÃ¡n tÃ­n hiá»‡u lá»—i (error signals) nhÆ° trÃªn cÃ³  thá»ƒ Ä‘Æ°á»£c 
má»Ÿ rá»™ng (khÃ¡i quÃ¡t) dá»… dÃ ng Ä‘á»‘i vá»›i máº¡ng nÆ¡-ron cÃ³ nhiá»u hÆ¡n 1 
táº§ng áº©n (hidden layer)
â– Dáº¡ng tá»•ng quÃ¡t cá»§a quy táº¯c cáº­p nháº­t trá»ng sá»‘ trong giáº£i
thuáº­t BP lÃ :
Î”wab =
Î·Î´axb
â‘b vÃ  a lÃ  2 chá»‰ sá»‘ tÆ°Æ¡ng á»©ng vá»›i 2 Ä‘áº§u cá»§a liÃªn káº¿t (bâ†’a) (tá»« má»™t
nÆ¡-ron (hoáº·c tÃ­n hiá»‡u Ä‘áº§u vÃ o) b Ä‘áº¿n nÆ¡-ron a)
â‘xb lÃ  giÃ¡ trá»‹ Ä‘áº§u ra cá»§a nÆ¡-ron á»Ÿ táº§ng áº©n (hoáº·c tÃ­n hiá»‡u Ä‘áº§u vÃ o) b
â‘Î´a lÃ  tÃ­n hiá»‡u lá»—i cá»§a nÆ¡-ron a
45
â—
Máº¡ng nÆ¡-ron gá»“m Q táº§ng, q = 1,2,...,Q
â—
qNeti vÃ  qOuti lÃ  Ä‘áº§u vÃ o tá»•ng thá»ƒ (net input) vÃ  giÃ¡ trá»‹ Ä‘áº§u ra cá»§a 
nÆ¡-ron i á»Ÿ táº§ng q
â—
Máº¡ng cÃ³ m tÃ­n hiá»‡u Ä‘áº§u vÃ o vÃ  n nÆ¡-ron Ä‘áº§u ra
â—
qwij lÃ  trá»ng sá»‘ cá»§a liÃªn káº¿t tá»« nÆ¡-ron j á»Ÿ táº§ng (q-1) Ä‘áº¿n nÆ¡-ron i á»Ÿ 
táº§ng q
Back_propagation_incremental(D, Î·)
BÆ°á»›c 0 (Khá»Ÿi táº¡o)
Chá»n ngÆ°á»¡ng lá»—i Ethreshold (giÃ¡ trá»‹ lá»—i cÃ³ thá»ƒ cháº¥p nháº­n Ä‘Æ°á»£c)
Khá»Ÿi táº¡o giÃ¡ trá»‹ ban Ä‘áº§u cá»§a cÃ¡c trá»ng sá»‘ vá»›i cÃ¡c giÃ¡ trá»‹ nhá» ngáº«u nhiÃªn
GÃ¡n E=0
46
BÆ°á»›c 1 (Báº¯t Ä‘áº§u má»™t chu ká»³ há»c)
Ãp dá»¥ng vectÆ¡ Ä‘áº§u vÃ o cá»§a vÃ­ dá»¥ há»c k Ä‘á»‘i vá»›i táº§ng Ä‘áº§u vÃ o (q=1)
Back propagation incremental 
BÆ°á»›c 3 TÃ­nh toÃ¡n lá»—i Ä‘áº§u ra cá»§a máº¡ng vÃ  tÃ­n hiá»‡u lá»—i Qi cá»§a má»—i 
nÆ¡-ron á»Ÿ táº§ng Ä‘áº§u ra 
BÆ°á»›c 2 (Lan truyá»n tiáº¿n)
Lan truyá»n tiáº¿n cÃ¡c tÃ­n hiá»‡u Ä‘áº§u vÃ o qua máº¡ng, cho Ä‘áº¿n khi nháº­n Ä‘Æ°á»£c 
cÃ¡c giÃ¡ trá»‹ Ä‘áº§u ra cá»§a máº¡ng (á»Ÿ táº§ng Ä‘áº§u ra) QOuti
47
BÆ°á»›c 4 (Lan truyá»n ngÆ°á»£c lá»—i)
Lan truyá»n ngÆ°á»£c lá»—i Ä‘á»ƒ cáº­p nháº­t cÃ¡c trá»ng sá»‘ vÃ  tÃ­nh toÃ¡n cÃ¡c tÃ­n hiá»‡u lá»—i 
q-1Î´i cho cÃ¡c táº§ng phÃ­a trÆ°á»›c
BÆ°á»›c 5 (Kiá»ƒm tra káº¿t thÃºc má»™t chu ká»³ há»c â€“ epoch)
Kiá»ƒm tra xem toÃ n bá»™ táº­p há»c Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng (Ä‘Ã£ xong má»™t chu ká»³ há»c 
â€“ epoch)
Náº¿u toÃ n bá»™ táº­p há»c Ä‘Ã£ Ä‘Æ°á»£c dÃ¹ng, chuyá»ƒn Ä‘áº¿n BÆ°á»›c 6; ngÆ°á»£c láº¡i, 
chuyá»ƒn Ä‘áº¿n BÆ°á»›c 1
BÆ°á»›c 6 (Kiá»ƒm tra lá»—i tá»•ng thá»ƒ)
Náº¿u lá»—i tá»•ng thá»ƒ E nhá» hÆ¡n ngÆ°á»¡ng lá»—i cháº¥p nháº­n Ä‘Æ°á»£c (<Ethreshold), thÃ¬ 
quÃ¡ trÃ¬nh há»c káº¿t thÃºc vÃ  tráº£ vá» cÃ¡c trá»ng sá»‘ há»c Ä‘Æ°á»£c;
NgÆ°á»£c láº¡i, gÃ¡n láº¡i E=0, vÃ  báº¯t Ä‘áº§u má»™t chu ká»³ há»c má»›i (quay vá» BÆ°á»›c 1)
Back_propagation_incremental(D, Î·)
x1
x2
Giáº£i thuáº­t BP: Lan truyá»n tiáº¿n (1)
48
f(Net1)
2
f(Net )
f(Net3)
f(Net4)
Out6
f(Net5)
f(Net6)
x1
x2
1
49
2
1
1x
1x
1
f (w x + w x2 )
Out =
w
1x x
1
1
w x
1x2 2
Giáº£i thuáº­t BP: Lan truyá»n tiáº¿n (2)
f(Net1)
Out6
2
f(Net )
f(Net3)
f(Net4)
f(Net5)
f(Net6)
x1
2x
w2
50
2 x2
w
2 x
2
2 x2 2
2 x1 1x + w
x
)
Out
= f 
(w
Giáº£i thuáº­t BP: Lan truyá»n tiáº¿n (3)
f(Net1)
Out6
2
f(Net )
f(Net3)
4
f(Net )
f(Net5)
f(Net6)
x1
x2
3
51
w
3
3x2 2
3x1 1x + w
x
)
Out = f 
(w
Giáº£i thuáº­t BP: Lan truyá»n tiáº¿n (4)
f(Net1)
Out6
2
f(Net )
w
3x
x
2 f(Net 
)
2
3
f(Net4)
f(Net5)
f(Net6)
x1
x2
2
52
42
w
Out
w41Out
1
w4 O
2+ w43Out3 )
Out4  =f (w41Out1 + w42Out
Giáº£i thuáº­t BP: Lan truyá»n tiáº¿n (5)
f(Net1)
Out6
2
f(Net )
f(Net3)
f(Net4)
f(Net5)
f(Net6)
x1
x2
w52Out2
53
w51Out1
w5 O
Out5  = f (w51Out1  + w52Out2  + w53Out3 )
Giáº£i thuáº­t BP: Lan truyá»n tiáº¿n (6)
f(Net1)
Out6
2
f(Net )
f(Net3)
4
f(Net )
f(Net5)
f(Net6)
x1
x2
w65Out5
54
4
64
w Out
4+ w65Out5 )
Out6  =   f 
(w64Out
Giáº£i thuáº­t BP: Lan truyá»n tiáº¿n (7)
f(Net1)
Out6
2
f(Net )
f(Net3)
4
f(Net )
f(Net5)
f(Net6)
x1
x2
Giáº£i thuáº­t BP: TÃ­nh toÃ¡n lá»—i
f(Net1)
Out6
2
f(Net )
f(Net3)
f(Net4)
f(Net5)
d is the desired  
output value
f(Net6)
55
Î´6
1
56
x
x2
64
w
Î´4  =
f '(Net 4 )(w64Î´6 )
Giáº£i thuáº­t BP: Lan truyá»n ngÆ°á»£c (1)
Î´6
Î´4
f(Net1)
Out6
2
f(Net )
f(Net3)
f(Net4)
f(Net5)
f(Net6)
x1
x2
65
w
Î´5  =
f '(Net5 )(w65Î´6 )
57
Î´6
Î´5
f(Net1)
Out6
f(Net2)
f(Net3)
4
f(Net )
f(Net5)
f(Net6)
Giáº£i thuáº­t BP: Lan truyá»n ngÆ°á»£c (2)
x1
x2
41
w
Î´1  =
f '(Net1 )(w41Î´4  + w51Î´5 
)
58
w
Î´4
Î´5
Î´1
f(Net1)
Out6
f(Net2)
f(Net3)
4
f(Net )
f(Net5)
f(Net6)
Giáº£i thuáº­t BP: Lan truyá»n ngÆ°á»£c (3)
x1
x2
w
42
Î´2  =
f '(Net2 )(w42Î´4  + w52Î´5 
)
59
w
52
Î´4
Î´5
Î´2
f(Net1)
Out6
2
f(Net )
f(Net3)
4
f(Net )
f(Net5)
f(Net6)
Giáº£i thuáº­t BP: Lan truyá»n ngÆ°á»£c (4)
x1
x2
43
Î´3  =
f '(Net3 )(w43Î´4  + w53Î´5 )
w
Î´4
60
Î´5
Î´3
f(Net1)
Out6
2
f(Net ) w
f(Net3)
4
f(Net )
f(Net5)
f(Net6)
Giáº£i thuáº­t BP: Lan truyá»n ngÆ°á»£c (5)
x1
x2
1
61
w
1x
2
w
1x
2
2
1
1
w
1x
1x
w
1x
= w1x +Î·Î´1 x2
= w
+Î·Î´1 x1
Giáº£i thuáº­t BP: Cáº­p nháº­t trá»ng sá»‘ (1)
Î´1
f(Net1)
Out6
2
f(Net )
3
f(Net )
4
f(Net )
f(Net5)
f(Net6)
x1
2x
w
62
2
w
2 
x
2
2
1
1
w
2 x
2 x
w
2 x
= w2 x +Î·Î´2 x2
= w
+Î·Î´2 x1
Î´2
f(Net1)
Out6
2
f(Net )
f(Net3)
4
f(Net )
f(Net5)
f(Net6)
Giáº£i thuáº­t BP: Cáº­p nháº­t trá»ng sá»‘ (2)
x1
x2
2
63
w
3x
w
2
2
w
3 x
3 x1 3
1
3 x1
= w3 x +Î·Î´3 x2
w = w
+Î·Î´
x
Î´3
f(Net1)
Out6
2
f(Net )
3
f(Net )
f(Net4)
f(Net5)
f(Net6)
Giáº£i thuáº­t BP: Cáº­p nháº­t trá»ng sá»‘ (3)
1x
x2
w
41
w
42
43
w
w43 = w43 +Î·Î´4Out3
64
+Î·Î´4Out2
w
42 = w
42
w41 = w41 +Î·Î´4Out1
Î´4
f(Net1)
Out6
f(Net2)
f(Net3)
f(Net4)
f(Net5)
6
f(Net )
Giáº£i thuáº­t BP: Cáº­p nháº­t trá»ng sá»‘ (4)
x1
2x
51
w
w
52
w
53
w53 = w53 +Î·Î´5Out3
65
+Î·Î´5Out2
w
52 = w
52
w51 = w51 +Î·Î´5Out1
Î´5
f(Net1)
Out6
f(Net2)
f(Net3)
f(Net4)
f(Net5)
f(Net6)
Giáº£i thuáº­t BP: Cáº­p nháº­t trá»ng sá»‘ (5)
x1
x2
64
w
66
w
64 = w
64  
w65 = w65
Î´6
f(Net1)
Out6
2
f(Net )
3
f(Net )
4
f(Net )
f(Net5)
f(Net6)
w
65
Giáº£i thuáº­t BP: Cáº­p nháº­t trá»ng sá»‘ (6)
+Î·Î´5Out2
+Î·Î´5Out2
â– ThÃ´ng thÆ°á»ng, cÃ¡c trá»ng sá»‘ Ä‘Æ°á»£c khá»Ÿi táº¡o vá»›i cÃ¡c giÃ¡ trá»‹ nhá»
ngáº«u nhiÃªn
â– Náº¿u cÃ¡c trá»ng sá»‘ cÃ³ cÃ¡c giÃ¡ trá»‹ ban Ä‘áº§u lá»›n
â‘CÃ¡c hÃ m sigmoid sáº½ Ä‘áº¡t tráº¡ng thÃ¡i bÃ£o hÃ²a sá»›m
â‘Há»‡ thá»‘ng sáº½ táº¯c á»Ÿ má»™t Ä‘iá»ƒm yÃªn ngá»±a (saddle/stationary points)
67
BP: Khá»Ÿi táº¡o giÃ¡ trá»‹ cá»§a cÃ¡c trá»ng sá»‘
â– áº¢nh hÆ°á»Ÿng quan trá»ng Ä‘áº¿n hiá»‡u quáº£ vÃ  kháº£ nÄƒng há»™i tá»¥ cá»§a giáº£i 
thuáº­t há»c BP
â‘Má»™t giÃ¡ trá»‹ Î· lá»›n cÃ³ thá»ƒ Ä‘áº©y nhanh sá»± há»™i tá»¥ cá»§a quÃ¡ trÃ¬nh há»c, nhÆ°ng cÃ³  
thá»ƒ lÃ m cho há»‡ thá»‘ng bá» qua Ä‘iá»ƒm tá»‘i Æ°u toÃ n cá»¥c hoáº·c há»™i tá»¥ vÃ o Ä‘iá»ƒm 
khÃ´ng tá»‘t (saddle points)
â‘Má»™t giÃ¡ trá»‹ Î· nhá» cÃ³ thá»ƒ lÃ m cho quÃ¡ trÃ¬nh há»c kÃ©o dÃ i ráº¥t lÃ¢u
â– ThÆ°á»ng Ä‘Æ°á»£c chá»n theo thá»±c nghiá»‡m (experimentally) Ä‘á»‘i vá»›i má»—i 
bÃ i toÃ¡n
â– CÃ¡c giÃ¡ trá»‹ tá»‘t cá»§a tá»‘c Ä‘á»™ há»c á»Ÿ lÃºc báº¯t Ä‘áº§u (quÃ¡ trÃ¬nh há»c) cÃ³ thá»ƒ 
khÃ´ng tá»‘t á»Ÿ  má»™t thá»i Ä‘iá»ƒm sau Ä‘áº¥y
â‘Sá»­ dá»¥ng má»™t tá»‘c Ä‘á»™ há»c thÃ­ch nghi (Ä‘á»™ng)?
68
BP: Tá»‘c Ä‘á»™ há»c (Learning rate)
BP: Momentum
Î±Î”w(t)
-Î·âˆ‡E(tâ€™+1) + Î±Î”w(tâ€™)
-Î·âˆ‡E(tâ€™+1)
Î”w(tâ€™)
Bâ€™
Aâ€™
69
A
-Î·âˆ‡E(t+1) + Î±Î”w(t)
-Î·âˆ‡E(t+1)
Î±Î”w(t)
B
Î”w(t)
Gradient descent Ä‘á»‘i vá»›i má»™t hÃ m 
lá»—i báº­c 2 Ä‘Æ¡n giáº£n.
Quá»¹ Ä‘áº¡o bÃªn trÃ¡i khÃ´ng sá»­ dá»¥ng
momentum.
Quá»¹ Ä‘áº¡o bÃªn pháº£i cÃ³ sá»­ 
dá»¥ng momentum.
â€¢ PhÆ°Æ¡ng phÃ¡p Gradient descent cÃ³ 
thá»ƒ ráº¥t cháº­m náº¿u Î· nhá», vÃ  cÃ³ thá»ƒ 
dao Ä‘á»™ng máº¡nh náº¿u Î· quÃ¡ lá»›n
â€¢ Äá»ƒ giáº£m má»©c Ä‘á»™ dao Ä‘á»™ng, cáº§n 
Ä‘Æ°a  vÃ o má»™t thÃ nh pháº§n 
momentum
Î”w
(t) = -Î·âˆ‡E(t) + Î±Î”w(t-1)
trong Ä‘Ã³ Î± (âˆˆ[0,1]) lÃ  má»™t tham sá»‘  
momentum (thÆ°á»ng láº¥y =0.9)
â€¢ Dá»±a trÃªn cÃ¡c kinh nghiá»‡m, ta nÃªn 
chá»n
cÃ¡c giÃ¡ trá»‹ há»£p lÃ½ cho tá»‘c Ä‘á»™ há»c 
vÃ   momentum thoáº£ mÃ£n
(Î· + Î±) â‰³
1 
trong Ä‘Ã³ Î± > Î· Ä‘á»ƒ trÃ¡nh dao Ä‘á»™ng
BP: Sá»‘ lÆ°á»£ng cÃ¡c nÆ¡-ron á»Ÿ táº§ng áº©n
70
â– KÃ­ch thÆ°á»›c (sá»‘ nÆ¡-ron) cá»§a táº§ng áº©n lÃ  má»™t cÃ¢u há»i quan trá»ng  
Ä‘á»‘i vá»›i viá»‡c Ã¡p dá»¥ng cÃ¡c máº¡ng nÆ¡-ron lan truyá»n tiáº¿n nhiá»u táº§ng  
Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n thá»±c táº¿
â– Trong thá»±c táº¿, ráº¥t khÃ³ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh chÃ­nh xÃ¡c sá»‘ lÆ°á»£ng cÃ¡c 
nÆ¡-ron cáº§n thiáº¿t Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c má»™t Ä‘á»™ chÃ­nh xÃ¡c mong muá»‘n 
cá»§a há»‡  thá»‘ng
â– KÃ­ch thÆ°á»›c cá»§a táº§ng áº©n thÆ°á»ng Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh qua thÃ­ nghiá»‡m
(experiment/trial and test)
ANN: Giá»›i háº¡n há»c
71
â€¢ CÃ¡c hÃ m nhá»‹ phÃ¢n (Boolean functions)
â€¢ Báº¥t ká»³ hÃ m nhá»‹ phÃ¢n nÃ o cÅ©ng cÃ³ thá»ƒ há»c Ä‘Æ°á»£c (xáº¥p xá»‰ tá»‘t) bá»Ÿi má»™t ANN  
sá»­ dá»¥ng 1 táº§ng áº©n
â€¢ CÃ¡c hÃ m liÃªn tá»¥c (Continuous functions)
â€¢ Báº¥t ká»³ má»™t hÃ m liÃªn tá»¥c bá»‹ giá»›i háº¡n (bounded continuous function) nÃ o  
cÅ©ng cÃ³ thá»ƒ há»c Ä‘Æ°á»£c (xáº¥p xá»‰) bá»Ÿi má»™t ANN sá»­ dá»¥ng 1 táº§ng áº©n [Cybenko,  
1989; Hornik et al., 1991]
ANN: Æ¯u Ä‘iá»ƒm, NhÆ°á»£c Ä‘iá»ƒm
72
â€¢ CÃ¡c Æ°u Ä‘iá»ƒm
â€¢ Báº£n cháº¥t (vá» cáº¥u trÃºc) há»— trá»£ tÃ­nh toÃ¡n song song á»Ÿ má»©c cao
â€¢ Äáº¡t Ä‘á»™ chÃ­nh xÃ¡c cao trong nhiá»u bÃ i toÃ¡n (áº£nh, video, Ã¢m thanh, vÄƒn  
báº£n)
â€¢ Ráº¥t linh Ä‘á»™ng trong kiáº¿n trÃºc máº¡ng
â€¢ CÃ¡c nhÆ°á»£c Ä‘iá»ƒm
â€¢ KhÃ´ng cÃ³ quy táº¯c tá»•ng quÃ¡t Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cáº¥u trÃºc máº¡ng vÃ  cÃ¡c tham sá»‘
há»c tá»‘i Æ°u cho má»™t (lá»›p) bÃ i toÃ¡n nháº¥t Ä‘á»‹nh
â€¢ KhÃ´ng cÃ³ phÆ°Æ¡ng phÃ¡p tá»•ng quÃ¡t Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hoáº¡t Ä‘á»™ng bÃªn trong cá»§a  
ANN (vÃ¬ váº­y, há»‡ thá»‘ng ANN bá»‹ xem nhÆ° má»™t â€œhá»™p Ä‘enâ€)
â€¢ Ráº¥t khÃ³ (khÃ´ng thá»ƒ) Ä‘Æ°a ra giáº£i thÃ­ch cho ngÆ°á»i dÃ¹ng
â€¢ LÃ½ thuyáº¿t ná»n táº£ng cÃ²n Ã­t, Ä‘á»ƒ giÃºp giáº£i thÃ­ch Ä‘Æ°á»£c nhá»¯ng thÃ nh cÃ´ng 
trong thá»±c táº¿
ANN: Ãp dá»¥ng khi nÃ o?
73
â€¢ Dáº¡ng cá»§a hÃ m há»c khÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c trÆ°á»›c
â€¢ KhÃ´ng cáº§n thiáº¿t (hoáº·c khÃ´ng quan trá»ng) pháº£i Ä‘Æ°a ra giáº£i thÃ­ch  cho 
ngÆ°á»i dÃ¹ng Ä‘á»‘i vá»›i cÃ¡c káº¿t quáº£
â€¢ Cháº¥p nháº­n thá»i gian (khÃ¡) lÃ¢u cho quÃ¡ trÃ¬nh huáº¥n luyá»‡n
â€¢ CÃ³ thá»ƒ thu tháº­p má»™t lÆ°á»£ng lá»›n cÃ¡c nhÃ£n cho dá»¯ liá»‡u.
â€¢ CÃ¡c miá»n liÃªn quan Ä‘áº¿n: image, video, speech, text
-
CÃ¡c thÃ nh pháº§n cáº¥u táº¡o thÃ nh máº¡ng nÆ¡ ron nhÃ¢n táº¡o
-
CÃ¡c thuáº­t toÃ¡n há»c cho máº¡ng nÆ¡ ron nhÃ¢n táº¡o
Tá»•ng káº¿t buá»•i há»c

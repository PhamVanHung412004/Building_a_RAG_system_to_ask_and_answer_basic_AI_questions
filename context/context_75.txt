Pytorch
Deep Learning Framework
Quang-Vinh Dinh
Ph.D. in Computer Science
AI VIETNAM
All-in-One Course
â¢Introduction to PyTorch
â¢Model Construction 
â¢Model Training and Inference
â¢Applying Softmax for Image Data
Outline
Introduction
AI VIETNAM
All-in-One Course
Create a tensor in PyTorch
2
Introduction
â– Tensor
â– Broadcasting
AI VIETNAM
All-in-One Course
data 
1
3
2
4
Axis 0
Axis 1
1
+
2
4
3
5
Introduction
AI VIETNAM
All-in-One Course
data 
1
3
2
4
Axis 0
Axis 1
2
+
3
5
4
6
â– Tensor
â– Broadcasting
4
Introduction
â– Tensor
â– Important functions
AI VIETNAM
All-in-One Course
ğ‘ ğ‘‘= ğ’™âˆ’ğ’š2
Squared Difference
x 
1
2
3
4
ğ’™âˆ’ğ‘¦2 =
16
9
4
1
sd
5
Introduction
â– Tensor
â– Important functions
AI VIETNAM
All-in-One Course
ğ‘ ğ‘‘= à·
ğ‘–
ğ’™ğ‘–âˆ’ğ’šğ‘–2
Mean Squared Error
y 
5
5
5
5
16
9
4
1
sd
x 
1
2
3
4
Ïƒğ‘–ğ’™ğ‘–âˆ’ğ’šğ‘–2 = Ïƒğ‘–( 
) = 7.5
6
Introduction
AI VIETNAM
All-in-One Course
x 
1
3
2
4
Axis 0
Axis 1
y 
3
5
4
6
1
3
2
4
3
5
4
6
tensor2 
1
3
2
4
3
5
4
6
tensor1 
â– Tensor
â– Important functions
Introduction
AI VIETNAM
All-in-One Course
.argmax(axis=0) = 1
0
4
4
3
1
1
2
.argmax(axis=1) =
1
0
0
4
4
3
1
1
2
â– Tensor
â– Important functions
8
Introduction
AI VIETNAM
All-in-One Course
ğ‘¦= ğ‘¥2
ğ‘§= 3ğ‘¦+ 2
â– Gradient computation
ğ‘¥
+
âˆ™2
âˆ—
3
2
ğ‘§
9
Example 1
à·œğ‘¦
ğ‘¥
âˆ—
ğ‘¤
+
ğ‘
1 output
1+1 variables
Model
ğ‘¥ = 6.7
ğ‘= âˆ’0.0393
w = -0.655
ğ‘¦ = 9.1
à·œğ‘¦= ğ‘¥ğ‘¤+ ğ‘ 
Input
Label
Loss
ğ¿ğ‘œğ‘ ğ‘ =
à·œğ‘¦âˆ’ğ‘¦2
Parameters
10
à·œğ‘¦
ğ‘¥
âˆ—
ğ‘¤
+
ğ‘
1 output
1+1 variables
Model
ğ‘¥ = 6.7
ğ‘= 0.04
w = âˆ’0.34
ğ‘¦ = 9.1
à·œğ‘¦= ğ‘¥ğ‘¤+ ğ‘ 
Input
Label
Loss
ğ¿ğ‘œğ‘ ğ‘ =
à·œğ‘¦âˆ’ğ‘¦2
Parameters
Example 1
à·œğ‘¦
ğ‘¥
âˆ—
ğ‘¤
+
ğ‘
Model
ğ‘¥ = 6.7
ğ‘= 0.04
w = âˆ’0.34
ğ‘¦ = 9.1
à·œğ‘¦= ğ‘¥ğ‘¤+ ğ‘ 
Input
Label
Loss
ğ¿ğ‘œğ‘ ğ‘ =
à·œğ‘¦âˆ’ğ‘¦2
Parameters
ğ¿
ğ‘¦
ğ¿ğ‘¤
â€²
ğ¿ğ‘
â€²
Example 1
Model
ğ‘¥ = 6.7
ğ‘= âˆ’0.0393
w = -0.655
ğ‘¦ = 9.1
à·œğ‘¦= ğ‘¥ğ‘¤+ ğ‘ 
Input
Label
Loss
ğ¿ğ‘œğ‘ ğ‘ =
à·œğ‘¦âˆ’ğ‘¦2
Parameters
à·œğ‘¦
ğ‘¥
âˆ—
ğ‘¤
+
ğ‘
ğ¿
ğ‘¦
ğ¿ğ‘¤
â€² = 0
ğ¿ğ‘
â€² = 0
ğ¿ğ‘¤
â€² = â‹¯
ğ¿ğ‘
â€² = â‹¯
1
2
3
4
5
1
2
3
4
5
Example 1
13
Model
ğ‘¥ = 6.7
ğ‘= 0.04
w = -0.34
ğ‘¦ = 9.1
à·œğ‘¦= ğ‘¥ğ‘¤+ ğ‘ = -2.238 
Input
Label
Loss
à·œğ‘¦âˆ’ğ‘¦2 = 128.55
Parameters
Initialize b and 
w randomly
Example 1
Logistic Regression
à·œğ‘¦
ğ‘¥
âˆ—
ğ‘¤
+
ğ‘
1 output
1+1 variables
ğœ()
Model
Loss
0.1
ğ‘¦
ğ‘¥
-0.1
ğ‘¦= 0
ğ‘
ğ‘¤
à·œğ‘¦= ğœ(ğ‘§) =
1
1 + ğ‘’âˆ’ğ‘§
ğ‘§= ğ‘¤ğ‘¥+ ğ‘
âˆ’ylogà·œyâˆ’(1âˆ’y)log(1âˆ’à·œy )
Model
Loss
ğ’™= 1 1.5 0.2
1 4.1 1.3
ğœ½=
0.1
0.5
âˆ’0.1
à·ğ’š= ğœğ’™ğœ½ = 0.6963
0.8828
ğ¿(ğœ½) = 0.65815
ğ’š= 0
1
4
ğ›»ğœ½ğ¿=
0.28961
0.28217
âˆ’0.0064
ğ›‰âˆ’Î·Lğ›‰
â€² =
0.1
0.5
âˆ’0.1
âˆ’Î·
0.28961
0.28217
âˆ’0.0064
=
0.0971
0.4971
âˆ’0.099
5
3
Logistic Regression
Loss Functions
AI VIETNAM
All-in-One Course
ğ¿(à·ğ’š, ğ’š) = à·
ğ‘–
âˆ’ğ‘¦ğ‘–log à·œğ‘¦ğ‘–
â– Cross-entropy
ğ‘¥
L = âˆ’ğ‘¦0logà·œğ‘¦0 âˆ’ğ‘¦1logà·œğ‘¦1
ğ‘§0 = ğ‘¤0ğ‘¥+ ğ‘0
0.2
0.1
ğ‘¦
ğ‘§1 = ğ‘¤1ğ‘¥+ ğ‘1
âˆ’0.1
0.05
à·œğ‘¦0 =
ğ‘’ğ‘§0
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
à·œğ‘¦1 =
ğ‘’ğ‘§1
Ïƒğ‘–=0
1
ğ‘’ğ‘§ğ‘–
ğ’™= 1.4
4.5
ğ’š= [1 0]
[0 1]
ğ‘¤0
ğ‘0
ğ‘¤1
ğ‘1
ğ’›0 = 0.38
1.0
ğ’›1 = âˆ’0.09
âˆ’0.4
à·ğ’š0 = 0.615
0.802
à·ğ’š1 = 0.385
0.198
ğ¿= 1.0530
17
nn.Sequential()
AI VIETNAM
All-in-One Course
1
ğ‘§
Model
ğ‘¥1
ğ‘¥2
ğ‘¥3
dense(units=1)
input_shape = (3,)
1
ğ‘§1
ğ‘§2
ğ‘§3
Softmax
Model
ğ‘¥1
ğ‘¥2
ğ‘¥3
ğ‘¥4
ğ‘¦1
ğ‘¦2
ğ‘¦3
dense(units=3)
input_shape = (4,)
softmax
18
nn.Sequential()
AI VIETNAM
All-in-One Course
â€¦
Model
nn.Sequential()
1
ğ‘§1
ğ‘§2
ğ‘§3
ğ‘¥1
ğ‘¥2
ğ‘¥3
ğ‘¥4
1
ğ‘§
ğ‘¥1
ğ‘¥2
ğ‘¥3
nn.Sequential()
AI VIETNAM
All-in-One Course
1
ğ‘§1
ğ‘§2
ğ‘§3
Softmax
ğ‘¥1
ğ‘¥2
ğ‘¥3
ğ‘¥4
ğ‘¦1
ğ‘¦2
ğ‘¦3
â€¦
Model
nn.Sequential()
dense(units=3)
input_shape = (4,)
softmax
20
â¢Introduction to PyTorch
â¢Model Construction 
â¢Model Training and Inference
â¢Applying Softmax for Image Data
Outline
Model Construction
â– Linear regression
AI VIETNAM
All-in-One Course
Feature
Label
House price data
price = w âˆ—ğ‘ğ‘Ÿğ‘’ğ‘+ ğ‘
à·œğ‘¦ = ğ‘¤ğ‘¥+ ğ‘
Model
area
price
Input layer
a layer
dense(units=1)
input_shape = (1,)
1
w
ğ‘
21
Model Construction
AI VIETNAM
All-in-One Course
Features
Label
Advertising-based sale data
à·œğ‘¦ = ğ‘¤1ğ‘¥1 + ğ‘¤2ğ‘¥2 + ğ‘¤3ğ‘¥3 + ğ‘
Sale = ğ‘¤1 âˆ—ğ‘‡ğ‘‰+ ğ‘¤2 âˆ—ğ‘…ğ‘ğ‘‘ğ‘–ğ‘œ+ ğ‘¤3 âˆ—ğ‘ğ‘’ğ‘¤ğ‘ ğ‘ğ‘ğ‘ğ‘’ğ‘Ÿ+ ğ‘
Model
1
ğ‘§
ğ‘¥1
ğ‘¥2
ğ‘¥3
Input layer
a layer
dense(units=1)
input_shape = (3,)
â– Linear regression
Model Construction
AI VIETNAM
All-in-One Course
Boston House 
Price Data
Features
Label
medv = ğ‘¤1 âˆ—ğ‘¥1 + â‹¯+ ğ‘¤13 âˆ—ğ‘¥13 + ğ‘
Model
â– Linear regression
23
Model Construction
AI VIETNAM
All-in-One Course
medv = ğ‘¤1 âˆ—ğ‘¥1 + â‹¯+ ğ‘¤13 âˆ—ğ‘¥13 + ğ‘
Model
1
ğ‘§
ğ‘¥1
â€¦
ğ‘¥13
Input layer
a layer
dense(units=1)
input_shape = (13,)
â€¦
â– Linear regression
24
Model Construction
â– Logistic regression
AI VIETNAM
All-in-One Course
Feature
Label
z = ğœ½ğ‘‡ğ’™
Model
à·œğ‘¦=
1
1 + ğ‘’âˆ’ğ‘§
Input layer
A layer
dense(units=1)
input_shape = (1,)
1
à·œy
ğ‘¥
Sigmoid
function
ğ‘§
criterion = nn.BCEWithLogitsLoss()
25
Model Construction
â– Logistic regression
AI VIETNAM
All-in-One Course
Feature
Label
Model
à·œğ‘¦=
1
1 + ğ‘’âˆ’ğ‘§
ğ‘§= ğœ½ğ‘‡ğ’™
Input layer
A layer
dense(units=1)
input_shape = (2,)
1
à·œy
Sigmoid
function
ğ‘§
ğ‘¥2
ğ‘¥1
criterion = nn.BCEWithLogitsLoss()
26
Model Construction
â– Logistic regression
AI VIETNAM
All-in-One Course
Input layer
A layer
dense(units=1)
input_shape = (4,)
1
ğ‘§
Sigmoid
function
ğ‘¥1
ğ‘¥2
ğ‘¥3
ğ‘¥4
à·œy
Feature
Label
Model
à·œğ‘¦=
1
1 + ğ‘’âˆ’ğ‘§
ğ‘§= ğœ½ğ‘‡ğ’™
criterion = nn.BCEWithLogitsLoss()
27
Model Construction
â– Softmax regression
AI VIETNAM
All-in-One Course
Feature
Label
Iris Classification Data
ğ‘§1 = ğ‘¥ğ‘¤1 + ğ‘1
ğ‘§2 = ğ‘¥ğ‘¤2 + ğ‘2
à·œy1 =
ğ‘’ğ‘§1
Ïƒğ‘—=1
2
ğ‘’ğ‘§ğ‘—
à·œy2 =
ğ‘’ğ‘§1
Ïƒğ‘—=1
2
ğ‘’ğ‘§ğ‘—
Input layer
A layer
dense(units=2)
input_shape = (1,)
1
ğ‘¤1
à·œy1
ğ‘¥
Softmax
function
ğ‘¤1
ğ‘1
ğ‘¤2
ğ‘2
à·œy2
ğ‘§1
ğ‘§2
Activation layer
softmax
criterion = nn.CrossEntropyLoss()
28
Model Construction
â– Softmax regression
AI VIETNAM
All-in-One Course
Input layer
A layer
dense(units=3)
input_shape = (1,)
1
ğ‘¥
ğ‘§1
ğ‘§2
ğ‘§3
Softmax
à·œy1
à·œy2
à·œy3
criterion = nn.CrossEntropyLoss()
29
Model Construction
â– Softmax regression
AI VIETNAM
All-in-One Course
Input layer
A layer
dense(units=3)
input_shape = (4,)
1
ğ‘§1
ğ‘§2
ğ‘§3
Softmax
ğ‘¥1
ğ‘¥2
ğ‘¥3
ğ‘¥4
à·œy1
à·œy2
à·œy3
ğ’›= ğœ½ğ‘‡ğ’™
à·œğ²=
ğ‘’ğ’›
Ïƒğ‘–=1
ğ‘˜
ğ‘’ğ‘§ğ‘–
Forward computation
â¢Introduction to PyTorch
â¢Model Construction 
â¢Model Training and Inference
â¢Applying Softmax for Image Data
Outline
Training
â– Logistic regression
AI VIETNAM
All-in-One Course
â†’ TÃ­nh Ä‘áº¡o hÃ m
â†’ Cáº­p nháº­t tham sá»‘ (Stochastic 
gradient descent)
â†’ TÃ­nh output à·œğ‘¦
â†’ TÃ­nh loss (binary cross-entropy)
à·œğ‘¦= ğœ(ğ‘§) =
1
1 + ğ‘’âˆ’ğ’›
ğ¿(ğœ½) = âˆ’ğ²Tlogà·œğ²âˆ’(1âˆ’y)Tlog(1âˆ’à·œğ² )
ğ¿ğœ½
â€² = ğ±T(à·œğ²âˆ’ğ’š)
ğœ½= ğœ½âˆ’ğœ‚ğ¿ğœ½
â€²
ğ’›= ğœ½ğ‘‡ğ’™
Declare optimizer and loss function
Start training
31
Training
â– Softmax regression
AI VIETNAM
All-in-One Course
â†’ TÃ­nh Ä‘áº¡o hÃ m
â†’ Cáº­p nháº­t tham sá»‘ (Stochastic 
gradient descent)
â†’ TÃ­nh output à·œğ‘¦
â†’ TÃ­nh loss (cross-entropy)
ğœ½= ğœ½âˆ’ğœ‚ğ¿ğœ½
â€²
ğ’›= ğœ½ğ‘‡ğ’™
à·œğ²=
ğ‘’ğ’›
Ïƒğ‘–=1
ğ‘˜
ğ‘’ğ‘§ğ‘–
ğ¿(ğœ½) = âˆ’à·
ğ‘–=1
ğ‘˜
ğ‘¦ğ‘–logà·œğ‘¦ğ‘–
ğœ•ğ¿
ğœ•ğœ½ğ‘–
= ğ’™à·œğ‘¦ğ‘–âˆ’ğ‘¦ğ‘–
Delaration and Training
32
Training
â– Softmax regression
AI VIETNAM
All-in-One Course
ğ’›= ğœ½ğ‘‡ğ’™
à·œğ²=
ğ‘’ğ’›
Ïƒğ‘–=1
ğ‘˜
ğ‘’ğ‘§ğ‘–
Model
33
Training
â– Softmax regression
AI VIETNAM
All-in-One Course
ğ’›= ğœ½ğ‘‡ğ’™
à·œğ²=
ğ‘’ğ’›
Ïƒğ‘–=1
ğ‘˜
ğ‘’ğ‘§ğ‘–
Model
34
â¢Introduction to PyTorch
â¢Model Construction 
â¢Model Training and Inference
â¢Applying Softmax for Image Data
Outline
Image Classification: Image Data
â– Grayscale images
AI VIETNAM
All-in-One Course
(Height, Width)
Pixel p = scalar
0 â‰¤p â‰¤255
Resolution: #pixels
Resolution = HeightxWidth
35
Image Classification: Image Data
â– Color images
AI VIETNAM
All-in-One Course
(Channel, Height, Width,)
Pixel p=
ğ‘Ÿ
ğ‘”
ğ‘
0 â‰¤r,g,b â‰¤255
RGB color image
Resolution: #pixels
Resolution = HeightxWidth
36
Important Packages
â– Some functions
import urllib.request as req
req.urlretrieve(url, name)
To download a file
from PIL import Image
img = Image.open(name)
To open an image
import matplotlib.pyplot as plt
plt.imshow(img)
To show an image
37
MNIST dataset
Image Data
Grayscale images
Resolution=28x28
Training set: 60000 samples
Testing set: 10000 samples
38
Fashion-MNIST dataset
T-shirt
Trouser
Pullover
Dress
Coat
Sandal
Shirt
Sneaker
Bag
Ankle
Boot
Image Data
Grayscale images
Resolution=28x28
Training set: 60000 samples
Testing set: 10000 samples
Using 
Softmax 
Regression
784 Nodes
Input layer
Output
1
ğ‘§1
ğ‘§10
Softmax 
activation
Fully 
connect
10 Nodes
Output layer
28
28
784
flatten data
. . .
. . .
Data Sets
Demo
AI VIETNAM
All-in-One Course
Test Accuracy
 91.97%

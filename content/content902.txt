AI VIETNAM aivietnam.edu.vn
5 Chain-of-Thought Prompting
Phương pháp "Chain of Thought" (COT) được giới thiệu này như một cách để cải thiện hiệu suất
của các mô hình ngôn ngữ lớn (LLMs) trong việc giải quyết các bài toán đòi hỏi suy luận phức tạp.
Phương pháp này dựa trên việc kích thích mô hình tạo ra một chuỗi các bước suy nghĩ trung gian
tự nhiên, giúp dẫn đến kết quả cuối cùng. Điều này cho phép mô hình phân rã các vấn đề thành
các bước nhỏ hơn, làm cho quá trình suy luận trở nên minh bạch và dễ hiểu hơn. Từ kết quả thực
nghiệm trong paper "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"
Wei et al., 2022 cho thấy rằng việc sử dụng COT cải thiện đáng kể hiệu suất của mô hình trên các
tác vụ toán học, suy luận thông thường và suy luận biểu tượng. Phương pháp này mở ra hướng
mới trong việc tối ưu hóa các mô hình ngôn ngữ lớn, giúp chúng có khả năng giải quyết các tác vụ
phức tạp hơn mà không cần tinh chỉnh cụ thể cho từng tác vụ.
Hình 6: COT giúp các mô hình ngôn ngữ lớn giải quyết các nhiệm vụ suy luận số học phức tạp,
suy luận thông thường và suy luận biểu tượng.
6 Zero-shot Chain-of-Thought Prompting
Zero-shot Chain of Thought (Zero-shot COT) là một cách tiếp cận giúp cải thiện khả năng suy
luận của các mô hình ngôn ngữ lớn (LLMs) mà không cần hướng dẫn cụ thể từ một số ví dụ mẫu
từ dữ liệu(few-shot). Phương pháp này cho phép mô hình tạo ra chuỗi suy nghĩ một cách tự nhiên
và logic để giải quyết các bài toán, mà không cần dựa trên các ví dụ cụ thể đã được cung cấp
trước đó. 
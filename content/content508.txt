AI VIETNAM aivietnam.edu.vn
17
18 <|im_start|>assistant
19 """.strip()
20
21 encoding = tokenizer(prompt, return_tensors="pt").to(device)
22 with torch.inference_mode():
23 outputs = model.generate(
24 input_ids=encoding.input_ids,
25 attention_mask=encoding.attention_mask,
26 generation_config=generation_config
27 )
28
29 print(tokenizer.decode(outputs[0], skip_special_tokens=True))
Kết quả trả về của mô hình cho câu prompt trên được mô tả như hình dưới đây:
Hình 9: Câu trả lời của mô hình
10
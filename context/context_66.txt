Self-supervised and Semi-supervised Learning
January 8, 2024
Module
Graduate School of Data Science
Chonnam National University
Ph.D. Ngo Ba Hung
Email: ngohung@jnu.ac.kr
Facebook: https://www.facebook.com/hung.ngo.7121
2
Topic 1: Self-supervised Learning
Overview
Supervised Learning
Semi-supervised Learning
supervised learning provides a set of input-output pairs.
The entire dataset to be trained on samples has the
corresponding labels.
Semi-supervised learning provides a small set of input-output
pairs.
The model trained on small labeled data is tested on the large
unlabeled data (the unlabeled data is also used during training).
3
Topic 1: Self-supervised Learning
Overview
Unsupervised Learning
Self-supervised Learning
Unsupervised learning only input data has no corresponding
labels.
Using method for exploiting extracted representations (samples
having the similar features are grouped (clustered) together,
but samples having the different features keep far from each
other.
(K-NN, K-Mean, K-Medoids methods)
Self-supervised learning is categorized into to unsupervised
learning because no labels were given.
4
â‘Families of SSL
âš«Deep Metric Learning
â–ªSimCLR
â–ªNNCLR
â–ªSCL
âš«Self-distillation
â–ªSimSIAM
â–ªBYOL
â–ªDINO, DINO v2
âš«Canonical Correlation Analysis
â–ªVICReg
â–ªBarlowTwins
â–ªSWAV
â–ªEMP-SSL
Topic 1: Self-supervised Learning
Overview
5
â‘SimCLR*
âš«Concept of contrastive learning
Topic 1: Self-supervised Learning
Deep Metric Learning
Mathematic explanation
and its formulation:
*Chen, T., Kornblith, S., Norouzi, M., & Hinton, G. A simple framework for contrastive learning of visual representations. In International conference on machine learning. PMLR, 2020.
6
â‘SimCLR*
âš«Image transformation
âš«Getting representation
Topic 1: Self-supervised Learning
Deep Metric Learning
*Chen, T., Kornblith, S., Norouzi, M., & Hinton, G. A simple framework for contrastive learning of visual representations. In International conference on machine learning. PMLR, 2020.
7
â‘SimCLR*
âš«Projection head
â–ªâ„ğ‘–and â„ğ‘—are passed through a series of non-linear layers
Dense ïƒ Relu ïƒ Dense
Topic 1: Self-supervised Learning
Deep Metric Learning
*Chen, T., Kornblith, S., Norouzi, M., & Hinton, G. A simple framework for contrastive learning of visual representations. In International conference on machine learning. PMLR, 2020.
8
â‘SimCLR*
âš«Calculation of cosine similarity
âš«Calculate the probability of two similarity images
Topic 1: Self-supervised Learning
Deep Metric Learning
*Chen, T., Kornblith, S., Norouzi, M., & Hinton, G. A simple framework for contrastive learning of visual representations. In International conference on machine learning. PMLR, 2020.
9
â‘Simple Siamese network (SimSIAM)*
âš«Architecture
âš«Pseudo code of SimSIAM
Topic 1: Self-supervised Learning
Self-distillation
*Chen, Xinlei, and Kaiming He. "Exploring simple siamese representation learning." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR). 2021.
and
augmented images of an input image
Encoder uses ResNet backbone network
Projection uses multi-layer perceptron (MLP)
10
â‘Simple Siamese network (SimSIAM)*
âš«Output of the encoder
âš«Output of the predictor
âš«Minimize the negative cosine similarity
Topic 1: Self-supervised Learning
Self-distillation
*Chen, Xinlei, and Kaiming He. "Exploring simple siamese representation learning." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR). 2021.
(
)
(
)
1
1
p
h f x
(
)
(
)
2
2
p
h f x
(
)
1
1
z
f x
(
)
2
2
z
f x
11
â‘Simple Siamese network (SimSIAM)*
âš«Output of the encoder
âš«Output of the predictor
âš«Minimize the negative cosine similarity
Topic 1: Self-supervised Learning
Self-distillation
*Chen, Xinlei, and Kaiming He. "Exploring simple siamese representation learning." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR). 2021.
(
)
(
)
1
1
p
h f x
(
)
(
)
2
2
p
h f x
(
)
1
1
z
f x
(
)
2
2
z
f x
12
â‘SimSIAM*
âš«Summary
Topic 1: Self-supervised Learning
Self-distillation
*Chen, Xinlei, and Kaiming He. "Exploring simple siamese representation learning." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR). 2021.
Stop gradient
13
Topic 1: Self-supervised Learning
*Chen, Xinlei, and Kaiming He. "Exploring simple siamese representation learning." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR). 2021.
Implementation
â‘Implementation
âš«Dataset
â–ªCIFAR-10
â€“
4,000 images (labeled)
â€“
56,000 image (unlabeled)
âš«
Code 
âš«
Data prepare
14
Topic 1: Self-supervised Learning
*Chen, Xinlei, and Kaiming He. "Exploring simple siamese representation learning." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR). 2021.
Implementation
â‘Implementation
âš«Optimizer
âš«Training
15
Topic 1: Self-supervised Learning
*Chen, Xinlei, and Kaiming He. "Exploring simple siamese representation learning." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR). 2021.
Implementation
â‘Implementation
âš«Training
16
Topic 1: Self-supervised Learning
*Chen, Xinlei, and Kaiming He. "Exploring simple siamese representation learning." Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR). 2021.
Implementation
â‘Implementation
âš«Results
17
Topic 1: Self-supervised Learning
Extension 
â‘CLIP - Contrastive Language-Image Pre-training
*Radford, Alec, et al. "Learning transferable visual models from natural language supervision." International conference on machine learning. PMLR, 2021.
18
Topic 1: Self-supervised Learning
*Xuefeng Hu, Ke Zhang, Lu Xia, Albert Chen, Jiajia Luo, Yuyin Sun, Ken Wang, et.al; Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024.
Extension 
â‘ReCLIP
19
â‘Barlow Twins*
âš«Self-Supervised Learning via Redundancy Reduction
â–ªArchitecture
Topic 1: Self-supervised Learning
Method 
Canonical Correlation Analysis
*Zbontar, J., Jing, L., Misra, I., LeCun, Y., & Deny, S. Barlow twins: Self-supervised learning via redundancy reduction. In International Conference on Machine Learning. 2021, PMLR.
20
â‘Barlow Twins*
âš«Self-Supervised Learning via Redundancy Reduction
â–ªOperation
â€“ Invariance term
Â» Make the embedding from different image views
(augmentation versions) of the same image close each other
â€“ Redundancy reduction term
Topic 1: Self-supervised Learning
Method 
Canonical Correlation Analysis
*Zbontar, J., Jing, L., Misra, I., LeCun, Y., & Deny, S. Barlow twins: Self-supervised learning via redundancy reduction. In International Conference on Machine Learning. 2021, PMLR.
Deal with the on-diagonal terms
Deal with the off-diagonal terms
As close as possible to one
As close as possible to zero
21
â‘Barlow Twins*
âš«Self-Supervised Learning via Redundancy Reduction
Topic 1: Self-supervised Learning
Method 
Canonical Correlation Analysis
*Zbontar, J., Jing, L., Misra, I., LeCun, Y., & Deny, S. Barlow twins: Self-supervised learning via redundancy reduction. In International Conference on Machine Learning. 2021, PMLR.
Department of Multimedia Engineering
Dongguk University
Semi-supervise Learning (SSL)
January 8, 2024
Ph.D. Ba Hung Ngo    
Module
23
Method 
FixMatch*
Topic 2: Semi-supervised Learning
*Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence." Advances in neural information processing systems 33 (NeurIPS), 2020.
Data Setting:
Training Procedure:
24
Method 
FixMatch*
Topic 2: Semi-supervised Learning
*Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence." Advances in neural information processing systems 33 (NeurIPS), 2020.
â‘Data Augmentation
Strong 
Augmented
Weakly 
Augmented
25
â‘Model Training and Loss Functions
âš«Supervised Learning
Method 
FixMatch*
Topic 2: Semi-supervised Learning
*Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence." Advances in neural information processing systems 33 (NeurIPS), 2020.
26
â‘Model Training and Loss Functions
âš«Unsupervised Learning
â–ªPseudo labeling
â–ªConsistency regularization 
Method 
FixMatch*
Topic 2: Semi-supervised Learning
*Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence." Advances in neural information processing systems 33 (NeurIPS), 2020.
27
Method 
FixMatch*
Topic 2: Semi-supervised Learning
*Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence." Advances in neural information processing systems 33 (NeurIPS), 2020.
â‘Implementation
âš«Dataset
â–ªCIFAR-10
â€“
60,000 color images
â€“
10 classes
â€“
50,000 training images (labeled)
â€“
10,000 training images (unlabeled)
28
Method 
FixMatch*
Topic 2: Semi-supervised Learning
*Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence." Advances in neural information processing systems 33 (NeurIPS), 2020.
â‘Implementation
âš«Dataset
â–ªCIFAR-10
â€“
4,000 images (labeled)
â€“
56,000 image (unlabeled)
âš«
Code
29
Method 
FixMatch*
Topic 2: Semi-supervised Learning
*Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence." Advances in neural information processing systems 33 (NeurIPS), 2020.
â‘Implementation
âš«
Data preparation
âš«
Data Loader
30
Method 
FixMatch*
Topic 2: Semi-supervised Learning
*Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence." Advances in neural information processing systems 33 (NeurIPS), 2020.
â‘Implementation
âš«
Data transformation
31
Method 
FixMatch*
Topic 2: Semi-supervised Learning
*Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence." Advances in neural information processing systems 33 (NeurIPS), 2020.
â‘Implementation
âš«
Model selection
32
Method 
FixMatch*
Topic 2: Semi-supervised Learning
*Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence." Advances in neural information processing systems 33 (NeurIPS), 2020.
â‘Implementation
âš«
Model
33
Method 
FixMatch*
Topic 2: Semi-supervised Learning
*Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence." Advances in neural information processing systems 33 (NeurIPS), 2020.
â‘Implementation
âš«
Load data
34
Method 
FixMatch*
Topic 2: Semi-supervised Learning
*Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence." Advances in neural information processing systems 33 (NeurIPS), 2020.
â‘Implementation
âš«
Training
35
Method 
FixMatch*
Topic 2: Semi-supervised Learning
*Sohn, Kihyuk, et al. "Fixmatch: Simplifying semi-supervised learning with consistency and confidence." Advances in neural information processing systems 33 (NeurIPS), 2020.
â‘Implementation
âš«
Training
â–ªOn labeled data
36
Method 
DASH*
Topic 2: Semi-supervised Learning
*Xu, Yi, et al. "Dash: Semi-supervised learning with dynamic thresholding." International Conference on Machine Learning. PMLR, 2021.
â‘Semi-Supervised Learning with Dynamic Thresholding
37
THANK YOU

<<<<<<< HEAD
Node ID: b701a204-90f1-40a5-921c-d66486369a75
Text: AI VIETNAM aivietnam.edu.vn 20 driver.get(url) 21 22 # Start
crawl urls of image like brute force - the same mechanism with this
but add some feature 23 urls = [] 24 more_content_available = True 25
26 pbar = tqdm(total=self.max_images, desc=f"Fetching images for
{term}") # Set up for visualize progress 27 28 while len(urls) <
self.max_images an...
=======
AI VIETNAM aivietnam.edu.vn
20 driver.get(url)
21
22 # Start crawl urls of image like brute force - the same mechanism with this but add
some feature
23 urls = []
24 more_content_available = True
25
26 pbar = tqdm(total=self.max_images, desc=f"Fetching images for {term}") # Set up for
visualize progress
27
28 while len(urls) < self.max_images and more_content_available:
29 soup = BeautifulSoup(driver.page_source, "html.parser")
30 img_tags = soup.find_all("img")
31
32 for img in img_tags:
33 if len(urls) >= self.max_images:
34 break
35 if ’src’ in img.attrs:
36 href = img.attrs[’src’]
37 img_path = urljoin(url, href)
38 img_path = img_path.replace("_m.jpg", "_b.jpg").replace("_n.jpg", "_b.jpg")
.replace("_w.jpg", "_b.jpg")
39 if img_path == "https://combo.staticflickr.com/ap/build/images/getty/
IStock_corporate_logo.svg":
40 continue
41 urls.append(img_path)
42 pbar.update(1)
43
44 try:
45 load_more_button = WebDriverWait(driver, 10).until(
46 EC.element_to_be_clickable((By.XPATH, ’//button[@id="
yui_3_16_0_1_1721642285931_28620"]’))
47 )
48 load_more_button.click()
49 time.sleep(2)
50 except:
51 driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
52 time.sleep(2)
53
54 new_soup = BeautifulSoup(driver.page_source, "html.parser")
55 new_img_tags = new_soup.find_all("img", loading_="lazy")
56 if len(new_img_tags) == len(img_tags):
57 more_content_available = False
58 img_tags = new_img_tags
59
60 pbar.close()
61 driver.quit()
62 return urls
Đồng thời, sẽ rất lâu nếu chúng ta đợi một class tải xong url mới bắt đầu class số hai, vì thế ở đây khi
crawl url, ta sẽ áp dụng xử lí đa luồng multi-threading để phân luồng tải, thực hiện tải url cho nhiều
class cùng một lần và thực hiện liên tiếp, từ đó tốc độ crawl tăng lên đáng kể, giúp chúng ta tối ưu thời
gian xong việc thu thập dữ liệu.
25
>>>>>>> HEAD@{1}

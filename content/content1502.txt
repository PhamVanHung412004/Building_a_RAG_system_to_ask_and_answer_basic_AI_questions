<<<<<<< HEAD
Node ID: 21072173-3efe-4156-bfe0-8e72ac55deaf
Text: append ( loss . item ()) 28 29 avg_losses = { task : sum (
task_loss )/ len ( task_loss ) for task , task_loss in losses . items
()} 30 31 return avg_losses 32 33 34 def evaluation_epoch ( val_loader
, model , device ): 35 # iteration for all batches 36 model . eval ()
37 losses = {’ semantic ’: [] , ’depth ’: [] , ’total ’:[]} 38 with
torch . n...
=======
append ( loss . item ())
28
29 avg_losses = { task : sum ( task_loss )/ len ( task_loss ) for task , task_loss in losses .
items ()}
30
31 return avg_losses
32
33
34 def evaluation_epoch ( val_loader , model , device ):
35 # iteration for all batches
36 model . eval ()
37 losses = {’ semantic ’: [] , ’depth ’: [] , ’total ’:[]}
38 with torch . no_grad ():
39 for i, batch in tqdm ( enumerate ( val_loader )):
40 images = batch [’image ’]. to( device )
41 semantic = batch [’ semantic ’]. long ().to( device )
42 depth = batch [’depth ’]. to( device )
43
44 output = model ( images )
45
46 train_loss = {
47 ’ semantic ’: compute_loss ( output [’ semantic ’], semantic , ’ semantic ’),
48 ’depth ’: compute_loss ( output [’depth ’], depth , ’depth ’)
49 }
50
51 loss = train_loss [’ semantic ’] + train_loss [’depth ’]
52
53 losses [’ semantic ’]. append ( train_loss [’ semantic ’]. item ())
54 losses [’depth ’]. append ( train_loss [’depth ’]. item ())
55 losses [’total ’]. 
>>>>>>> HEAD@{1}

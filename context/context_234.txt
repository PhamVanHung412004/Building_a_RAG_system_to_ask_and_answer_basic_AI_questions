Text Classification
using Neural Network
Year 2023
Nguyen Quoc Thai
AI VIETNAM
All-in-One Course
1
2
CONTENT
(1) ‚Äì Introduction
(2) ‚Äì Preprocessing
(3) ‚Äì Representation
(4) ‚Äì Modeling
(5) ‚Äì Training, Prediction
1 - Introduction
!
3
Text Classification
v Input
√ò A fixed set of classes C = {c1, c2, ‚Ä¶, cN}
√ò A training set of M hand-labeled documents: (d1, c1),‚Ä¶, (dM, cN)
√ò A document d
v Output
√ò A learned classifier d => c (C) 
1 - Introduction
!
4
Text Classification
v Token-level Classification
√ò Sequence labeling: Word Segmentation, POS Tagging, NER,‚Ä¶
1 - Introduction
!
5
Text Classification
v Token-level Classification
√ò Sequence labeling: Word Segmentation, POS Tagging, NER,‚Ä¶
v Document-level Classification
√ò Sentiment Analysis
1 - Introduction
!
6
Text Classification
v Binary Classification
v Multiclass Classification
v Multilabel Classification
Binary Classification
Multiclass 
Classification
Multilabel 
Classification
1 - Introduction
!
7
Text Classification (Sentiment Analysis)
v NTC-SCV Dataset
v Document-level Classification
v Binary Classification (2 Classes: Positive, Negative)
Positive Example
Negative Example
M√¨nh ƒë∆∞·ª£c 1 c√¥ b·∫°n gi·ªõi_thi·ªáu ƒë·∫øn ƒë√¢y , t√¨m
ƒë·ªãa_ch·ªâkh√° d·ªÖ. Menu n∆∞·ªõc u·ªëng ch·∫•t kh·ªèi n√≥i
. M√¨nh mu·ªën c≈©ng ƒëc 8 lo·∫°i n∆∞·ªõc ·ªüƒë√¢y , m√≥n
n√†o c≈©ng ngon v√† b·ªï_d∆∞·ª°ng c·∫£.
Qu√°n ch·∫ø_bi·∫øn ƒë·ªì_ƒÉn l√¢u , C√°_Sapa n∆∞·ªõng 
u·ªõp r·∫•t d·ªü , s√≤ L√¥ng ko t∆∞∆°i , n∆∞·ªõc_ch·∫•m ko 
ngon\n T√≥m_l·∫°i s·∫Ω ko bao_gi·ªù gh√© n·ªØa , ƒÉn_d·ªü 
m√† u·ªïng ti·ªÅn
M·ªói l·∫ßn th√®m tr√† s·ªØa l√† l√†m 1 ly . Qu√°n d·ªÖ
ki·∫øm , kh√¥ng_gian l·∫°i r·ªông_r√£i . Nh√¢n_vi√™n th√¨
d·ªÖ_th∆∞∆°ng g·∫ßn_g≈©i . N√≥i_chung th√®m tr√† s·ªØa
l√† m√¨nh gh√© Qu√°n ·ªüƒë√¢y v√¨ g·∫ßn nh√† .
Qu√°n n√†y th·∫•y kh√° nhi·ªÅu ng∆∞·ªùi b·∫£o m√¨nh n√™n 
m√¨nh ƒë√£ ƒëi ƒÉn th·ª≠ , nh∆∞ng th·ª±c_s·ª± ƒÉn xong 
th·∫•y kh√¥ng ƒë∆∞·ª£c nh∆∞ mong_ƒë·ª£i l·∫Øm .
1 - Introduction
!
8
Pipeline
2 - Preprocessing
!
9
Text Preprocessing
v Language Detection
Vietnamese Language
Other Language
Qu√°n n√†y th·∫•y kh√° nhi·ªÅu ng∆∞·ªùi b·∫£o m√¨nh n√™n m√¨nh ƒë√£ ƒëi ƒÉn th·ª≠
, nh∆∞ng th·ª±c_s·ª±ƒÉn xong th·∫•y kh√¥ng ƒë∆∞·ª£c ngon. üëçüëç</p>
M√¨nh ƒë∆∞·ª£c 1 c√¥ b·∫°n gi·ªõi_thi·ªáu ƒë·∫øn ƒë√¢y , t√¨m ƒë·ªãa_ch·ªâkh√° d·ªÖ.
Menu n∆∞·ªõc u·ªëng ch·∫•t kh·ªèi n√≥i . https://foody.com
Visiting_Da_Nang frequently but this is the first time I have
found a coffee shop which has a creative design ( korean style )
The room is cheap ! ! ! ! It ' s near the city center . The staff is
so nice : - D üëçüëçüëçüëçüëçüëç\n
Language 
Detector
langid library
2 - Preprocessing
!
10
Text Preprocessing
v Language Detection
v Text Cleaning
Vietnamese Language
Qu√°n n√†y th·∫•y kh√° nhi·ªÅu ng∆∞·ªùi b·∫£o m√¨nh n√™n m√¨nh ƒë√£ ƒëi ƒÉn th·ª≠
, nh∆∞ng th·ª±c_s·ª±ƒÉn xong th·∫•y kh√¥ng ƒë∆∞·ª£c ngon. üëçüëç</p>
M√¨nh ƒë∆∞·ª£c 1 c√¥ b·∫°n gi·ªõi_thi·ªáu ƒë·∫øn ƒë√¢y , t√¨m ƒë·ªãa_ch·ªâkh√° d·ªÖ.
Menu n∆∞·ªõc u·ªëng ch·∫•t kh·ªèi n√≥i . https://foody.com
1 ‚Äì Removal URLs, HTML Tags
2 ‚Äì Removal punctuations, digits
3 ‚Äì Removal emoticons, flags,‚Ä¶
4 ‚Äì Normalize whitespace
5 ‚Äì Lowercasing
3 - Representation
!
11
Numeric Representation
ùíô=
1 1.4 0.2
1 1.5 0.2
1 3.0 1.1
1 4.1 1.3
ùíö=
0
0
1
1
Convert to Vector
3 - Representation
!
12
Numeric Representation
3 - Representation
!
13
Numeric Representation
Natural Language 
Understanding (NLU)
a computer‚Äôs ability to 
understand language
q Syntax
q Semantics
q Phonology
q Pragmatics
q Morphology
Natural Language 
Generation (NLG)
generate natural 
language by a computer
I go to school
[0 0 0 0 1 0 1 0 1 ]
Convert
3 - Representation
!
14
Numeric Representation
I go to school
I go to school
I
go
to
school
Tokenization
v Token-Level
v Document-Level
3 - Representation
!
15
Numeric Representation
Basic Representation
One-hot Encoding
Bag of Words (BoW)
Bag of N-grams
TF-IDF
3 - Representation
!
16
Numeric Representation
Distributed Representation 
(Dense Vector)
Word2Vec
Glove
Fasttext
ELMO
3 - Representation
!
17
One-hot Encoding
v Token-Level
v Represented by a V-dimensional binary vector of 0s and 1s
- All 0s barring the index, index = wid
- At this index, put 1
Dog bites man.
Man bites dog.
Dog eats meat.
Man eats food.
[dog, bites, man]
[man, bites, dog]
[dog, eats, meat]
[man, eats, food]
Preprocessing
Tokenization
IDX
Token
0
bites
1
dog
2
eats
3
food
4
man
5
meat
Vocabulary
Build
Vocabulary
3 - Representation
!
18
One-hot Encoding
v Token-Level
v Represented by a V-dimensional binary vector of 0s and 1s
- All 0s barring the index, index = wid
- At this index, put a 1
IDX
Token
0
bites
1
dog
2
eats
3
food
4
man
5
meat
Vocabulary
Dog bites man.
[dog, bites, man]
0
1
0
0
0
0
1
0
0
0
0
0
0
0
0
0
1
0
dog
bites
man
[[0, 1, 0, 0, 0, 0],
[1, 0, 0, 0, 0, 0],
[0, 0, 0, 0, 1, 0]]
3 - Representation
!
19
Bag of Words (BoW)
v Document-Level: Consider text as a bag (collection) of words
v Represented by a V-dimensional
Use: the number of occurrences of the word in the document
[dog, bites, man]
Vocabulary
IDX
0
1
2
3
4
5
Token
bites
dog
eats
food
man
meat
1
1
0
0
1
0
Counter
3 - Representation
!
20
Bag of Words (BoW)
v Document-Level: Consider text as a bag (collection) of words
v Represented by a V-dimensional
Use: the number of occurrences of the word in the document
[man, bites, dog]
1
1
0
0
1
0
[dog, eats, meat]
0
1
1
0
0
1
[man, eats, food]
0
0
0
1
1
0
[dog, bites, man]
1
1
0
0
1
0
3 - Representation
!
21
Index-based Representation
v Document-Level:
v Represented by a N-dimensional (length of sentence)
The ith component off the vector,  i = wid is index of the word w occurs in vocabulary
v Attention to the order of words in the sentence
v Use word-based tokenization
v Build a vocabulary
3 - Representation
!
22
Index-based Representation
IDX
Token
0
<unk>
1
dog
2
man
3
bites
4
eats
5
food
6
meat
3 - Representation
!
23
Index-based Representation
IDX
Token
0
<unk>
1
dog
2
man
3
bites
4
eats
5
food
6
meat
Vocabulary
[man, bites, dog]
[dog, eats, meat]
[man, eats, food]
2
4
5
[dog, bites, man]
1
4
6
2
3
1
1
3
2
v Use word-based tokenization
v Build a vocabulary
v Convert text into features
3 - Representation
!
24
Index-based Representation
IDX
Token
0
<unk>
1
dog
2
man
3
bites
4
eats
5
food
6
meat
Vocabulary
[dog, bites, man]
1
3
2
v Use word-based tokenization
v Build a vocabulary
v Convert text into features
3 - Representation
!
25
Index-based Representation
v Padding all sentences => the same length
v Append token ‚Äú<pad>‚Äù
[dog, bites, man]
2
4
3
[dog, dog, bites, man]
2
2
4
3
2
4
3
0
Padding
IDX
Token
0
<pad>
1
<unk>
2
dog
3
man
4
bites
5
eats
6
food
7
meat
Vocabulary
3 - Representation
!
26
Index-based Representation
v Padding all sentences => the same length
v Append token ‚Äú<pad>‚Äù
IDX
Token
0
<pad>
1
<unk>
2
dog
3
man
4
bites
5
eats
6
food
7
meat
Vocabulary
3 - Representation
!
27
Index-based Representation
v Padding all sentences => the same length
v Append token ‚Äú<pad>‚Äù
v Truncating
[dog, bites, man]
2
4
3
[dog, dog, bites, man]
2
2
4
3
IDX
Token
0
<pad>
1
<unk>
2
dog
3
man
4
bites
5
eats
6
food
7
meat
Vocabulary
Truncating
2
2
4
3 - Representation
!
28
Index-based Representation
v Padding all sentences => the same length
v Append token ‚Äú<pad>‚Äù
v Truncating
IDX
Token
0
<pad>
1
<unk>
2
dog
3
man
4
bites
5
eats
6
food
7
meat
Vocabulary
3 - Representation
!
29
Dense Representation
v Token-level: dense vectors (low dimensional, hardly any zeros)
v Learn during training (weights)
IDX
Token
0
<pad>
1
<unk>
2
dog
3
man
4
bites
5
eats
6
food
7
meat
Vocabulary
[dog, bites, man]
[man, bites, dog]
[dog, eats, meat]
[man, eats, food]
0
0.1
3.1
1
0.5
2.5
2
1.3
0.6
3
0.4
0.1
4
0.7
1.4
5
2.3
1.7
6
2.5
2.5
7
0.3
1.2
Embedding Matrix
(Lookup Table)
Initial 
weights
v Index-based Representation
v Get vectors from embedding matrix
3 - Representation
!
30
Dense Representation
[dog, bites, man]
[man, bites, dog]
2
4
3
3
4
2
Input matrix
Index-based Representation
Input shape: 2x3
IDX
Token
0
<pad>
1
<unk>
2
dog
3
man
4
bites
5
eats
6
food
7
meat
v Index-based Representation
3 - Representation
!
31
Dense Representation
[dog, bites, man]
[man, bites, dog]
2
4
3
3
4
2
Input matrix
Index-based Representation
Input shape: 2x3
0
0.1
3.1
1
0.5
2.5
2
1.3
0.6
3
0.4
0.1
4
0.7
1.4
5
2.3
1.7
6
2.5
2.5
7
0.3
1.2
Embedding Matrix
(Lookup Table)
w[2]
w[4]
w[3]
w[3]
w[4]
w[2]
Select 
Operation
0.6 1.4 0.1
1.3 0.7 0.4
0.4 0.7 1.3
Shape: 2x3x2
Output matrix
3 - Representation
!
32
Dense Representation
3 - Representation
!
33
Dense Representation
3 - Representation
!
34
Dense Representation
[dog, bites, man]
[man, bites, dog]
2
4
3
3
4
2
Input matrix
Index-based Representation
Input shape: N x M
0
0.1
3.1
1
0.5
2.5
2
1.3
0.6
Embedding Matrix
(Lookup Table)
V   Vocabulary
D: Embedding Dim
IDX
Token
0
<pad>
1
<unk>
2
dog
0.6 1.4 0.1
1.3 0.7 0.4
0.4 0.7 1.3
N Samples
M: Sequence Length
Shape: V x D
Output shape: N x M x D
Model
4 - Modeling
!
35
Classifier
X1
X2
XN
Embedding Layer
Dense vector
Flatten
Classifier
Input
4 - Modeling
!
36
Classifier
X1
X2
XN
Embedding Layer
Dense vector
Flatten
Classifier
Input
EmbeddingBag
4 - Modeling
!
37
Classifier
X1
X2
XN
EmbeddingBag Layer
Classifier
Input
4 - Modeling
!
38
EmbeddingBag Layer
[dog, bites, man]
[man, bites, dog]
2
4
3
3
4
2
Input matrix
Index-based Representation
Input shape: N x M
V   Vocabulary
IDX
Token
0
<pad>
1
<unk>
2
dog
N Samples
M
Sequence Length
2
4
3
3
4
2
0
3
Inputs
Offsets
4 - Modeling
!
39
EmbeddingBag Layer
Embedding Matrix
(Lookup Table)
1.3
0.6
0.7
1.4
0.4
0.1
Slicing: [0:3]
2
4
3
3
4
2
0
3
Inputs
Offsets
0
0.1
3.1
1
0.5
2.5
2
1.3
0.6
3
0.4
0.1
4
0.7
1.4
5
2.3
1.7
6
2.5
2.5
7
0.3
1.2
2
4
3
2.4
2.1
0.4
0.1
0.7
1.4
1.3
0.6
Slicing: [3:]
3
4
2
2.4
2.1
2.4
2.1
2.4
2.1
Shape: N x D
4 - Modeling
!
40
EmbeddingBag Layer
4 - Modeling
!
41
EmbeddingBag Layer
4 - Modeling
!
42
Model
5 ‚Äì Training, Prediction
!
43
Source Code
Thanks!
Any questions?
44

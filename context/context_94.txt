Chá»§ Ä‘á»:
MÃ´ hÃ¬nh ngÃ´n ngá»¯
TrÃ­ch chá»n Ä‘áº·c trÆ°ng trong NLP 
Má»¥c Ä‘Ã­ch buá»•i há»c
â—
Há»c viÃªn náº¯m Ä‘Æ°á»£c cÃ¡c ká»¹ thuáº­t trÃ­ch chá»n Ä‘áº·c trÆ°ng trong 
xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn
Ná»™i dung chÃ­nh
MÃ´ hÃ¬nh ngÃ´n ngá»¯
TrÃ­ch chá»n Ä‘áº·c trÆ°ng
MÃ´ hÃ¬nh ngÃ´n ngá»¯
MÃ´ hÃ¬nh hoÃ¡ ngÃ´n ngá»¯
â—
MÃ´ hÃ¬nh ngÃ´n ngá»¯ lÃ  mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n xÃ¡c xuáº¥t cá»§a má»™t chuá»—i 
cÃ¡c tá»«.
â—‹
P(W) = P(w1, w2, ..., wn)
â—‹
VÃ­ dá»¥:
â– 
S1 = â€œcon mÃ¨o nháº£y qua con chÃ³â€, P(S1) ~ 1
â– 
S2 = â€œqua con mÃ¨o con chÃ³ nháº£yâ€, P(S2) ~ 0
á»¨ng dá»¥ng
â—
Dá»‹ch mÃ¡y
â—‹
P(high winds tonight) > P (large winds tonight)
â—
Sá»­a lá»—i vÄƒn báº£n
â—‹
The office is about fifteen minuets from my house
â—‹
P (â€œabout fifteen minutes fromâ€) > P(about fifteen minuets from) 
â—
Nháº­n dáº¡ng giá»ng nÃ³i
â—‹
P(I saw a van) > P(eyes awe of an)
â—
Nháº­n dáº¡ng chá»¯ viáº¿t
â—‹
P(Act naturally) > P(Abt naturally)
â—
TÃ³m táº¯t, há»i â€“ Ä‘Ã¡p, ..
XÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n
XÃ¡c suáº¥t cÃ³ Ä‘iá»u kiá»‡n
â—
MÃ´ HÃ¬nh NgÃ´n Ngá»¯ = mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n tá»«
â—
Quy táº¯c dÃ¢y chuyá»n
P(x1,x2,x3,...,xn) = P(x1)P(x2|x1)P(x3|x1,x2)...P(xn|x1,...,xn-1)
â—
VÃ­ dá»¥
â—‹
P(â€œits water is so transparentâ€) = P(its) Ã— P(water|its) Ã— P(is|its 
water) Ã— P(so|its water is) Ã— P(transparent|its water is so)
â—
MÃ´ hÃ¬nh ngÃ´n ngá»¯ lÃ  mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n tá»« dá»±a trÃªn cÃ¡c tá»« phÃ­a 
trÆ°á»›c
MÃ´ hÃ¬nh ngÃ´n ngá»¯
â—
TÃ­nh xÃ¡c suáº¥t cá»§a tá»« trong ngá»¯ cáº£nh dá»±a trÃªn N-gram
XÃ¡c suáº¥t cá»§a tá»«
CÃ³ váº¥n Ä‘á» gÃ¬ vá»›i cÃ¡ch tÃ­nh trÃªn?
Giáº£ thuyáº¿t Markov
Giáº£ thuyáº¿t Markov
Unigram (1-gram): xÃ¡c suáº¥t cá»§a má»™t tá»« khÃ´ng phá»¥ thuá»™c vÃ o tá»« phÃ­a trÆ°á»›c
MÃ´ hÃ¬nh n-gram
Bigram (2-gram): xÃ¡c suáº¥t má»™t tá»« xuáº¥t hiá»‡n sau má»™t tá»« cho trÆ°á»›c
Trigram (3-gram): xÃ¡c suáº¥t má»™t tá»« phá»¥ thuá»™c vÃ o 2 tá»« phÃ­a trÆ°á»›c
N-gram: xÃ¡c suáº¥t 1 tá»« phá»¥ thuá»™c vÃ o N tá»« phÃ­a trÆ°á»›c
Sá»­ dá»¥ng Maximum Likelihood Estimate
Æ¯á»›c lÆ°á»£ng xÃ¡c suáº¥t
VÃ­ dá»¥
Thá»‘ng kÃª trÃªn dá»¯ liá»‡u
â—
Berkeley Restaurant Project (BeRP)
â—
BeRP chá»©a cÃ¡c cÃ¢u tÆ° váº¥n trong lÄ©nh vá»±c nhÃ  hÃ ng thÃ nh phá»‘ 
Berkeley, California
â—
Chá»©a 9222 cÃ¢u. VÃ­ dá»¥:
â—‹
can you tell me about any good cantonese restaurants close by â€¢ 
mid priced thai food is what iâ€™m looking for
â—‹
tell me about chez panisse
â—‹
can you give me a listing of the kinds of food that are available â€¢ iâ€™m 
looking for a good place to eat breakfast
â—‹
when is caffe venezia open during the day 
â—‹
...
Äáº¿m Ä‘á»“ng xuáº¥t hiá»‡n
XÃ¡c xuáº¥t Bigram
Chuáº©n hÃ³a báº±ng Unigrams:
Káº¿t quáº£
XÃ¡c xuáº¥t Bigram
TÃ­nh xÃ¡c suáº¥t cÃ¢u dá»±a trÃªn cÃ¡c bigram
P(<s> I want english food </s>) =
P(I|<s>)
Ã— P(want|I)
Ã— P(english|want)
Ã— P(food|english)
Ã— P(</s>|food)
= .000031
TÃ­nh xÃ¡c suáº¥t cÃ¢u dá»±a trÃªn cÃ¡c bigram
CÃ¡c xÃ¡c suáº¥t Ä‘Ã£ tÃ­nh Ä‘Æ°á»£c
â—
P(english|want) = .0011
â—
P(chinese|want) = .0065
â—
P(to|want) = .66
â—
P(eat | to) = .28
â—
P(food | to) = 0
â—
P(want | spend) = 0
â—
P (i | <s>) = .25
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ sáºµn
Google Book N-grams
â—
http://ngrams.googlelabs.com/
KenLM
â—
https://kheafield.com/code/kenlm/
ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
Extrinsic evaluation - ÄÃ¡nh giÃ¡ ngoÃ i
â—
MÃ´ hÃ¬nh ngÃ´n ngá»¯ A vÃ  B Ä‘Æ°á»£c sá»­ dá»¥ng trong má»™t bÃ i toÃ¡n X khÃ¡c:
â—‹
BÃ i toÃ¡n speech recognition, spelling, machine translation
â—
So sÃ¡nh mÃ´ hÃ¬nh A vá»›i mÃ´ hÃ¬nh B tÆ°Æ¡ng á»©ng vá»›i so sÃ¡nh káº¿t quáº£ á»©ng 
dá»¥ng A vá»›i B trong bÃ i toÃ¡n X.
ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
Intrinsic evaluation - ÄÃ¡nh giÃ¡ trong
â—
Sá»­ dá»¥ng dá»¯ liá»‡u Test lÃ  cÃ¡c cÃ¢u trong ngÃ´n ngá»¯ 
â—
Sá»­ dá»¥ng Ä‘á»™ Ä‘o Perplexity (Ä‘á»™ phá»©c táº¡p)
â—‹
ÄÃ¡nh giÃ¡ xáº¥p xá»‰ khÃ´ng tá»‘t
â– 
Chá»‰ khi dá»¯ liá»‡u test giá»‘ng dá»¯ liá»‡u train (vá» bá»™ tá»« vá»±ng)
â– 
Tá»‘t cho thÃ­ nghiá»‡m nhÆ°ng khÃ´ng tá»‘t cho thá»±c táº¿
Shannon Game:
â—
Ta cÃ³ thá»ƒ tiÃªn Ä‘oÃ¡n tá»« tiáº¿p theo khÃ´ng?
I always order pizza with cheese and ____
The 33rd President of the US was ____
I saw a ____
â—
CÃ³ thá»ƒ dÃ¹ng unigram khÃ´ng?
MÃ´ hÃ¬nh tá»‘t sáº½ gÃ¡n xÃ¡c suáº¥t cao cho tá»« thÆ°á»ng xuyÃªn xuáº¥t hiá»‡n á»Ÿ vá»‹ trÃ­ dá»± 
Ä‘oÃ¡n
Ã tÆ°á»Ÿng cá»§a Perplexity
Äá»™ phá»©c táº¡p tÆ°Æ¡ng Ä‘Æ°Æ¡ng sá»‘ trÆ°á»ng há»£p ráº½ nhÃ¡nh
â€¢ Giáº£ thiáº¿t 1 cÃ¢u gá»“m cÃ¡c chá»¯ sá»‘ ngáº«u nhiÃªn. Khi Ä‘Ã³ Ä‘á»™ phá»©c táº¡p cá»§a
cÃ¢u dá»±a trÃªn 1 mÃ´ hÃ¬nh sáº½ gÃ¡n P=1/10 Ä‘/v má»—i chá»¯ sá»‘.
Äá»™ phá»©c táº¡p (Perplexity)
Äá»™ phá»©c táº¡p tÆ°Æ¡ng Ä‘Æ°Æ¡ng sá»‘ trÆ°á»ng há»£p ráº½ nhÃ¡nh
â€¢ Giáº£ thiáº¿t 1 cÃ¢u gá»“m cÃ¡c chá»¯ sá»‘ ngáº«u nhiÃªn. Khi Ä‘Ã³ Ä‘á»™ phá»©c táº¡p cá»§a
cÃ¢u dá»±a trÃªn 1 mÃ´ hÃ¬nh sáº½ gÃ¡n P=1/10 Ä‘/v má»—i chá»¯ sá»‘.
Cá»±c tiá»ƒu perplexity tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i viá»‡c cá»±c Ä‘áº¡i xÃ¡c suáº¥t
Äá»™ phá»©c táº¡p (Perplexity)
Perplexity tháº¥p = mÃ´ hÃ¬nh tá»‘t
â€¢ Bá»™ dá»¯ liá»‡u WSJ
â€¢ Táº­p huáº¥n luyá»‡n 38 triá»‡u tá»«, kiá»ƒm tra 1.5 triá»‡u tá»«
Äá»™ phá»©c táº¡p (Perplexity)
GiÃ¡ trá»‹ phÃ¹ há»£p cá»§a n lÃ  bao nhiÃªu?
â—
Vá» máº·t lÃ½ thuyáº¿t, ráº¥t khÃ³ xÃ¡c Ä‘á»‹nh
â—
Tuy nhiÃªn: nhiá»u nháº¥t cÃ³ thá»ƒ (â†’ tiá»‡m cáº­n vá»›i mÃ´ hÃ¬nh â€œhoÃ n háº£oâ€)
â—
Vá» máº·t thá»±c nghiá»‡m, phá»• biáº¿n n = 3
â—‹
Æ¯á»›c lÆ°á»£ng tham sá»‘? (Ä‘á»™ tin cáº­y, dá»¯ liá»‡u, lÆ°u trá»¯, khÃ´ng gian, ...)
â—‹
4 lÃ  quÃ¡ lá»›n: |V|=60k â†’ 1.296 x 1019 tham sá»‘
â—‹
nhÆ°ng: 6-7 cÃ³ thá»ƒ náº¿u cÃ³ Ä‘á»§ dá»¯ liá»‡u: trong thá»±c táº¿, chÃºng ta cÃ³ thá»ƒ 
khÃ´i phá»¥c báº£n gá»‘c tá»« 7-grams!
GiÃ¡ trá»‹ n
N-grams chá»‰ tiÃªn Ä‘oÃ¡n tá»« tá»‘t náº¿u táº­p test giá»‘ng táº­p train.
Ta cáº§n táº¡o ra mÃ´ hÃ¬nh cÃ³ tÃ­nh tá»•ng quÃ¡t, nghÄ©a lÃ  cÃ³ thá»ƒ xá»­ lÃ½ cÃ¡c 
trÆ°á»ng há»£p xÃ¡c suáº¥t = 0 (nhá»¯ng TH khÃ´ng cÃ³ trong táº­p train nhÆ°ng cÃ³ 
trong táº­p test)
Hiá»‡n tÆ°á»£ng quÃ¡ khá»›p dá»¯ liá»‡u (overfitting)
Khi chÃºng ta cÃ³ thá»‘ng kÃª thÆ°a:
P(w | denied the) 
â—
3 allegations
â—
2 reports
â—
1 claims
â—
1 request
XÃ¡c suáº¥t trÃªn táº­p train:
Giáº£m xÃ¡c suáº¥t cÃ¡c n-gram cÃ³ xÃ¡c suáº¥t lá»›n 
hÆ¡n 0 Ä‘á»ƒ bÃ¹ cho cÃ¡c n-gram cÃ³ xÃ¡c suáº¥t 
báº±ng 0.
â—
P(w | denied the) 
â—
2.5 allegations 
â—
1.5 reports
â—
0.5 claims
â—
0.5 request
â—
2 other
Váº¥n Ä‘á» lÃ m má»‹n
TrÃ­ch chá»n Ä‘áº·c trÆ°ng
PhÃ¢n loáº¡i vÄƒn báº£n
Äáº§u vÃ o:
â—
Má»™t vÄƒn báº£n d
â—
Má»™t táº­p cÃ¡c lá»›p C = {c1, c2, ..., cJ}
Äáº§u ra:
Dá»± Ä‘oÃ¡n lá»›p c âˆˆ C cá»§a d
â—
Chá»n Ä‘áº·c trÆ°ng
â—
Luáº­t (Rules) dá»±a vÃ o káº¿t há»£p cÃ¡c Ä‘áº·c trÆ°ng cá»§a tá»« hoáº·c cÃ¡c 
Ä‘áº·c trÆ°ng khÃ¡c
â—‹
spam: black-list-address OR (â€œdollarsâ€ ANDâ€œhave been 
selectedâ€)
â—
Äá»™ chÃ­nh xÃ¡c cÃ³ thá»ƒ cao
â—‹
Náº¿u luáº­t Ä‘Æ°á»£c thiáº¿t káº¿ cáº©n tháº­n bá»Ÿi chuyÃªn gia
â—
XÃ¢y dá»±ng vÃ  duy trÃ¬ nhá»¯ng bá»™ luáº­t nÃ y lÃ  tá»‘n kÃ©m
Luáº­t thá»§ cÃ´ng
â—
Äáº§u vÃ o:
â—‹
Má»™t vÄƒn báº£n (email) d
â—‹
Má»™t táº­p cÃ¡c lá»›p C = {c1, c2,..., cJ}
â—‹
Má»™t táº­p dá»¯ liá»‡u huáº¥n luyá»‡n gá»“m m máº«u Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ£n 
(d1,c1),....,(dm,cm)
â—
Äáº§u ra:
â—‹
Má»™t bá»™ phÃ¢n lá»›p Î³:d â†’ c
Há»c mÃ¡y cÃ³ giÃ¡m sÃ¡t
â—
Sá»­ dá»¥ng báº¥t ká»³ cÃ¡c loáº¡i phÃ¢n lá»›p
â—‹
NaÃ¯ve Bayes
â—‹
Logistic regression
â—‹
Support-vector machines
â—‹
Neural Network
â—‹
â€¦
Má»™t sá»‘ phÆ°Æ¡ng phÃ¡p
Há»‡ thá»‘ng phÃ¢n loáº¡i vÄƒn báº£n
â—
Má»™t biáº¿n cÃ³ thá»ƒ Ä‘o lÆ°á»ng, khÃ¡c biá»‡t cá»§a má»™t thá»© mÃ  chÃºng ta 
muá»‘n láº­p mÃ´ hÃ¬nh.
â—
ChÃºng ta thÆ°á»ng chá»n Ä‘áº·c trÆ°ng mÃ  há»¯u Ã­ch Ä‘á»ƒ xÃ¡c Ä‘á»‹nh thá»© 
gÃ¬ Ä‘Ã³, vÃ­ dá»¥ nhÆ° Ä‘á»ƒ phÃ¢n lá»›p (loáº¡i).
â—‹
VÃ­ dá»¥: CÃ´ gÃ¡i Ä‘Ã³ ráº¥t Ä‘áº¹p trong bá»¯a tiá»‡c hÃ´m Ä‘Ã³.
â—
ChÃºng ta thÆ°á»ng cáº§n má»™t sá»‘ Ä‘áº·c trÆ°ng Ä‘á»ƒ láº­p mÃ´ hÃ¬nh Ä‘áº§y 
Ä‘á»§.
â€“ nhÆ°ng khÃ´ng quÃ¡ nhiá»u!
Äáº·c trÆ°ng (Features)
â—
Numeric Representation
Äáº·c trÆ°ng (Features)
â—
Numeric Representation
Äáº·c trÆ°ng (Features)
Tá»« vÄƒn báº£n sang Ä‘áº·c trÆ°ng
CÃ³ thá»ƒ viá»‡c sinh ra cÃ¡c Ä‘áº·c trÆ°ng há»¯u Ã­ch báº±ng thá»§ cÃ´ng 
(feature engineering)
â—
Äáº·c trÆ°ng thá»‘ng kÃª: Ä‘á»™ dÃ i, vá»‹ trÃ­,...
â—
Sá»­ dá»¥ng Ä‘iá»ƒm tá»« cÃ¡c tá»« Ä‘iá»ƒn:
â—‹
Sentiment dictionaries: SentiWordNet, SentiWords, ... 
â—‹
Subjectivity/objectivity dictionaries: MPQA
â—
CÃ¡c Ä‘áº·c trÆ°ng cÃº phÃ¡p: 
â—‹
POS tags
â—
Äáº·c trÆ°ng cho bÃ i toÃ¡n: e.g. number of emojis (ğŸ˜, ğŸ˜˜)
Biá»ƒu diá»…n vÄƒn báº£n
GiÃ¡ trá»‹ cá»§a má»™t vÃ i Ä‘áº·c trÆ°ng cá»§a má»™t quan sÃ¡t cÃ³ thá»ƒ Ä‘Æ°a vÃ o 
má»™t vector
Vector Ä‘áº·c trÆ°ng
CÃ¡c Ä‘áº·c trÆ°ng sáº½ há»¯u Ã­ch trong viá»‡c phÃ¢n biá»‡t giá»¯a cÃ¡c thá»ƒ loáº¡i
Vector Ä‘áº·c trÆ°ng
Biá»ƒu diá»…n vÄƒn báº£n
One-hot encoding
â—
Token-Level
â—
ÄÆ°á»£c biá»ƒu diá»…n báº±ng vectÆ¡ nhá»‹ phÃ¢n
One-hot encoding
â—
Token-Level
â—
ÄÆ°á»£c biá»ƒu diá»…n báº±ng vectÆ¡ nhá»‹ phÃ¢n
One-hot encoding
NhÆ°á»£c Ä‘iá»ƒm
â—
Ma tráº­n thÆ°a (háº§u háº¿t lÃ  sá»‘ 0)
â—‹
Sá»‘ chiá»u cá»§a VectÆ¡ tá»· lá»‡ thuáº­n vá»›i 
kÃ­ch thÆ°á»›c cá»§a sá»‘ lÆ°á»£ng tá»« vá»±ng
â—
KhÃ´ng náº¯m báº¯t Ä‘Æ°á»£c Ã½ nghÄ©a cá»§a tá»«
â—‹
Chá»‰ bao gá»“m cÃ¡c sá»‘ 0 vÃ  1
â—
Out of vocabulary (OOV)
Bag of Words (BoW)
Document-Level: Coi vÄƒn báº£n nhÆ° má»™t tÃºi (bá»™ sÆ°u táº­p) cÃ¡c tá»«
ÄÆ°á»£c biá»ƒu diá»…n báº±ng vectÆ¡ n-chiá»u
â—
sá»‘ láº§n xuáº¥t hiá»‡n cá»§a tá»« trong tÃ i liá»‡u
Bag of Words (BoW)
Document-Level: Coi vÄƒn báº£n nhÆ° má»™t tÃºi (bá»™ sÆ°u táº­p) cÃ¡c tá»«
ÄÆ°á»£c biá»ƒu diá»…n báº±ng vectÆ¡ n-chiá»u
â—
sá»‘ láº§n xuáº¥t hiá»‡n cá»§a tá»« trong tÃ i liá»‡u
Bag of Words (BoW)
NhÆ°á»£c Ä‘iá»ƒm
-
Out of vocabulary (OOV): tá»« khÃ´ng náº±m trong tá»« Ä‘iá»ƒn
Bag of Words (BoW)
NhÆ°á»£c Ä‘iá»ƒm
Vector biá»ƒu diá»…n khÃ´ng tÃ­nh Ä‘áº¿n táº§n suáº¥t xuáº¥t hiá»‡n cá»§a tá»«
Bag of Words (BoW)
Æ¯u Ä‘iá»ƒm
-
Giá»¯ Ä‘Æ°á»£c sá»± tÆ°Æ¡ng Ä‘á»“ng vá» ngá»¯ nghÄ©a cá»§a tÃ i liá»‡u
Bag of Words (BoW)
NhÆ°á»£c Ä‘iá»ƒm
â—
Ma tráº­n thÆ°a (háº§u háº¿t lÃ  sá»‘ 0)
â—‹
Sá»‘ chiá»u cá»§a VectÆ¡ tá»· lá»‡ thuáº­n vá»›i 
kÃ­ch thÆ°á»›c cá»§a sá»‘ lÆ°á»£ng tá»« vá»±ng
â—
KhÃ´ng náº¯m báº¯t Ä‘Æ°á»£c Ã½ nghÄ©a cá»§a tá»«
â—‹
Chá»‰ bao gá»“m cÃ¡c sá»‘ 0 vÃ  1
â—
Out of vocabulary (OOV)
â—
Document Level: Xem vÄƒn báº£n nhÆ° má»™t tÃºi (bá»™ sÆ°u táº­p) cÃ¡c tá»«
â—
Vocabulary: táº­p há»£p táº¥t cáº£ cÃ¡c n-gram duy nháº¥t tá»« kho ngá»¯ liá»‡u
Bag of N-grams
â—
TF (Term Frequency): dÃ¹ng Ä‘á»ƒ Æ°á»›c lÆ°á»£ng táº§n suáº¥t xuáº¥t hiá»‡n 
cá»§a tá»« trong vÄƒn báº£n. Tuy nhiÃªn vá»›i má»—i vÄƒn báº£n thÃ¬ cÃ³ Ä‘á»™ dÃ i 
khÃ¡c nhau, vÃ¬ tháº¿ sá»‘ láº§n xuáº¥t hiá»‡n cá»§a tá»« cÃ³ thá»ƒ nhiá»u hÆ¡n . VÃ¬ 
váº­y sá»‘ láº§n xuáº¥t hiá»‡n cá»§a tá»« sáº½ Ä‘Æ°á»£c chia Ä‘á»™ dÃ i cá»§a vÄƒn báº£n 
(tá»•ng sá»‘ tá»« trong vÄƒn báº£n Ä‘Ã³)
TF-IDF
â—
TF (Term Frequency)
TF-IDF
â—
TF (Term Frequency)
TF-IDF
N: Tá»•ng sá»‘ tÃ i liá»‡u trong kho vÄƒn báº£n
dft: Sá»‘ lÆ°á»£ng tÃ i liá»‡u cÃ³ thuáº­t ngá»¯ t trong Ä‘Ã³
TF-IDF
IDF (Inverse Document Frequency)
â—
Äo lÆ°á»ng táº§m quan trá»ng cá»§a tá»« trÃªn má»™t kho ngá»¯ liá»‡u
TF-IDF
IDF (Inverse Document Frequency)
Khi tÃ­nh táº§n sá»‘ xuáº¥t hiá»‡n tf thÃ¬ cÃ¡c tá»« Ä‘á»u Ä‘Æ°á»£c coi lÃ  quan trá»ng nhÆ° 
nhau. Tuy nhiÃªn cÃ³ má»™t sá»‘ tá»« thÆ°á»ng Ä‘Æ°á»£c Ä‘Æ°á»£c sá»­ dá»¥ng nhiá»u 
nhÆ°ng khÃ´ng quan trá»ng Ä‘á»ƒ thá»ƒ hiá»‡n Ã½ nghÄ©a cá»§a Ä‘oáº¡n vÄƒn , vÃ­ dá»¥ :
â—
Tá»« ná»‘i: vÃ , nhÆ°ng, tuy nhiÃªn, vÃ¬ tháº¿, vÃ¬ váº­y, â€¦
â—
Giá»›i tá»«: á»Ÿ, trong, trÃªn, â€¦
â—
Tá»« chá»‰ Ä‘á»‹nh: áº¥y, Ä‘Ã³, nhá»‰, â€¦
VÃ¬ váº­y ta cáº§n giáº£m Ä‘i má»©c Ä‘á»™ quan trá»ng cá»§a nhá»¯ng tá»« Ä‘Ã³ báº±ng cÃ¡ch 
sá»­ dá»¥ng IDF
TF-IDF
IDF (Inverse Document Frequency)
TF-IDF
â—
lÃ  trá»ng sá»‘ cá»§a má»™t tá»« trong vÄƒn báº£n thu Ä‘Æ°á»£c qua thá»‘ng kÃª thá»ƒ 
hiá»‡n má»©c Ä‘á»™ quan trá»ng cá»§a tá»« nÃ y trong má»™t vÄƒn báº£n, mÃ  báº£n 
thÃ¢n vÄƒn báº£n Ä‘ang xÃ©t náº±m trong má»™t táº­p há»£p cÃ¡c vÄƒn báº£n.
â—
Khi Ä‘Ã³, biá»ƒu diá»…n vectÆ¡ TF-IDF cho má»™t tÃ i liá»‡u chá»‰ Ä‘Æ¡n giáº£n lÃ  
Ä‘iá»ƒm TF-IDF cho tá»«ng thuáº­t ngá»¯ trong tÃ i liá»‡u Ä‘Ã³.
TF-IDF
TF-IDF
TF-IDF
TF-IDF
Æ¯u Ä‘iá»ƒm
â—
Náº¯m báº¯t má»™t sá»‘ Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng vá» ngá»¯ nghÄ©a
â—
Há»¯u Ã­ch cho viá»‡c truy xuáº¥t thÃ´ng tin vÃ  phÃ¢n loáº¡i vÄƒn báº£n
Text Classification
PhÆ°Æ¡ng phÃ¡p Naive Bayes
â—
Giáº£ Ä‘á»‹nh NaÃ¯ve Bayes: CÃ¡c thuá»™c tÃ­nh mÃ  mÃ´ táº£ dá»¯ liá»‡u lÃ  Ä‘á»™c 
láº­p Ä‘iá»u kiá»‡n theo bá»Ÿi giáº£ thuyáº¿t phÃ¢n lá»›p
â—
Cá»±c Ä‘áº¡i giáº£ thuyáº¿t háº­u nghiá»‡m
â—
Má»™t trong nhá»¯ng phÆ°Æ¡ng phÃ¡p há»c mÃ¡y thá»±c táº¿ nháº¥t
â—
CÃ¡c á»©ng dá»¥ng thÃ nh cÃ´ng:
â—‹
Cháº©n Ä‘oÃ¡n sá»©c khá»e
â—‹
PhÃ¢n lá»›p vÄƒn báº£n, lá»c ná»™i dung thÆ° rÃ¡c (spam mail)
PhÆ°Æ¡ng phÃ¡p Naive Bayes
PhÃ¢n loáº¡i vÄƒn báº£n
â—
Má»¥c tiÃªu: gÃ¡n má»™t vÄƒn báº£n má»›i vÃ o má»™t lá»›p cÃ³ xÃ¡c suáº¥t háº­u nghiá»‡m 
cao nháº¥t P(class | document)
â—
VÃ­ dá»¥: PhÃ¢n loáº¡i Spam mail
â—‹
Má»™t email lÃ  spam náº¿u P(spam | message) > P(Â¬spam | message)
PhÃ¢n loáº¡i vÄƒn báº£n
â—
Má»¥c tiÃªu: gÃ¡n má»™t vÄƒn báº£n má»›i vÃ o má»™t lá»›p cÃ³ xÃ¡c suáº¥t háº­u 
nghiá»‡m cao nháº¥t P(class | document)
â—
ChÃºng ta cÃ³ P(class | document) Î¼ P(document | class)P(class)
â—
MÃ´ hÃ¬nh cáº§n Æ°á»›c lÆ°á»£ng likelihoods P(document | class) cho táº¥t 
cáº£ cÃ¡c lá»›p priors P(class)
Thuáº­t toÃ¡n NaÃ¯ve Bayes
â—
 Má»¥c tiÃªu: Æ°á»›c lÆ°á»£ng xÃ¡c suáº¥t háº­u nghiá»‡m P(document | class) 
vÃ  xÃ¡c suáº¥t tiá»n nghiá»‡m P(class)
â—
Likelihood: giáº£ sá»­ dÃ¹ng bag of words
â—‹
Má»™t VÄƒn Báº£n LÃ  Má»™t Chuá»—i CÃ¡c Tá»« (w1,...,wn)
â—‹
Thá»© tá»± cÃ¡c tá»« khÃ´ng quan trá»ng
â—‹
Má»—i tá»« phá»¥ thuá»™c Ä‘iá»u kiá»‡n vá»›i lá»›p cá»§a vÄƒn báº£n nhÆ° sau
â—
NhÆ° váº­y, váº¥n Ä‘á» Ä‘Æ°á»£c Ä‘Æ¡n giáº£n hoÃ¡ báº±ng quÃ¡ trÃ¬nh Æ°á»›c lÆ°á»£ng 
xÃ¡c suáº¥t cá»§a tá»«ng tá»« P(wi | class)
Æ¯á»›c lÆ°á»£ng tham sá»‘
â—
Tham sá»‘ cá»§a mÃ´ hÃ¬nh: lÃ  cÃ¡c xÃ¡c suáº¥t likelihoods P(word | class) 
vÃ  xÃ¡c suáº¥t tiá»n nghiá»‡m P(class)
â—‹
LÃ m tháº¿ nÃ o Ä‘á»ƒ xÃ¡c Ä‘á»‹nh giÃ¡ trá»‹ cá»§a cÃ¡c tham sá»‘?
â—‹
Cáº§n táº­p dá»¯ liá»‡u huáº¥n luyá»‡n
â—
QuÃ¡ trÃ¬nh Æ°á»›c lÆ°á»£ng maximum likelihood (ML) tá»« táº­p dá»¯ liá»‡u 
huáº¥n luyá»‡n nhÆ° sau:
Æ¯á»›c lÆ°á»£ng tham sá»‘
â—
 Æ¯á»›c lÆ°á»£ng tham sá»‘:
â—
LÃ m má»‹n tham sá»‘ (parameter smoothing): xá»­ lÃ½ trÆ°á»ng há»£p cÃ¡c 
tá»« khÃ´ng xuáº¥t hiá»‡n hoáº·c xuáº¥t hiá»‡n quÃ¡ nhiá»u
â—
Tá»•ng káº¿t buá»•i há»c
